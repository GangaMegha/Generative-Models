{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RBM_FashionMNIST.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMCLZLWVqXCstRlaq/DER40",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GangaMegha/Generative-Models/blob/main/RBM_FashionMNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FcyDht9LwHXP"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Import MNIST data\n",
        "import tensorflow as tf"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bpN1fuKVG8DQ"
      },
      "source": [
        "# RBM class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DgSFBOGKG_OC"
      },
      "source": [
        "class RBM():\n",
        "    def __init__(self, num_hidden, num_visible, lr, n, batch_size, epochs):\n",
        "        self.num_hidden = num_hidden\n",
        "        self.num_visible = num_visible\n",
        "        self.lr = lr\n",
        "        self.n = n\n",
        "        self.batch_size = batch_size\n",
        "        self.epochs = epochs\n",
        "\n",
        "        self.W = np.random.randn(num_hidden, num_visible)/np.sqrt(0.5*(num_visible + num_hidden)) # weights\n",
        "\n",
        "        self.b_h = np.zeros((num_hidden, 1)) # bias latent\n",
        "        self.b_v = np.zeros((num_visible, 1)) # bias visible\n",
        "\n",
        "        self.dW = []\n",
        "        self.db_h = []\n",
        "        self.db_v = []\n",
        "\n",
        "    def sigmoid(self, x):  \n",
        "        #Sigmoid activation \n",
        "        #Implemented interms  of tanh for increased stability\n",
        "        return .5 * (1 + np.tanh(.5 * x))\n",
        "\n",
        "    \n",
        "    def bernoulli_array(self, prob_array, dim):\n",
        "        # Simulating Bernoulli from uniform\n",
        "        sample = np.zeros(dim)\n",
        "\n",
        "        # Draw x~Uni[0,1]\n",
        "        uni_sample = np.random.uniform(0, 1, dim)\n",
        "\n",
        "        # return 1 if x < p else return 0\n",
        "        diff = uni_sample - prob_array\n",
        "        coords = np.argwhere(diff<0)\n",
        "        sample[[*coords.T]] = 1  \n",
        "\n",
        "        return sample\n",
        "\n",
        "    def gibbs_sampling(self, h_0):\n",
        "\n",
        "        h = h_0.copy()\n",
        "\n",
        "        for i in range(self.n):\n",
        "\n",
        "            # (v x h) @ (h x b) + (v x 1) = (v x b)\n",
        "            p_v_h = self.sigmoid(self.W.T @ h + self.b_v)\n",
        "            v = self.bernoulli_array(p_v_h, (p_v_h.shape[0], p_v_h.shape[1]))\n",
        "\n",
        "            # (h x v) @ (v x b) + (h x 1) = (h x b)\n",
        "            p_h_v = self.sigmoid(self.W @ v + self.b_h)\n",
        "            h = self.bernoulli_array(p_h_v, (p_h_v.shape[0], p_h_v.shape[1]))\n",
        "\n",
        "        return v, h, p_h_v\n",
        "\n",
        "    def gradient_descent(self, v_0, p_h_v_0, v_n, p_h_v_n):\n",
        "\n",
        "        # Compute the gradients\n",
        "        # (h x b) @ (b x v) - (h x b) @ (b x v) = (h x v)\n",
        "        self.dW = (p_h_v_0 @ v_0 - p_h_v_n @ v_n)/self.batch_size\n",
        "        self.db_h = np.mean(p_h_v_0 - p_h_v_n, axis=1)[:, np.newaxis]\n",
        "        self.db_v = np.mean(v_0 - v_n, axis=0)[:, np.newaxis]\n",
        "        \n",
        "        # Weight update\n",
        "        self.W   = self.W   + self.lr * self.dW\n",
        "        self.b_h = self.b_h + self.lr * self.db_h\n",
        "        self.b_v = self.b_v + self.lr * self.db_v\n",
        "\n",
        "\n",
        "    def reconstruction_error(self, v):\n",
        "        # Sample hidden state\n",
        "        p_h_v = self.sigmoid(self.W @ v + self.b_h)\n",
        "        h = self.bernoulli_array(p_h_v, (p_h_v.shape[0], p_h_v.shape[1]))\n",
        "\n",
        "        # Sample viible state\n",
        "        p_v_h = self.sigmoid(self.W.T @ h + self.b_v)\n",
        "        v_sampled = self.bernoulli_array(p_v_h, (p_v_h.shape[0], p_v_h.shape[1]))    \n",
        "\n",
        "        return np.sum(np.mean((v-v_sampled)**2, axis=1), axis=0)\n",
        "\n",
        "\n",
        "    def reconstruct_image(self, v):\n",
        "        # Sample hidden state\n",
        "        p_h_v = self.sigmoid(self.W @ v + self.b_h)\n",
        "        h = self.bernoulli_array(p_h_v, (p_h_v.shape[0], p_h_v.shape[1]))\n",
        "\n",
        "        # Sample viible state\n",
        "        p_v_h = self.sigmoid(self.W.T @ h + self.b_v)\n",
        "        v_sampled = self.bernoulli_array(p_v_h, (p_v_h.shape[0], p_v_h.shape[1]))    \n",
        "\n",
        "        return v_sampled\n",
        "\n",
        "\n",
        "    def Train(self, train, val):\n",
        "\n",
        "        num_batches = int(train.shape[0]/self.batch_size)\n",
        "        train_loss = []\n",
        "        val_loss = []\n",
        "\n",
        "        for epoch in range(self.epochs):\n",
        "\n",
        "            # Shuffling the data\n",
        "            train = np.random.permutation(train)\n",
        "\n",
        "            # Splitting data into batches\n",
        "            batches = np.array_split(train, num_batches)\n",
        "\n",
        "            for i in range(num_batches):\n",
        "\n",
        "                # visible units from data\n",
        "                v_0 = batches[i].T\n",
        "\n",
        "                # (h x v) @ (v x b) + (h x 1) = (h x b)\n",
        "                p_h_v_0 = self.sigmoid(self.W @ v_0 + self.b_h)\n",
        "                h_0 = self.bernoulli_array(p_h_v_0, (p_h_v_0.shape[0], p_h_v_0.shape[1]))\n",
        "\n",
        "                # Run the markov chain\n",
        "                v_n, h_n, p_h_v_n = self.gibbs_sampling(h_0)\n",
        "\n",
        "                # Compute gradients\n",
        "                self.gradient_descent(v_0.T, p_h_v_0, v_n.T, p_h_v_n)\n",
        "\n",
        "            # Compute reconstruction errror\n",
        "            error_train = self.reconstruction_error(train.T)\n",
        "            error_val = self.reconstruction_error(val.T)\n",
        "\n",
        "            print(f\"Epoch {epoch+1} ------> Error => Train : {error_train}, Val : {error_val}\")\n",
        " \n",
        "            train_loss.append(error_train)\n",
        "            val_loss.append(error_val)\n",
        "\n",
        "        return train_loss, val_loss\n",
        "\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kJ6GU55s92Qa"
      },
      "source": [
        "# Fashion MNIST data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "DOp2JtgT9l0P",
        "outputId": "15fe01ea-7505-4d97-d450-823d386afcc0"
      },
      "source": [
        "# Load MNIST data\n",
        "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
        "(train, train_y), (test, test_y) = fashion_mnist.load_data()\n",
        "\n",
        "train = train.copy()\n",
        "train_y = train_y.copy()\n",
        "\n",
        "test = test.copy()\n",
        "test_y = test_y.copy()\n",
        "\n",
        "# Converting to binary\n",
        "train[[*np.argwhere(train>0).T]] = 1\n",
        "test[[*np.argwhere(test>0).T]] = 1\n",
        "\n",
        "\n",
        "fig = plt.figure()\n",
        "for i in range(9):\n",
        "  plt.subplot(3,3,i+1)\n",
        "  plt.tight_layout()\n",
        "  plt.imshow(train[i], cmap='gray', interpolation='none')\n",
        "  plt.title(\"Label: {}\".format(train_y[i]))\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:12: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
            "  if sys.path[0] == '':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:13: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
            "  del sys.path[0]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 9 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z0uFtm7E9dvU",
        "outputId": "f9c1c9a3-85ca-49a3-dda1-db1714d4ab38"
      },
      "source": [
        "# Split data into Train, Val, Test and flatten the images\n",
        "frac = 0.15\n",
        "\n",
        "n = int(frac*(train.shape[0]))\n",
        "val = train[:n]\n",
        "train = train[n:]\n",
        "\n",
        "train = train.reshape(train.shape[0], -1)\n",
        "val = val.reshape(val.shape[0], -1)\n",
        "test = test.reshape(test.shape[0], -1)\n",
        "\n",
        "print('Train: ', train.shape)\n",
        "print('Val: ', val.shape)\n",
        "print('Test:  ', test.shape)\n",
        "\n",
        "print(\"\\n\\nUnique labels : \", np.unique(train_y))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train:  (51000, 784)\n",
            "Val:  (9000, 784)\n",
            "Test:   (10000, 784)\n",
            "\n",
            "\n",
            "Unique labels :  [0 1 2 3 4 5 6 7 8 9]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-7sT-yDYPI2M"
      },
      "source": [
        "# Train and Inference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yCLe1EBNPT-W"
      },
      "source": [
        "# RBM config\n",
        "num_hidden = 256 # number of hidden units\n",
        "lr = 0.001 # learning rate for gradient descent\n",
        "n = 1 # number of Gibbs sampling steps\n",
        "batch_size = 100 # mini batch size for gradient update\n",
        "epochs = 600 # number of epochs"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C3sHXwRmmmkt",
        "outputId": "2775a008-602a-4e7d-f604-9d86522afa22"
      },
      "source": [
        "rbm = RBM(num_hidden, val.shape[1], lr, n, batch_size, epochs)\n",
        "train_loss, val_loss = rbm.Train(train, val)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:35: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 ------> Error => Train : 207.0539411764706, Val : 206.89244444444444\n",
            "Epoch 2 ------> Error => Train : 178.04672549019608, Val : 177.41944444444445\n",
            "Epoch 3 ------> Error => Train : 164.18656862745098, Val : 163.50044444444444\n",
            "Epoch 4 ------> Error => Train : 155.8314705882353, Val : 155.15988888888887\n",
            "Epoch 5 ------> Error => Train : 149.7645294117647, Val : 148.97466666666668\n",
            "Epoch 6 ------> Error => Train : 145.21239215686273, Val : 144.67200000000003\n",
            "Epoch 7 ------> Error => Train : 142.0199803921569, Val : 141.26999999999998\n",
            "Epoch 8 ------> Error => Train : 138.50123529411766, Val : 137.86344444444444\n",
            "Epoch 9 ------> Error => Train : 135.63972549019607, Val : 134.96800000000002\n",
            "Epoch 10 ------> Error => Train : 133.3084705882353, Val : 132.79522222222224\n",
            "Epoch 11 ------> Error => Train : 131.2522156862745, Val : 130.65344444444443\n",
            "Epoch 12 ------> Error => Train : 129.2202549019608, Val : 128.70566666666667\n",
            "Epoch 13 ------> Error => Train : 127.33068627450982, Val : 126.7297777777778\n",
            "Epoch 14 ------> Error => Train : 125.78545098039216, Val : 125.23922222222222\n",
            "Epoch 15 ------> Error => Train : 124.3505294117647, Val : 123.92122222222224\n",
            "Epoch 16 ------> Error => Train : 122.80349019607843, Val : 122.33533333333332\n",
            "Epoch 17 ------> Error => Train : 121.4397843137255, Val : 121.14377777777779\n",
            "Epoch 18 ------> Error => Train : 120.36801960784314, Val : 119.96133333333333\n",
            "Epoch 19 ------> Error => Train : 119.2453137254902, Val : 118.88888888888889\n",
            "Epoch 20 ------> Error => Train : 118.26866666666666, Val : 117.77444444444444\n",
            "Epoch 21 ------> Error => Train : 117.41017647058823, Val : 117.10011111111112\n",
            "Epoch 22 ------> Error => Train : 116.32698039215686, Val : 115.79911111111112\n",
            "Epoch 23 ------> Error => Train : 115.53827450980391, Val : 115.05888888888889\n",
            "Epoch 24 ------> Error => Train : 114.70278431372549, Val : 114.30833333333334\n",
            "Epoch 25 ------> Error => Train : 113.92750980392157, Val : 113.48977777777777\n",
            "Epoch 26 ------> Error => Train : 113.08113725490196, Val : 112.8318888888889\n",
            "Epoch 27 ------> Error => Train : 112.51884313725489, Val : 112.08500000000001\n",
            "Epoch 28 ------> Error => Train : 111.85741176470589, Val : 111.47855555555556\n",
            "Epoch 29 ------> Error => Train : 111.09423529411765, Val : 110.82266666666666\n",
            "Epoch 30 ------> Error => Train : 110.44888235294118, Val : 110.06211111111111\n",
            "Epoch 31 ------> Error => Train : 109.93864705882353, Val : 109.53977777777777\n",
            "Epoch 32 ------> Error => Train : 109.32998039215686, Val : 109.113\n",
            "Epoch 33 ------> Error => Train : 108.84992156862745, Val : 108.31811111111111\n",
            "Epoch 34 ------> Error => Train : 108.23156862745098, Val : 107.92611111111111\n",
            "Epoch 35 ------> Error => Train : 107.67572549019609, Val : 107.40655555555556\n",
            "Epoch 36 ------> Error => Train : 107.29490196078432, Val : 106.88877777777779\n",
            "Epoch 37 ------> Error => Train : 106.59586274509805, Val : 106.20866666666666\n",
            "Epoch 38 ------> Error => Train : 106.23764705882354, Val : 105.86866666666667\n",
            "Epoch 39 ------> Error => Train : 105.84623529411765, Val : 105.46322222222223\n",
            "Epoch 40 ------> Error => Train : 105.27782352941176, Val : 104.97222222222223\n",
            "Epoch 41 ------> Error => Train : 104.9421568627451, Val : 104.612\n",
            "Epoch 42 ------> Error => Train : 104.54462745098039, Val : 104.3758888888889\n",
            "Epoch 43 ------> Error => Train : 104.06272549019607, Val : 103.72355555555555\n",
            "Epoch 44 ------> Error => Train : 103.77107843137256, Val : 103.48277777777778\n",
            "Epoch 45 ------> Error => Train : 103.42258823529413, Val : 103.018\n",
            "Epoch 46 ------> Error => Train : 103.08178431372548, Val : 102.75177777777778\n",
            "Epoch 47 ------> Error => Train : 102.67492156862744, Val : 102.31677777777779\n",
            "Epoch 48 ------> Error => Train : 102.26786274509804, Val : 101.92311111111111\n",
            "Epoch 49 ------> Error => Train : 101.88388235294119, Val : 101.62022222222222\n",
            "Epoch 50 ------> Error => Train : 101.67919607843137, Val : 101.22333333333333\n",
            "Epoch 51 ------> Error => Train : 101.32776470588236, Val : 101.08211111111112\n",
            "Epoch 52 ------> Error => Train : 100.93760784313726, Val : 100.658\n",
            "Epoch 53 ------> Error => Train : 100.642, Val : 100.27877777777778\n",
            "Epoch 54 ------> Error => Train : 100.34056862745098, Val : 100.23455555555556\n",
            "Epoch 55 ------> Error => Train : 99.98674509803922, Val : 99.86877777777778\n",
            "Epoch 56 ------> Error => Train : 99.74539215686275, Val : 99.346\n",
            "Epoch 57 ------> Error => Train : 99.48950980392156, Val : 99.24111111111111\n",
            "Epoch 58 ------> Error => Train : 99.24509803921569, Val : 98.959\n",
            "Epoch 59 ------> Error => Train : 98.9396862745098, Val : 98.75955555555556\n",
            "Epoch 60 ------> Error => Train : 98.61827450980391, Val : 98.38055555555556\n",
            "Epoch 61 ------> Error => Train : 98.48635294117646, Val : 98.11266666666667\n",
            "Epoch 62 ------> Error => Train : 98.13064705882353, Val : 97.75544444444444\n",
            "Epoch 63 ------> Error => Train : 97.896, Val : 97.46488888888888\n",
            "Epoch 64 ------> Error => Train : 97.6927843137255, Val : 97.31666666666666\n",
            "Epoch 65 ------> Error => Train : 97.40511764705882, Val : 96.99077777777778\n",
            "Epoch 66 ------> Error => Train : 97.03821568627451, Val : 96.85900000000001\n",
            "Epoch 67 ------> Error => Train : 96.90888235294116, Val : 96.71100000000001\n",
            "Epoch 68 ------> Error => Train : 96.76282352941176, Val : 96.59922222222222\n",
            "Epoch 69 ------> Error => Train : 96.49954901960784, Val : 96.13522222222223\n",
            "Epoch 70 ------> Error => Train : 96.19917647058824, Val : 95.8808888888889\n",
            "Epoch 71 ------> Error => Train : 96.03407843137255, Val : 95.62088888888889\n",
            "Epoch 72 ------> Error => Train : 95.90360784313725, Val : 95.5988888888889\n",
            "Epoch 73 ------> Error => Train : 95.59707843137255, Val : 95.32355555555554\n",
            "Epoch 74 ------> Error => Train : 95.40164705882353, Val : 95.184\n",
            "Epoch 75 ------> Error => Train : 95.10456862745099, Val : 94.85611111111112\n",
            "Epoch 76 ------> Error => Train : 94.91496078431372, Val : 94.64922222222222\n",
            "Epoch 77 ------> Error => Train : 94.84050980392158, Val : 94.58377777777778\n",
            "Epoch 78 ------> Error => Train : 94.60613725490195, Val : 94.28255555555555\n",
            "Epoch 79 ------> Error => Train : 94.36611764705881, Val : 94.0668888888889\n",
            "Epoch 80 ------> Error => Train : 94.14362745098039, Val : 93.90322222222223\n",
            "Epoch 81 ------> Error => Train : 93.9795294117647, Val : 93.62344444444444\n",
            "Epoch 82 ------> Error => Train : 93.8066862745098, Val : 93.57977777777776\n",
            "Epoch 83 ------> Error => Train : 93.58392156862746, Val : 93.38033333333334\n",
            "Epoch 84 ------> Error => Train : 93.36829411764705, Val : 93.01766666666667\n",
            "Epoch 85 ------> Error => Train : 93.24058823529411, Val : 92.92944444444444\n",
            "Epoch 86 ------> Error => Train : 93.03611764705882, Val : 92.68322222222223\n",
            "Epoch 87 ------> Error => Train : 92.88749019607843, Val : 92.5398888888889\n",
            "Epoch 88 ------> Error => Train : 92.69060784313726, Val : 92.40344444444443\n",
            "Epoch 89 ------> Error => Train : 92.47950980392156, Val : 92.28022222222222\n",
            "Epoch 90 ------> Error => Train : 92.33662745098039, Val : 92.00788888888889\n",
            "Epoch 91 ------> Error => Train : 92.15396078431372, Val : 91.82455555555555\n",
            "Epoch 92 ------> Error => Train : 91.99799999999999, Val : 91.62977777777778\n",
            "Epoch 93 ------> Error => Train : 91.71307843137254, Val : 91.6588888888889\n",
            "Epoch 94 ------> Error => Train : 91.6317450980392, Val : 91.30066666666667\n",
            "Epoch 95 ------> Error => Train : 91.49986274509803, Val : 91.33644444444445\n",
            "Epoch 96 ------> Error => Train : 91.32696078431373, Val : 91.01788888888889\n",
            "Epoch 97 ------> Error => Train : 91.18043137254902, Val : 91.02555555555556\n",
            "Epoch 98 ------> Error => Train : 90.92823529411764, Val : 90.76533333333333\n",
            "Epoch 99 ------> Error => Train : 90.84941176470588, Val : 90.59911111111111\n",
            "Epoch 100 ------> Error => Train : 90.63492156862745, Val : 90.27355555555556\n",
            "Epoch 101 ------> Error => Train : 90.50701960784315, Val : 90.12833333333333\n",
            "Epoch 102 ------> Error => Train : 90.34941176470589, Val : 90.05388888888888\n",
            "Epoch 103 ------> Error => Train : 90.1308431372549, Val : 89.94611111111112\n",
            "Epoch 104 ------> Error => Train : 90.00331372549019, Val : 89.80133333333333\n",
            "Epoch 105 ------> Error => Train : 89.93519607843137, Val : 89.69255555555556\n",
            "Epoch 106 ------> Error => Train : 89.71082352941175, Val : 89.57977777777776\n",
            "Epoch 107 ------> Error => Train : 89.69011764705883, Val : 89.40922222222223\n",
            "Epoch 108 ------> Error => Train : 89.43458823529411, Val : 89.014\n",
            "Epoch 109 ------> Error => Train : 89.19327450980393, Val : 89.02533333333334\n",
            "Epoch 110 ------> Error => Train : 89.20047058823529, Val : 88.95244444444444\n",
            "Epoch 111 ------> Error => Train : 89.04866666666666, Val : 88.70111111111112\n",
            "Epoch 112 ------> Error => Train : 88.88021568627451, Val : 88.606\n",
            "Epoch 113 ------> Error => Train : 88.6853725490196, Val : 88.49911111111112\n",
            "Epoch 114 ------> Error => Train : 88.59164705882353, Val : 88.419\n",
            "Epoch 115 ------> Error => Train : 88.41966666666667, Val : 88.09311111111111\n",
            "Epoch 116 ------> Error => Train : 88.31996078431372, Val : 88.18622222222223\n",
            "Epoch 117 ------> Error => Train : 88.29901960784314, Val : 88.05644444444445\n",
            "Epoch 118 ------> Error => Train : 88.09080392156862, Val : 87.84866666666667\n",
            "Epoch 119 ------> Error => Train : 87.90964705882354, Val : 87.7398888888889\n",
            "Epoch 120 ------> Error => Train : 87.87949019607844, Val : 87.6598888888889\n",
            "Epoch 121 ------> Error => Train : 87.63533333333334, Val : 87.37400000000001\n",
            "Epoch 122 ------> Error => Train : 87.56129411764705, Val : 87.1661111111111\n",
            "Epoch 123 ------> Error => Train : 87.34790196078431, Val : 87.26922222222223\n",
            "Epoch 124 ------> Error => Train : 87.28533333333333, Val : 87.012\n",
            "Epoch 125 ------> Error => Train : 87.12045098039215, Val : 86.97944444444444\n",
            "Epoch 126 ------> Error => Train : 86.96782352941176, Val : 86.65277777777777\n",
            "Epoch 127 ------> Error => Train : 86.88950980392157, Val : 86.76266666666666\n",
            "Epoch 128 ------> Error => Train : 86.72523529411765, Val : 86.52266666666667\n",
            "Epoch 129 ------> Error => Train : 86.62066666666666, Val : 86.52388888888889\n",
            "Epoch 130 ------> Error => Train : 86.45309803921567, Val : 86.26744444444444\n",
            "Epoch 131 ------> Error => Train : 86.37974509803921, Val : 86.15022222222221\n",
            "Epoch 132 ------> Error => Train : 86.21458823529412, Val : 86.10322222222221\n",
            "Epoch 133 ------> Error => Train : 86.19172549019608, Val : 85.91677777777778\n",
            "Epoch 134 ------> Error => Train : 86.06105882352942, Val : 85.92955555555555\n",
            "Epoch 135 ------> Error => Train : 85.89596078431373, Val : 85.71444444444445\n",
            "Epoch 136 ------> Error => Train : 85.73866666666666, Val : 85.47588888888889\n",
            "Epoch 137 ------> Error => Train : 85.62478431372548, Val : 85.38966666666667\n",
            "Epoch 138 ------> Error => Train : 85.59827450980393, Val : 85.36622222222222\n",
            "Epoch 139 ------> Error => Train : 85.44601960784314, Val : 85.29444444444445\n",
            "Epoch 140 ------> Error => Train : 85.36923529411764, Val : 85.25200000000001\n",
            "Epoch 141 ------> Error => Train : 85.25607843137256, Val : 85.11755555555555\n",
            "Epoch 142 ------> Error => Train : 85.2107843137255, Val : 84.83233333333334\n",
            "Epoch 143 ------> Error => Train : 85.0106862745098, Val : 84.793\n",
            "Epoch 144 ------> Error => Train : 84.95913725490196, Val : 84.68944444444443\n",
            "Epoch 145 ------> Error => Train : 84.746, Val : 84.71033333333332\n",
            "Epoch 146 ------> Error => Train : 84.71760784313724, Val : 84.44944444444445\n",
            "Epoch 147 ------> Error => Train : 84.55182352941176, Val : 84.48788888888889\n",
            "Epoch 148 ------> Error => Train : 84.44450980392156, Val : 84.18255555555555\n",
            "Epoch 149 ------> Error => Train : 84.33358823529412, Val : 84.30277777777778\n",
            "Epoch 150 ------> Error => Train : 84.24698039215686, Val : 84.00788888888889\n",
            "Epoch 151 ------> Error => Train : 84.15837254901962, Val : 84.0551111111111\n",
            "Epoch 152 ------> Error => Train : 84.09403921568628, Val : 83.983\n",
            "Epoch 153 ------> Error => Train : 83.95360784313725, Val : 83.71166666666667\n",
            "Epoch 154 ------> Error => Train : 83.87209803921569, Val : 83.70633333333333\n",
            "Epoch 155 ------> Error => Train : 83.69772549019608, Val : 83.48888888888888\n",
            "Epoch 156 ------> Error => Train : 83.59350980392156, Val : 83.46733333333333\n",
            "Epoch 157 ------> Error => Train : 83.46713725490196, Val : 83.36733333333333\n",
            "Epoch 158 ------> Error => Train : 83.43339215686275, Val : 83.19411111111111\n",
            "Epoch 159 ------> Error => Train : 83.32235294117646, Val : 83.15755555555556\n",
            "Epoch 160 ------> Error => Train : 83.28980392156862, Val : 83.05988888888889\n",
            "Epoch 161 ------> Error => Train : 83.16178431372549, Val : 82.99644444444445\n",
            "Epoch 162 ------> Error => Train : 83.02454901960785, Val : 82.74111111111111\n",
            "Epoch 163 ------> Error => Train : 83.00970588235293, Val : 82.83855555555556\n",
            "Epoch 164 ------> Error => Train : 82.8144705882353, Val : 82.6828888888889\n",
            "Epoch 165 ------> Error => Train : 82.78552941176471, Val : 82.46155555555556\n",
            "Epoch 166 ------> Error => Train : 82.528, Val : 82.34266666666667\n",
            "Epoch 167 ------> Error => Train : 82.55747058823529, Val : 82.48944444444444\n",
            "Epoch 168 ------> Error => Train : 82.37919607843138, Val : 82.23677777777777\n",
            "Epoch 169 ------> Error => Train : 82.28794117647058, Val : 82.28255555555555\n",
            "Epoch 170 ------> Error => Train : 82.31174509803921, Val : 82.1201111111111\n",
            "Epoch 171 ------> Error => Train : 82.16045098039216, Val : 82.06188888888889\n",
            "Epoch 172 ------> Error => Train : 82.17429411764707, Val : 82.01322222222223\n",
            "Epoch 173 ------> Error => Train : 81.94374509803922, Val : 81.93944444444445\n",
            "Epoch 174 ------> Error => Train : 81.91060784313726, Val : 81.80344444444444\n",
            "Epoch 175 ------> Error => Train : 81.85927450980392, Val : 81.52455555555555\n",
            "Epoch 176 ------> Error => Train : 81.69313725490197, Val : 81.6631111111111\n",
            "Epoch 177 ------> Error => Train : 81.60203921568628, Val : 81.44311111111111\n",
            "Epoch 178 ------> Error => Train : 81.49764705882353, Val : 81.42855555555556\n",
            "Epoch 179 ------> Error => Train : 81.43594117647058, Val : 81.372\n",
            "Epoch 180 ------> Error => Train : 81.35709803921569, Val : 81.2451111111111\n",
            "Epoch 181 ------> Error => Train : 81.23282352941177, Val : 81.07211111111111\n",
            "Epoch 182 ------> Error => Train : 81.14786274509802, Val : 81.03277777777777\n",
            "Epoch 183 ------> Error => Train : 81.1108431372549, Val : 81.00744444444445\n",
            "Epoch 184 ------> Error => Train : 80.94201960784314, Val : 80.75088888888888\n",
            "Epoch 185 ------> Error => Train : 80.94429411764705, Val : 80.76233333333333\n",
            "Epoch 186 ------> Error => Train : 80.828, Val : 80.67055555555555\n",
            "Epoch 187 ------> Error => Train : 80.79292156862745, Val : 80.59022222222222\n",
            "Epoch 188 ------> Error => Train : 80.68707843137254, Val : 80.57600000000001\n",
            "Epoch 189 ------> Error => Train : 80.63025490196078, Val : 80.58366666666666\n",
            "Epoch 190 ------> Error => Train : 80.46819607843138, Val : 80.43177777777778\n",
            "Epoch 191 ------> Error => Train : 80.44919607843137, Val : 80.24744444444444\n",
            "Epoch 192 ------> Error => Train : 80.38970588235294, Val : 80.24222222222222\n",
            "Epoch 193 ------> Error => Train : 80.30478431372549, Val : 79.952\n",
            "Epoch 194 ------> Error => Train : 80.15899999999999, Val : 80.00211111111112\n",
            "Epoch 195 ------> Error => Train : 80.11594117647059, Val : 79.96533333333333\n",
            "Epoch 196 ------> Error => Train : 80.02309803921568, Val : 79.93644444444445\n",
            "Epoch 197 ------> Error => Train : 79.92264705882353, Val : 79.81844444444445\n",
            "Epoch 198 ------> Error => Train : 79.93141176470589, Val : 79.70755555555556\n",
            "Epoch 199 ------> Error => Train : 79.77107843137256, Val : 79.63900000000001\n",
            "Epoch 200 ------> Error => Train : 79.72270588235294, Val : 79.61266666666666\n",
            "Epoch 201 ------> Error => Train : 79.69572549019608, Val : 79.51500000000001\n",
            "Epoch 202 ------> Error => Train : 79.532, Val : 79.44155555555557\n",
            "Epoch 203 ------> Error => Train : 79.47935294117647, Val : 79.29988888888889\n",
            "Epoch 204 ------> Error => Train : 79.44086274509803, Val : 79.37677777777779\n",
            "Epoch 205 ------> Error => Train : 79.38747058823529, Val : 79.20388888888888\n",
            "Epoch 206 ------> Error => Train : 79.25872549019607, Val : 79.12977777777778\n",
            "Epoch 207 ------> Error => Train : 79.22286274509804, Val : 79.01344444444445\n",
            "Epoch 208 ------> Error => Train : 79.13894117647058, Val : 79.11477777777779\n",
            "Epoch 209 ------> Error => Train : 78.95556862745099, Val : 78.96666666666667\n",
            "Epoch 210 ------> Error => Train : 79.02064705882353, Val : 79.00888888888889\n",
            "Epoch 211 ------> Error => Train : 78.90011764705882, Val : 78.78133333333334\n",
            "Epoch 212 ------> Error => Train : 78.86217647058824, Val : 78.655\n",
            "Epoch 213 ------> Error => Train : 78.74005882352941, Val : 78.58133333333333\n",
            "Epoch 214 ------> Error => Train : 78.65517647058823, Val : 78.34822222222222\n",
            "Epoch 215 ------> Error => Train : 78.58466666666666, Val : 78.52766666666666\n",
            "Epoch 216 ------> Error => Train : 78.57435294117647, Val : 78.3848888888889\n",
            "Epoch 217 ------> Error => Train : 78.45603921568627, Val : 78.38933333333333\n",
            "Epoch 218 ------> Error => Train : 78.27723529411765, Val : 78.12811111111111\n",
            "Epoch 219 ------> Error => Train : 78.30460784313726, Val : 78.1888888888889\n",
            "Epoch 220 ------> Error => Train : 78.25713725490195, Val : 78.21555555555555\n",
            "Epoch 221 ------> Error => Train : 78.19917647058824, Val : 78.18633333333332\n",
            "Epoch 222 ------> Error => Train : 78.05941176470589, Val : 78.00877777777777\n",
            "Epoch 223 ------> Error => Train : 78.04488235294119, Val : 77.94955555555555\n",
            "Epoch 224 ------> Error => Train : 77.97941176470587, Val : 77.82944444444445\n",
            "Epoch 225 ------> Error => Train : 77.88062745098038, Val : 77.80522222222221\n",
            "Epoch 226 ------> Error => Train : 77.81264705882353, Val : 77.79855555555557\n",
            "Epoch 227 ------> Error => Train : 77.72225490196078, Val : 77.77322222222222\n",
            "Epoch 228 ------> Error => Train : 77.73472549019607, Val : 77.71144444444445\n",
            "Epoch 229 ------> Error => Train : 77.60676470588234, Val : 77.52533333333335\n",
            "Epoch 230 ------> Error => Train : 77.55125490196079, Val : 77.49355555555556\n",
            "Epoch 231 ------> Error => Train : 77.51325490196078, Val : 77.3668888888889\n",
            "Epoch 232 ------> Error => Train : 77.52211764705882, Val : 77.5032222222222\n",
            "Epoch 233 ------> Error => Train : 77.34972549019608, Val : 77.25544444444444\n",
            "Epoch 234 ------> Error => Train : 77.31137254901961, Val : 77.22911111111111\n",
            "Epoch 235 ------> Error => Train : 77.29847058823529, Val : 77.12944444444445\n",
            "Epoch 236 ------> Error => Train : 77.2365294117647, Val : 77.14022222222222\n",
            "Epoch 237 ------> Error => Train : 77.08176470588235, Val : 77.11122222222222\n",
            "Epoch 238 ------> Error => Train : 77.0409411764706, Val : 76.95333333333333\n",
            "Epoch 239 ------> Error => Train : 77.04127450980391, Val : 76.84488888888887\n",
            "Epoch 240 ------> Error => Train : 76.94707843137255, Val : 76.926\n",
            "Epoch 241 ------> Error => Train : 76.93249019607843, Val : 76.75144444444445\n",
            "Epoch 242 ------> Error => Train : 76.85088235294117, Val : 76.65055555555556\n",
            "Epoch 243 ------> Error => Train : 76.7328431372549, Val : 76.69044444444445\n",
            "Epoch 244 ------> Error => Train : 76.755, Val : 76.67677777777777\n",
            "Epoch 245 ------> Error => Train : 76.65584313725489, Val : 76.438\n",
            "Epoch 246 ------> Error => Train : 76.50941176470587, Val : 76.45222222222222\n",
            "Epoch 247 ------> Error => Train : 76.49725490196079, Val : 76.47999999999999\n",
            "Epoch 248 ------> Error => Train : 76.48711764705882, Val : 76.243\n",
            "Epoch 249 ------> Error => Train : 76.44478431372549, Val : 76.24144444444445\n",
            "Epoch 250 ------> Error => Train : 76.34011764705883, Val : 76.30322222222223\n",
            "Epoch 251 ------> Error => Train : 76.2417843137255, Val : 76.33844444444443\n",
            "Epoch 252 ------> Error => Train : 76.20925490196078, Val : 76.13888888888889\n",
            "Epoch 253 ------> Error => Train : 76.11511764705882, Val : 76.08977777777778\n",
            "Epoch 254 ------> Error => Train : 76.12072549019608, Val : 76.0961111111111\n",
            "Epoch 255 ------> Error => Train : 76.0815294117647, Val : 76.08677777777777\n",
            "Epoch 256 ------> Error => Train : 75.96772549019609, Val : 75.94300000000001\n",
            "Epoch 257 ------> Error => Train : 76.01427450980393, Val : 75.75399999999999\n",
            "Epoch 258 ------> Error => Train : 75.941, Val : 75.809\n",
            "Epoch 259 ------> Error => Train : 75.78464705882354, Val : 75.75022222222222\n",
            "Epoch 260 ------> Error => Train : 75.76574509803922, Val : 75.73666666666666\n",
            "Epoch 261 ------> Error => Train : 75.71760784313724, Val : 75.65322222222223\n",
            "Epoch 262 ------> Error => Train : 75.68205882352942, Val : 75.54888888888888\n",
            "Epoch 263 ------> Error => Train : 75.57841176470588, Val : 75.485\n",
            "Epoch 264 ------> Error => Train : 75.5347843137255, Val : 75.49977777777778\n",
            "Epoch 265 ------> Error => Train : 75.5229411764706, Val : 75.36877777777778\n",
            "Epoch 266 ------> Error => Train : 75.38880392156864, Val : 75.35566666666666\n",
            "Epoch 267 ------> Error => Train : 75.39594117647059, Val : 75.2801111111111\n",
            "Epoch 268 ------> Error => Train : 75.30003921568628, Val : 75.24388888888889\n",
            "Epoch 269 ------> Error => Train : 75.32849019607843, Val : 75.1391111111111\n",
            "Epoch 270 ------> Error => Train : 75.22082352941176, Val : 75.19244444444445\n",
            "Epoch 271 ------> Error => Train : 75.2215294117647, Val : 75.11966666666666\n",
            "Epoch 272 ------> Error => Train : 75.14650980392157, Val : 75.0458888888889\n",
            "Epoch 273 ------> Error => Train : 75.06343137254902, Val : 75.08711111111111\n",
            "Epoch 274 ------> Error => Train : 74.96466666666667, Val : 74.98866666666666\n",
            "Epoch 275 ------> Error => Train : 74.94103921568627, Val : 74.85366666666665\n",
            "Epoch 276 ------> Error => Train : 74.90721568627451, Val : 74.99222222222222\n",
            "Epoch 277 ------> Error => Train : 74.94243137254901, Val : 74.7101111111111\n",
            "Epoch 278 ------> Error => Train : 74.82566666666668, Val : 74.855\n",
            "Epoch 279 ------> Error => Train : 74.80841176470588, Val : 74.67544444444445\n",
            "Epoch 280 ------> Error => Train : 74.68701960784314, Val : 74.59722222222221\n",
            "Epoch 281 ------> Error => Train : 74.6357450980392, Val : 74.48599999999999\n",
            "Epoch 282 ------> Error => Train : 74.60860784313726, Val : 74.63277777777778\n",
            "Epoch 283 ------> Error => Train : 74.50780392156862, Val : 74.53866666666667\n",
            "Epoch 284 ------> Error => Train : 74.49947058823528, Val : 74.48388888888888\n",
            "Epoch 285 ------> Error => Train : 74.4711568627451, Val : 74.3821111111111\n",
            "Epoch 286 ------> Error => Train : 74.37550980392157, Val : 74.35344444444445\n",
            "Epoch 287 ------> Error => Train : 74.37127450980391, Val : 74.33255555555556\n",
            "Epoch 288 ------> Error => Train : 74.3036862745098, Val : 74.25444444444446\n",
            "Epoch 289 ------> Error => Train : 74.18239215686275, Val : 74.20255555555556\n",
            "Epoch 290 ------> Error => Train : 74.18860784313725, Val : 74.19344444444444\n",
            "Epoch 291 ------> Error => Train : 74.11533333333334, Val : 74.10955555555554\n",
            "Epoch 292 ------> Error => Train : 74.10458823529412, Val : 74.07044444444443\n",
            "Epoch 293 ------> Error => Train : 74.04276470588235, Val : 74.0781111111111\n",
            "Epoch 294 ------> Error => Train : 73.99260784313725, Val : 73.92144444444443\n",
            "Epoch 295 ------> Error => Train : 73.97192156862745, Val : 73.89455555555556\n",
            "Epoch 296 ------> Error => Train : 73.91713725490196, Val : 74.02066666666667\n",
            "Epoch 297 ------> Error => Train : 73.92384313725489, Val : 73.94655555555556\n",
            "Epoch 298 ------> Error => Train : 73.80725490196079, Val : 73.68466666666667\n",
            "Epoch 299 ------> Error => Train : 73.70333333333332, Val : 73.68855555555555\n",
            "Epoch 300 ------> Error => Train : 73.70958823529412, Val : 73.80744444444444\n",
            "Epoch 301 ------> Error => Train : 73.72717647058823, Val : 73.57933333333332\n",
            "Epoch 302 ------> Error => Train : 73.70601960784313, Val : 73.6631111111111\n",
            "Epoch 303 ------> Error => Train : 73.55627450980393, Val : 73.45322222222222\n",
            "Epoch 304 ------> Error => Train : 73.55839215686275, Val : 73.57177777777778\n",
            "Epoch 305 ------> Error => Train : 73.56182352941175, Val : 73.54111111111112\n",
            "Epoch 306 ------> Error => Train : 73.49011764705882, Val : 73.44977777777777\n",
            "Epoch 307 ------> Error => Train : 73.47735294117646, Val : 73.39633333333333\n",
            "Epoch 308 ------> Error => Train : 73.4025294117647, Val : 73.38622222222222\n",
            "Epoch 309 ------> Error => Train : 73.35474509803922, Val : 73.33633333333333\n",
            "Epoch 310 ------> Error => Train : 73.21074509803921, Val : 73.2091111111111\n",
            "Epoch 311 ------> Error => Train : 73.21588235294118, Val : 73.20033333333333\n",
            "Epoch 312 ------> Error => Train : 73.20627450980392, Val : 73.10711111111111\n",
            "Epoch 313 ------> Error => Train : 73.20147058823528, Val : 72.99255555555555\n",
            "Epoch 314 ------> Error => Train : 73.0300588235294, Val : 73.01911111111112\n",
            "Epoch 315 ------> Error => Train : 73.05541176470587, Val : 72.95488888888889\n",
            "Epoch 316 ------> Error => Train : 73.04458823529413, Val : 73.02088888888889\n",
            "Epoch 317 ------> Error => Train : 72.97619607843137, Val : 72.90299999999999\n",
            "Epoch 318 ------> Error => Train : 72.96850980392156, Val : 72.95366666666666\n",
            "Epoch 319 ------> Error => Train : 72.87862745098039, Val : 72.97988888888888\n",
            "Epoch 320 ------> Error => Train : 72.78652941176472, Val : 72.8711111111111\n",
            "Epoch 321 ------> Error => Train : 72.78798039215687, Val : 72.74711111111111\n",
            "Epoch 322 ------> Error => Train : 72.80017647058824, Val : 72.71055555555556\n",
            "Epoch 323 ------> Error => Train : 72.7280980392157, Val : 72.66855555555556\n",
            "Epoch 324 ------> Error => Train : 72.63933333333333, Val : 72.7128888888889\n",
            "Epoch 325 ------> Error => Train : 72.63194117647059, Val : 72.45244444444444\n",
            "Epoch 326 ------> Error => Train : 72.52801960784313, Val : 72.53466666666668\n",
            "Epoch 327 ------> Error => Train : 72.55801960784314, Val : 72.47155555555557\n",
            "Epoch 328 ------> Error => Train : 72.48705882352942, Val : 72.41044444444445\n",
            "Epoch 329 ------> Error => Train : 72.41894117647058, Val : 72.43155555555556\n",
            "Epoch 330 ------> Error => Train : 72.39149019607842, Val : 72.33855555555556\n",
            "Epoch 331 ------> Error => Train : 72.38296078431372, Val : 72.4181111111111\n",
            "Epoch 332 ------> Error => Train : 72.333, Val : 72.394\n",
            "Epoch 333 ------> Error => Train : 72.24407843137254, Val : 72.22688888888888\n",
            "Epoch 334 ------> Error => Train : 72.26229411764706, Val : 72.30499999999999\n",
            "Epoch 335 ------> Error => Train : 72.19988235294119, Val : 72.18188888888889\n",
            "Epoch 336 ------> Error => Train : 72.12072549019607, Val : 71.97555555555556\n",
            "Epoch 337 ------> Error => Train : 72.19766666666666, Val : 72.11666666666666\n",
            "Epoch 338 ------> Error => Train : 72.12250980392156, Val : 72.06522222222222\n",
            "Epoch 339 ------> Error => Train : 72.0434117647059, Val : 72.05855555555556\n",
            "Epoch 340 ------> Error => Train : 72.0501568627451, Val : 71.8998888888889\n",
            "Epoch 341 ------> Error => Train : 71.94739215686275, Val : 71.82888888888888\n",
            "Epoch 342 ------> Error => Train : 71.9456274509804, Val : 71.97844444444443\n",
            "Epoch 343 ------> Error => Train : 71.8900980392157, Val : 71.96933333333334\n",
            "Epoch 344 ------> Error => Train : 71.83339215686274, Val : 71.68766666666667\n",
            "Epoch 345 ------> Error => Train : 71.80390196078432, Val : 71.78444444444445\n",
            "Epoch 346 ------> Error => Train : 71.79543137254902, Val : 71.61711111111111\n",
            "Epoch 347 ------> Error => Train : 71.72266666666667, Val : 71.74844444444444\n",
            "Epoch 348 ------> Error => Train : 71.77117647058824, Val : 71.79744444444444\n",
            "Epoch 349 ------> Error => Train : 71.59305882352942, Val : 71.614\n",
            "Epoch 350 ------> Error => Train : 71.5843137254902, Val : 71.64466666666667\n",
            "Epoch 351 ------> Error => Train : 71.56701960784314, Val : 71.50822222222223\n",
            "Epoch 352 ------> Error => Train : 71.52447058823529, Val : 71.53044444444444\n",
            "Epoch 353 ------> Error => Train : 71.49984313725491, Val : 71.43011111111112\n",
            "Epoch 354 ------> Error => Train : 71.47854901960784, Val : 71.38577777777778\n",
            "Epoch 355 ------> Error => Train : 71.40511764705883, Val : 71.446\n",
            "Epoch 356 ------> Error => Train : 71.40390196078431, Val : 71.39177777777778\n",
            "Epoch 357 ------> Error => Train : 71.31988235294118, Val : 71.32177777777778\n",
            "Epoch 358 ------> Error => Train : 71.33798039215685, Val : 71.35888888888888\n",
            "Epoch 359 ------> Error => Train : 71.24570588235295, Val : 71.19077777777778\n",
            "Epoch 360 ------> Error => Train : 71.23801960784314, Val : 71.16522222222223\n",
            "Epoch 361 ------> Error => Train : 71.18021568627451, Val : 71.23255555555556\n",
            "Epoch 362 ------> Error => Train : 71.1747843137255, Val : 71.21411111111111\n",
            "Epoch 363 ------> Error => Train : 71.12890196078432, Val : 71.10544444444444\n",
            "Epoch 364 ------> Error => Train : 71.14088235294118, Val : 71.10144444444444\n",
            "Epoch 365 ------> Error => Train : 71.09576470588235, Val : 70.95666666666666\n",
            "Epoch 366 ------> Error => Train : 71.04517647058823, Val : 70.95044444444444\n",
            "Epoch 367 ------> Error => Train : 70.99911764705882, Val : 71.00311111111111\n",
            "Epoch 368 ------> Error => Train : 70.97300000000001, Val : 71.04588888888888\n",
            "Epoch 369 ------> Error => Train : 70.91733333333333, Val : 70.84311111111111\n",
            "Epoch 370 ------> Error => Train : 70.905, Val : 70.73244444444444\n",
            "Epoch 371 ------> Error => Train : 70.74682352941176, Val : 70.99511111111111\n",
            "Epoch 372 ------> Error => Train : 70.86349019607843, Val : 70.81366666666668\n",
            "Epoch 373 ------> Error => Train : 70.80941176470589, Val : 70.793\n",
            "Epoch 374 ------> Error => Train : 70.75156862745098, Val : 70.66588888888889\n",
            "Epoch 375 ------> Error => Train : 70.70009803921569, Val : 70.62411111111112\n",
            "Epoch 376 ------> Error => Train : 70.66327450980393, Val : 70.60900000000001\n",
            "Epoch 377 ------> Error => Train : 70.60382352941176, Val : 70.64111111111112\n",
            "Epoch 378 ------> Error => Train : 70.61907843137256, Val : 70.60644444444445\n",
            "Epoch 379 ------> Error => Train : 70.55633333333333, Val : 70.51844444444444\n",
            "Epoch 380 ------> Error => Train : 70.52154901960785, Val : 70.60966666666667\n",
            "Epoch 381 ------> Error => Train : 70.50621568627452, Val : 70.528\n",
            "Epoch 382 ------> Error => Train : 70.43243137254902, Val : 70.47311111111111\n",
            "Epoch 383 ------> Error => Train : 70.42976470588236, Val : 70.38644444444444\n",
            "Epoch 384 ------> Error => Train : 70.48245098039216, Val : 70.35466666666667\n",
            "Epoch 385 ------> Error => Train : 70.40015686274509, Val : 70.38222222222223\n",
            "Epoch 386 ------> Error => Train : 70.30725490196079, Val : 70.42766666666667\n",
            "Epoch 387 ------> Error => Train : 70.3640588235294, Val : 70.27222222222221\n",
            "Epoch 388 ------> Error => Train : 70.22707843137255, Val : 70.39066666666666\n",
            "Epoch 389 ------> Error => Train : 70.21256862745099, Val : 70.35777777777778\n",
            "Epoch 390 ------> Error => Train : 70.24570588235295, Val : 70.14622222222224\n",
            "Epoch 391 ------> Error => Train : 70.2101568627451, Val : 70.179\n",
            "Epoch 392 ------> Error => Train : 70.1224705882353, Val : 70.06188888888889\n",
            "Epoch 393 ------> Error => Train : 70.11335294117646, Val : 70.126\n",
            "Epoch 394 ------> Error => Train : 70.14888235294117, Val : 70.13355555555555\n",
            "Epoch 395 ------> Error => Train : 70.08988235294117, Val : 70.02622222222222\n",
            "Epoch 396 ------> Error => Train : 69.99458823529412, Val : 70.104\n",
            "Epoch 397 ------> Error => Train : 69.95723529411765, Val : 69.90766666666667\n",
            "Epoch 398 ------> Error => Train : 69.98437254901961, Val : 70.03133333333334\n",
            "Epoch 399 ------> Error => Train : 69.88337254901961, Val : 69.86155555555555\n",
            "Epoch 400 ------> Error => Train : 69.89494117647058, Val : 69.875\n",
            "Epoch 401 ------> Error => Train : 69.87794117647059, Val : 69.84077777777777\n",
            "Epoch 402 ------> Error => Train : 69.85243137254902, Val : 69.90588888888888\n",
            "Epoch 403 ------> Error => Train : 69.81545098039216, Val : 69.79633333333334\n",
            "Epoch 404 ------> Error => Train : 69.74376470588236, Val : 69.84444444444443\n",
            "Epoch 405 ------> Error => Train : 69.72096078431372, Val : 69.721\n",
            "Epoch 406 ------> Error => Train : 69.68652941176471, Val : 69.66288888888889\n",
            "Epoch 407 ------> Error => Train : 69.65229411764706, Val : 69.61733333333333\n",
            "Epoch 408 ------> Error => Train : 69.63233333333334, Val : 69.71677777777778\n",
            "Epoch 409 ------> Error => Train : 69.62954901960785, Val : 69.65311111111112\n",
            "Epoch 410 ------> Error => Train : 69.55521568627451, Val : 69.61244444444444\n",
            "Epoch 411 ------> Error => Train : 69.54701960784314, Val : 69.54033333333334\n",
            "Epoch 412 ------> Error => Train : 69.49292156862745, Val : 69.61433333333335\n",
            "Epoch 413 ------> Error => Train : 69.46039215686274, Val : 69.55022222222223\n",
            "Epoch 414 ------> Error => Train : 69.47009803921569, Val : 69.44688888888889\n",
            "Epoch 415 ------> Error => Train : 69.415, Val : 69.49888888888889\n",
            "Epoch 416 ------> Error => Train : 69.36276470588236, Val : 69.41422222222222\n",
            "Epoch 417 ------> Error => Train : 69.35809803921569, Val : 69.35188888888888\n",
            "Epoch 418 ------> Error => Train : 69.34323529411765, Val : 69.35055555555556\n",
            "Epoch 419 ------> Error => Train : 69.33576470588235, Val : 69.276\n",
            "Epoch 420 ------> Error => Train : 69.29425490196078, Val : 69.37533333333333\n",
            "Epoch 421 ------> Error => Train : 69.32150980392157, Val : 69.25833333333334\n",
            "Epoch 422 ------> Error => Train : 69.18974509803921, Val : 69.23566666666667\n",
            "Epoch 423 ------> Error => Train : 69.1878431372549, Val : 69.35455555555555\n",
            "Epoch 424 ------> Error => Train : 69.17398039215686, Val : 69.29444444444445\n",
            "Epoch 425 ------> Error => Train : 69.17792156862745, Val : 69.19800000000001\n",
            "Epoch 426 ------> Error => Train : 69.07541176470588, Val : 69.22966666666667\n",
            "Epoch 427 ------> Error => Train : 69.11207843137254, Val : 69.024\n",
            "Epoch 428 ------> Error => Train : 69.02809803921569, Val : 69.01722222222222\n",
            "Epoch 429 ------> Error => Train : 69.03688235294118, Val : 68.95566666666667\n",
            "Epoch 430 ------> Error => Train : 68.96788235294117, Val : 68.93577777777777\n",
            "Epoch 431 ------> Error => Train : 68.96376470588235, Val : 68.9228888888889\n",
            "Epoch 432 ------> Error => Train : 68.91858823529412, Val : 68.932\n",
            "Epoch 433 ------> Error => Train : 68.93070588235295, Val : 68.87766666666667\n",
            "Epoch 434 ------> Error => Train : 68.89878431372549, Val : 69.02644444444445\n",
            "Epoch 435 ------> Error => Train : 68.89303921568627, Val : 68.90566666666666\n",
            "Epoch 436 ------> Error => Train : 68.78072549019609, Val : 68.83611111111111\n",
            "Epoch 437 ------> Error => Train : 68.82345098039215, Val : 68.79477777777778\n",
            "Epoch 438 ------> Error => Train : 68.78721568627451, Val : 68.77211111111112\n",
            "Epoch 439 ------> Error => Train : 68.7634705882353, Val : 68.70177777777778\n",
            "Epoch 440 ------> Error => Train : 68.69703921568626, Val : 68.74711111111111\n",
            "Epoch 441 ------> Error => Train : 68.66580392156862, Val : 68.66633333333333\n",
            "Epoch 442 ------> Error => Train : 68.6291568627451, Val : 68.70422222222223\n",
            "Epoch 443 ------> Error => Train : 68.61403921568629, Val : 68.72844444444445\n",
            "Epoch 444 ------> Error => Train : 68.50949019607843, Val : 68.60022222222221\n",
            "Epoch 445 ------> Error => Train : 68.62603921568626, Val : 68.696\n",
            "Epoch 446 ------> Error => Train : 68.50350980392156, Val : 68.54033333333334\n",
            "Epoch 447 ------> Error => Train : 68.5285294117647, Val : 68.582\n",
            "Epoch 448 ------> Error => Train : 68.51313725490196, Val : 68.47677777777778\n",
            "Epoch 449 ------> Error => Train : 68.4604705882353, Val : 68.49222222222222\n",
            "Epoch 450 ------> Error => Train : 68.477, Val : 68.54744444444444\n",
            "Epoch 451 ------> Error => Train : 68.4531568627451, Val : 68.57833333333333\n",
            "Epoch 452 ------> Error => Train : 68.37556862745097, Val : 68.32322222222223\n",
            "Epoch 453 ------> Error => Train : 68.34619607843138, Val : 68.40333333333334\n",
            "Epoch 454 ------> Error => Train : 68.30598039215687, Val : 68.41522222222221\n",
            "Epoch 455 ------> Error => Train : 68.33260784313725, Val : 68.52822222222223\n",
            "Epoch 456 ------> Error => Train : 68.34717647058824, Val : 68.28866666666667\n",
            "Epoch 457 ------> Error => Train : 68.21194117647059, Val : 68.32444444444445\n",
            "Epoch 458 ------> Error => Train : 68.23896078431373, Val : 68.28255555555555\n",
            "Epoch 459 ------> Error => Train : 68.16535294117647, Val : 68.25111111111111\n",
            "Epoch 460 ------> Error => Train : 68.16535294117647, Val : 68.0611111111111\n",
            "Epoch 461 ------> Error => Train : 68.15972549019608, Val : 68.08944444444444\n",
            "Epoch 462 ------> Error => Train : 68.13474509803922, Val : 68.07277777777777\n",
            "Epoch 463 ------> Error => Train : 68.102, Val : 68.06077777777777\n",
            "Epoch 464 ------> Error => Train : 68.09972549019608, Val : 67.98455555555556\n",
            "Epoch 465 ------> Error => Train : 68.05158823529412, Val : 68.21933333333334\n",
            "Epoch 466 ------> Error => Train : 68.06484313725491, Val : 68.07711111111111\n",
            "Epoch 467 ------> Error => Train : 68.0261568627451, Val : 68.01677777777778\n",
            "Epoch 468 ------> Error => Train : 67.90188235294119, Val : 68.119\n",
            "Epoch 469 ------> Error => Train : 67.9523137254902, Val : 68.0441111111111\n",
            "Epoch 470 ------> Error => Train : 67.88841176470588, Val : 68.06766666666667\n",
            "Epoch 471 ------> Error => Train : 67.87641176470588, Val : 67.959\n",
            "Epoch 472 ------> Error => Train : 67.81839215686274, Val : 67.95666666666666\n",
            "Epoch 473 ------> Error => Train : 67.78837254901961, Val : 67.78399999999999\n",
            "Epoch 474 ------> Error => Train : 67.82198039215686, Val : 67.91133333333333\n",
            "Epoch 475 ------> Error => Train : 67.80958823529411, Val : 67.84077777777777\n",
            "Epoch 476 ------> Error => Train : 67.75903921568627, Val : 67.89422222222223\n",
            "Epoch 477 ------> Error => Train : 67.7243137254902, Val : 67.75822222222223\n",
            "Epoch 478 ------> Error => Train : 67.75550980392157, Val : 67.78744444444445\n",
            "Epoch 479 ------> Error => Train : 67.72739215686275, Val : 67.8111111111111\n",
            "Epoch 480 ------> Error => Train : 67.7005294117647, Val : 67.72288888888889\n",
            "Epoch 481 ------> Error => Train : 67.62870588235295, Val : 67.68788888888889\n",
            "Epoch 482 ------> Error => Train : 67.67384313725489, Val : 67.66955555555556\n",
            "Epoch 483 ------> Error => Train : 67.58141176470588, Val : 67.69411111111111\n",
            "Epoch 484 ------> Error => Train : 67.5765294117647, Val : 67.70488888888889\n",
            "Epoch 485 ------> Error => Train : 67.57556862745099, Val : 67.691\n",
            "Epoch 486 ------> Error => Train : 67.58764705882353, Val : 67.77166666666666\n",
            "Epoch 487 ------> Error => Train : 67.52456862745099, Val : 67.50711111111112\n",
            "Epoch 488 ------> Error => Train : 67.49039215686274, Val : 67.57933333333332\n",
            "Epoch 489 ------> Error => Train : 67.47870588235294, Val : 67.48155555555556\n",
            "Epoch 490 ------> Error => Train : 67.42062745098039, Val : 67.47\n",
            "Epoch 491 ------> Error => Train : 67.37390196078431, Val : 67.5551111111111\n",
            "Epoch 492 ------> Error => Train : 67.37225490196079, Val : 67.51133333333334\n",
            "Epoch 493 ------> Error => Train : 67.39976470588235, Val : 67.57511111111111\n",
            "Epoch 494 ------> Error => Train : 67.34303921568628, Val : 67.35533333333333\n",
            "Epoch 495 ------> Error => Train : 67.34976470588235, Val : 67.40411111111112\n",
            "Epoch 496 ------> Error => Train : 67.27478431372549, Val : 67.35122222222222\n",
            "Epoch 497 ------> Error => Train : 67.28586274509803, Val : 67.32622222222221\n",
            "Epoch 498 ------> Error => Train : 67.23882352941176, Val : 67.30955555555555\n",
            "Epoch 499 ------> Error => Train : 67.231, Val : 67.4351111111111\n",
            "Epoch 500 ------> Error => Train : 67.17801960784314, Val : 67.28477777777778\n",
            "Epoch 501 ------> Error => Train : 67.15350980392157, Val : 67.06044444444444\n",
            "Epoch 502 ------> Error => Train : 67.1954705882353, Val : 67.31611111111111\n",
            "Epoch 503 ------> Error => Train : 67.0815294117647, Val : 67.19888888888889\n",
            "Epoch 504 ------> Error => Train : 67.12213725490196, Val : 67.18522222222222\n",
            "Epoch 505 ------> Error => Train : 67.11558823529413, Val : 67.01655555555556\n",
            "Epoch 506 ------> Error => Train : 67.05186274509803, Val : 67.1211111111111\n",
            "Epoch 507 ------> Error => Train : 67.06421568627451, Val : 67.13944444444444\n",
            "Epoch 508 ------> Error => Train : 66.97154901960783, Val : 67.12188888888889\n",
            "Epoch 509 ------> Error => Train : 67.01866666666666, Val : 66.96733333333333\n",
            "Epoch 510 ------> Error => Train : 66.99070588235294, Val : 67.00777777777778\n",
            "Epoch 511 ------> Error => Train : 66.95262745098039, Val : 67.12466666666667\n",
            "Epoch 512 ------> Error => Train : 66.89076470588236, Val : 66.89444444444445\n",
            "Epoch 513 ------> Error => Train : 66.91986274509804, Val : 66.969\n",
            "Epoch 514 ------> Error => Train : 66.91539215686275, Val : 67.12111111111112\n",
            "Epoch 515 ------> Error => Train : 66.8371568627451, Val : 66.974\n",
            "Epoch 516 ------> Error => Train : 66.8491568627451, Val : 66.94222222222223\n",
            "Epoch 517 ------> Error => Train : 66.80521568627451, Val : 66.94711111111111\n",
            "Epoch 518 ------> Error => Train : 66.77876470588235, Val : 66.86533333333333\n",
            "Epoch 519 ------> Error => Train : 66.73774509803921, Val : 66.83877777777778\n",
            "Epoch 520 ------> Error => Train : 66.80443137254902, Val : 66.75266666666667\n",
            "Epoch 521 ------> Error => Train : 66.74972549019608, Val : 66.82677777777778\n",
            "Epoch 522 ------> Error => Train : 66.68723529411764, Val : 66.86555555555556\n",
            "Epoch 523 ------> Error => Train : 66.66619607843137, Val : 66.70433333333334\n",
            "Epoch 524 ------> Error => Train : 66.64998039215686, Val : 66.7328888888889\n",
            "Epoch 525 ------> Error => Train : 66.6521568627451, Val : 66.59655555555555\n",
            "Epoch 526 ------> Error => Train : 66.57413725490196, Val : 66.68844444444446\n",
            "Epoch 527 ------> Error => Train : 66.60705882352941, Val : 66.66888888888889\n",
            "Epoch 528 ------> Error => Train : 66.59472549019608, Val : 66.62899999999999\n",
            "Epoch 529 ------> Error => Train : 66.60007843137255, Val : 66.62366666666668\n",
            "Epoch 530 ------> Error => Train : 66.5301568627451, Val : 66.52566666666667\n",
            "Epoch 531 ------> Error => Train : 66.47998039215686, Val : 66.69844444444445\n",
            "Epoch 532 ------> Error => Train : 66.51794117647059, Val : 66.52955555555556\n",
            "Epoch 533 ------> Error => Train : 66.48474509803921, Val : 66.51811111111111\n",
            "Epoch 534 ------> Error => Train : 66.48101960784314, Val : 66.58555555555556\n",
            "Epoch 535 ------> Error => Train : 66.45262745098039, Val : 66.42922222222222\n",
            "Epoch 536 ------> Error => Train : 66.44327450980393, Val : 66.43988888888889\n",
            "Epoch 537 ------> Error => Train : 66.37125490196078, Val : 66.50611111111111\n",
            "Epoch 538 ------> Error => Train : 66.33645098039216, Val : 66.465\n",
            "Epoch 539 ------> Error => Train : 66.33209803921568, Val : 66.39911111111111\n",
            "Epoch 540 ------> Error => Train : 66.33229411764707, Val : 66.44311111111111\n",
            "Epoch 541 ------> Error => Train : 66.29503921568627, Val : 66.35144444444444\n",
            "Epoch 542 ------> Error => Train : 66.27980392156863, Val : 66.34922222222222\n",
            "Epoch 543 ------> Error => Train : 66.26629411764705, Val : 66.31700000000001\n",
            "Epoch 544 ------> Error => Train : 66.2271568627451, Val : 66.3351111111111\n",
            "Epoch 545 ------> Error => Train : 66.24501960784315, Val : 66.29566666666668\n",
            "Epoch 546 ------> Error => Train : 66.196, Val : 66.16244444444445\n",
            "Epoch 547 ------> Error => Train : 66.19715686274509, Val : 66.23711111111112\n",
            "Epoch 548 ------> Error => Train : 66.12825490196079, Val : 66.25133333333332\n",
            "Epoch 549 ------> Error => Train : 66.14452941176471, Val : 66.23122222222221\n",
            "Epoch 550 ------> Error => Train : 66.0631568627451, Val : 66.2188888888889\n",
            "Epoch 551 ------> Error => Train : 66.06460784313725, Val : 66.24588888888889\n",
            "Epoch 552 ------> Error => Train : 66.09135294117647, Val : 66.24544444444444\n",
            "Epoch 553 ------> Error => Train : 66.04858823529412, Val : 66.1178888888889\n",
            "Epoch 554 ------> Error => Train : 66.05658823529413, Val : 66.10522222222222\n",
            "Epoch 555 ------> Error => Train : 66.00911764705882, Val : 66.06977777777777\n",
            "Epoch 556 ------> Error => Train : 66.00935294117647, Val : 66.22722222222222\n",
            "Epoch 557 ------> Error => Train : 65.93045098039215, Val : 66.13244444444445\n",
            "Epoch 558 ------> Error => Train : 65.97045098039216, Val : 66.03177777777778\n",
            "Epoch 559 ------> Error => Train : 65.87698039215687, Val : 66.1048888888889\n",
            "Epoch 560 ------> Error => Train : 65.942, Val : 66.14977777777777\n",
            "Epoch 561 ------> Error => Train : 65.90452941176471, Val : 66.04299999999999\n",
            "Epoch 562 ------> Error => Train : 65.86558823529411, Val : 66.09722222222223\n",
            "Epoch 563 ------> Error => Train : 65.83405882352942, Val : 65.91766666666666\n",
            "Epoch 564 ------> Error => Train : 65.85707843137256, Val : 65.96966666666667\n",
            "Epoch 565 ------> Error => Train : 65.80266666666667, Val : 65.96877777777779\n",
            "Epoch 566 ------> Error => Train : 65.82113725490196, Val : 65.91433333333333\n",
            "Epoch 567 ------> Error => Train : 65.75672549019609, Val : 65.88266666666667\n",
            "Epoch 568 ------> Error => Train : 65.754, Val : 65.79400000000001\n",
            "Epoch 569 ------> Error => Train : 65.7129411764706, Val : 65.89266666666667\n",
            "Epoch 570 ------> Error => Train : 65.68033333333332, Val : 65.91522222222223\n",
            "Epoch 571 ------> Error => Train : 65.70825490196079, Val : 65.84366666666666\n",
            "Epoch 572 ------> Error => Train : 65.71447058823529, Val : 65.807\n",
            "Epoch 573 ------> Error => Train : 65.6524705882353, Val : 65.82855555555555\n",
            "Epoch 574 ------> Error => Train : 65.66535294117648, Val : 65.80811111111112\n",
            "Epoch 575 ------> Error => Train : 65.65580392156863, Val : 65.66088888888889\n",
            "Epoch 576 ------> Error => Train : 65.62411764705882, Val : 65.69955555555556\n",
            "Epoch 577 ------> Error => Train : 65.60276470588235, Val : 65.70366666666666\n",
            "Epoch 578 ------> Error => Train : 65.57176470588234, Val : 65.61177777777777\n",
            "Epoch 579 ------> Error => Train : 65.4991568627451, Val : 65.59555555555556\n",
            "Epoch 580 ------> Error => Train : 65.56878431372549, Val : 65.70844444444444\n",
            "Epoch 581 ------> Error => Train : 65.53, Val : 65.65044444444445\n",
            "Epoch 582 ------> Error => Train : 65.46988235294117, Val : 65.678\n",
            "Epoch 583 ------> Error => Train : 65.48398039215687, Val : 65.65488888888889\n",
            "Epoch 584 ------> Error => Train : 65.47956862745099, Val : 65.51055555555556\n",
            "Epoch 585 ------> Error => Train : 65.4756862745098, Val : 65.53666666666666\n",
            "Epoch 586 ------> Error => Train : 65.42556862745099, Val : 65.52277777777778\n",
            "Epoch 587 ------> Error => Train : 65.38503921568628, Val : 65.44944444444444\n",
            "Epoch 588 ------> Error => Train : 65.3902156862745, Val : 65.47344444444445\n",
            "Epoch 589 ------> Error => Train : 65.37031372549019, Val : 65.42988888888888\n",
            "Epoch 590 ------> Error => Train : 65.36768627450981, Val : 65.56633333333333\n",
            "Epoch 591 ------> Error => Train : 65.30405882352942, Val : 65.53855555555556\n",
            "Epoch 592 ------> Error => Train : 65.3020588235294, Val : 65.40622222222223\n",
            "Epoch 593 ------> Error => Train : 65.25917647058824, Val : 65.39666666666668\n",
            "Epoch 594 ------> Error => Train : 65.27894117647058, Val : 65.36822222222222\n",
            "Epoch 595 ------> Error => Train : 65.21174509803922, Val : 65.36211111111112\n",
            "Epoch 596 ------> Error => Train : 65.23480392156864, Val : 65.43588888888888\n",
            "Epoch 597 ------> Error => Train : 65.22645098039216, Val : 65.32077777777778\n",
            "Epoch 598 ------> Error => Train : 65.21501960784315, Val : 65.2941111111111\n",
            "Epoch 599 ------> Error => Train : 65.19927450980393, Val : 65.21066666666667\n",
            "Epoch 600 ------> Error => Train : 65.1690980392157, Val : 65.22444444444444\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "-Yefr5jKS7AT",
        "outputId": "a3db9083-b551-4afd-a128-add28c54b019"
      },
      "source": [
        "fig = plt.figure()\n",
        "plt.plot(train_loss, c='r', label=\"Train\")\n",
        "plt.plot(val_loss, c='g', label=\"Val\")\n",
        "plt.legend()\n",
        "plt.title(\"Reconstruction Error\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Error\")"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Error')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0MePRvw4a6TT",
        "outputId": "bf8db68b-d93b-45c5-faad-f8183171afc9"
      },
      "source": [
        "err = rbm.reconstruction_error(test.T)\n",
        "\n",
        "print(\"Reconstruction error using original RBM : \", err)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:35: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Reconstruction error using original RBM :  65.7017\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lol-hyPcBByF"
      },
      "source": [
        "# Test data image reconstruction\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        },
        "id": "mHybMXHyBAKH",
        "outputId": "ffd2c6b2-758e-4944-bdf1-5480c0f82891"
      },
      "source": [
        "print(\"\\n\\nOriginal Images ....\")\n",
        "fig1 = plt.figure()\n",
        "for i in range(9):\n",
        "  plt.subplot(3,3,i+1)\n",
        "  plt.tight_layout()\n",
        "  plt.imshow(test[i].reshape((28,28)), cmap='gray', interpolation='none')\n",
        "  plt.title(\"Label: {}\".format(test_y[i]))\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Original Images ....\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 9 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "kLQRDTvgBh_Z",
        "outputId": "8748ed91-08b8-4fca-daf2-1e9567312a8b"
      },
      "source": [
        "print(\"\\n\\nSampled images....\")\n",
        "fig2 = plt.figure()\n",
        "for i in range(9):\n",
        "  plt.subplot(3,3,i+1)\n",
        "  plt.tight_layout()\n",
        "\n",
        "  # 1 step sampling\n",
        "  img = rbm.reconstruct_image(test[i].T.reshape((784,1)))\n",
        "\n",
        "  plt.imshow(img.reshape((28,28)), cmap='gray', interpolation='none')\n",
        "  plt.title(\"Label: {}\".format(test_y[i]))\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Sampled images....\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:35: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 9 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}