{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DeepBeliefNetwork_FashionMNIST.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPEXGn5qN6TpXkcyljqrNSB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GangaMegha/Generative-Models/blob/main/DeepBeliefNetwork_FashionMNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ayR5fsPyUxX1"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Import MNIST data\n",
        "import tensorflow as tf\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0x0WT2okU7Qd"
      },
      "source": [
        "## RBM Class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gebftx4nU_Rv"
      },
      "source": [
        "class RBM():\n",
        "    def __init__(self, num_hidden, num_visible, lr, n, batch_size, epochs):\n",
        "        self.num_hidden = num_hidden\n",
        "        self.num_visible = num_visible\n",
        "        self.lr = lr\n",
        "        self.n = n\n",
        "        self.batch_size = batch_size\n",
        "        self.epochs = epochs\n",
        "\n",
        "        self.W = np.random.randn(num_hidden, num_visible)/np.sqrt(0.5*(num_visible + num_hidden)) # weights\n",
        "\n",
        "        self.b_h = np.zeros((num_hidden, 1)) # bias latent\n",
        "        self.b_v = np.zeros((num_visible, 1)) # bias visible\n",
        "\n",
        "        self.dW = []\n",
        "        self.db_h = []\n",
        "        self.db_v = []\n",
        "\n",
        "    def sigmoid(self, x):  \n",
        "        #Sigmoid activation \n",
        "        #Implemented interms  of tanh for increased stability\n",
        "        return .5 * (1 + np.tanh(.5 * x))\n",
        "\n",
        "    \n",
        "    def bernoulli_array(self, prob_array, dim):\n",
        "        # Simulating Bernoulli from uniform\n",
        "        sample = np.zeros(dim)\n",
        "\n",
        "        # Draw x~Uni[0,1]\n",
        "        uni_sample = np.random.uniform(0, 1, dim)\n",
        "\n",
        "        # return 1 if x < p else return 0\n",
        "        diff = uni_sample - prob_array\n",
        "        coords = np.argwhere(diff<0)\n",
        "        sample[[*coords.T]] = 1  \n",
        "\n",
        "        return sample\n",
        "\n",
        "    def gibbs_sampling(self, h_0):\n",
        "\n",
        "        h = h_0.copy()\n",
        "\n",
        "        for i in range(self.n):\n",
        "\n",
        "            # (v x h) @ (h x b) + (v x 1) = (v x b)\n",
        "            p_v_h = self.sigmoid(self.W.T @ h + self.b_v)\n",
        "            v = self.bernoulli_array(p_v_h, (p_v_h.shape[0], p_v_h.shape[1]))\n",
        "\n",
        "            # (h x v) @ (v x b) + (h x 1) = (h x b)\n",
        "            p_h_v = self.sigmoid(self.W @ v + self.b_h)\n",
        "            h = self.bernoulli_array(p_h_v, (p_h_v.shape[0], p_h_v.shape[1]))\n",
        "\n",
        "        return v, h, p_h_v\n",
        "\n",
        "    def hidden_to_visible(self, h):\n",
        "\n",
        "        h = h.T.copy()\n",
        "\n",
        "        # (v x h) @ (h x b) + (v x 1) = (v x b)\n",
        "        p_v_h = self.sigmoid(self.W.T @ h + self.b_v)\n",
        "        v = self.bernoulli_array(p_v_h, (p_v_h.shape[0], p_v_h.shape[1]))\n",
        "\n",
        "        return v.T\n",
        "\n",
        "    def visible_to_hidden(self, v):\n",
        "\n",
        "        v = v.T.copy()\n",
        "\n",
        "        # (h x v) @ (v x b) + (h x 1) = (h x b)\n",
        "        p_h_v = self.sigmoid(self.W @ v + self.b_h)\n",
        "        h = self.bernoulli_array(p_h_v, (p_h_v.shape[0], p_h_v.shape[1]))\n",
        "\n",
        "        return h.T\n",
        "\n",
        "    def gradient_descent(self, v_0, p_h_v_0, v_n, p_h_v_n):\n",
        "\n",
        "        # Compute the gradients\n",
        "        # (h x b) @ (b x v) - (h x b) @ (b x v) = (h x v)\n",
        "        self.dW = (p_h_v_0 @ v_0 - p_h_v_n @ v_n)/self.batch_size\n",
        "        self.db_h = np.mean(p_h_v_0 - p_h_v_n, axis=1)[:, np.newaxis]\n",
        "        self.db_v = np.mean(v_0 - v_n, axis=0)[:, np.newaxis]\n",
        "        \n",
        "        # Weight update\n",
        "        self.W   = self.W   + self.lr * self.dW\n",
        "        self.b_h = self.b_h + self.lr * self.db_h\n",
        "        self.b_v = self.b_v + self.lr * self.db_v\n",
        "\n",
        "\n",
        "    def reconstruction_error(self, v):\n",
        "        # Sample hidden state\n",
        "        p_h_v = self.sigmoid(self.W @ v + self.b_h)\n",
        "        h = self.bernoulli_array(p_h_v, (p_h_v.shape[0], p_h_v.shape[1]))\n",
        "\n",
        "        # Sample viible state\n",
        "        p_v_h = self.sigmoid(self.W.T @ h + self.b_v)\n",
        "        v_sampled = self.bernoulli_array(p_v_h, (p_v_h.shape[0], p_v_h.shape[1]))    \n",
        "\n",
        "        return np.sum(np.mean((v-v_sampled)**2, axis=1), axis=0)\n",
        "\n",
        "\n",
        "    def reconstruct_image(self, v):\n",
        "        # Sample hidden state\n",
        "        p_h_v = self.sigmoid(self.W @ v + self.b_h)\n",
        "        h = self.bernoulli_array(p_h_v, (p_h_v.shape[0], p_h_v.shape[1]))\n",
        "\n",
        "        # Sample viible state\n",
        "        p_v_h = self.sigmoid(self.W.T @ h + self.b_v)\n",
        "        v_sampled = self.bernoulli_array(p_v_h, (p_v_h.shape[0], p_v_h.shape[1]))    \n",
        "\n",
        "        return v_sampled\n",
        "\n",
        "\n",
        "    def Train(self, train, val):\n",
        "\n",
        "        num_batches = int(train.shape[0]/self.batch_size)\n",
        "        train_loss = []\n",
        "        val_loss = []\n",
        "\n",
        "        for epoch in range(self.epochs):\n",
        "\n",
        "            # Shuffling the data\n",
        "            train = np.random.permutation(train)\n",
        "\n",
        "            # Splitting data into batches\n",
        "            batches = np.array_split(train, num_batches)\n",
        "\n",
        "            for i in range(num_batches):\n",
        "\n",
        "                # visible units from data\n",
        "                v_0 = batches[i].T\n",
        "\n",
        "                # (h x v) @ (v x b) + (h x 1) = (h x b)\n",
        "                p_h_v_0 = self.sigmoid(self.W @ v_0 + self.b_h)\n",
        "                h_0 = self.bernoulli_array(p_h_v_0, (p_h_v_0.shape[0], p_h_v_0.shape[1]))\n",
        "\n",
        "                # Run the markov chain\n",
        "                v_n, h_n, p_h_v_n = self.gibbs_sampling(h_0)\n",
        "\n",
        "                # Compute gradients\n",
        "                self.gradient_descent(v_0.T, p_h_v_0, v_n.T, p_h_v_n)\n",
        "\n",
        "            # Compute reconstruction errror\n",
        "            error_train = self.reconstruction_error(train.T)\n",
        "            error_val = self.reconstruction_error(val.T)\n",
        "\n",
        "            print(f\"Epoch {epoch+1} ------> Error => Train : {error_train}, Val : {error_val}\")\n",
        " \n",
        "            train_loss.append(error_train)\n",
        "            val_loss.append(error_val)\n",
        "\n",
        "        return train_loss, val_loss\n",
        "\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jCLP9TmvwiOn"
      },
      "source": [
        "# Fashion MNIST Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 512
        },
        "id": "2WS8CGYJXy3B",
        "outputId": "6beb501d-334f-4156-a655-9fb60ce2d0a0"
      },
      "source": [
        "# Load MNIST data\n",
        "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
        "(train, train_y), (test, test_y) = fashion_mnist.load_data()\n",
        "\n",
        "train = train.copy()\n",
        "train_y = train_y.copy()\n",
        "\n",
        "test = test.copy()\n",
        "test_y = test_y.copy()\n",
        "\n",
        "# Converting to binary\n",
        "train[[*np.argwhere(train>0).T]] = 1\n",
        "test[[*np.argwhere(test>0).T]] = 1\n",
        "\n",
        "\n",
        "fig = plt.figure()\n",
        "for i in range(9):\n",
        "  plt.subplot(3,3,i+1)\n",
        "  plt.tight_layout()\n",
        "  plt.imshow(train[i], cmap='gray', interpolation='none')\n",
        "  plt.title(\"Label: {}\".format(train_y[i]))\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "8192/5148 [===============================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:12: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
            "  if sys.path[0] == '':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:13: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
            "  del sys.path[0]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVUAAAELCAYAAABpiBWpAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAATdElEQVR4nO3df6xkdXnH8c+HZQOuIj9cQhG4tNBIg23A3k2ggdCNkIA1RBNK00QKBDHtHw3VgtEaCYhQjf9oiKk1xF+AadNCE1JATGPcaqSG7I3dWppgUsuy2CzdxV0WkMivp3+cue0wO3NnzpnnzPnOzPuVTHbm7pxzvuee5z7nOd/zPec4IgQAyHFE1w0AgEVCUgWARCRVAEhEUgWARCRVAEhEUgWARJ0mVds7bF8/62lRLmICg+YtJlKSqu0nbV+SMa822D7K9udt/7ftA7b/yvbmrtu1yEqPCUmy/RHbe20fsv1V20d13aZFtiwxsSyH/x+XtE3Sb0p6h6TflvTJTluETtm+VFVcXCzpdElnSPpUp41Cp7JiotWkavt42w/a3terEB+0ferA1860/Vhvz/CA7RP6pj/f9qO2D9reZXt7w6ZcLunOiPh5ROyTdKek6xrOC1MoKCaukfSViHg8Ig5I+rSkaxvOC1NYtJhou1I9QtLXVGX9FUkvSfriwHeuVpXgTpb0qqqEJ9unSHpI0u2STpB0k6T7bZ84uBDbK71f6MoGbfHA+1NtH9tkpTCVUmLinZJ29X3eJekk229ruF5obqFiotWkGhHPRsT9EfGLiHhe0h2Sfnfga/dExL9HxIuSbpb0B7Y3SbpK0sMR8XBEvB4R/yRpp6TfG7KcpyLiuIh4akRTHpH0Z7ZPtP0rkm7o/XxLwmqihoJi4i2Snuv7vP7+mClWDw0sWkwcWefLddneIunzki6TdHzvx8fY3hQRr/U+7+mbZLekzZK2qtprXWn78r7/3yzpuw2acoek4yT9q6RfSrpL0rskPdNgXphCQTHxgqS39n1ef/98g3lhCosWE20f/t8o6SxJ50XEWyVd1Pt5/6H4aX3vVyS9Imm/ql/iPb09y/rrzRHx2bqNiIiXIuJPI+KUiDhD0rOS1iLi9SYrhakUEROSHpd0Tt/ncyQ9ExHPNpgXprNQMZGZVDfbPrrvdaSqsvklSQd7Hcu3DJnuKttn9/ZWt0m6r7d3ulfS5bYvtb2pN8/tQzqwx7J9iu23u3K+qsOHYW1BrmJjQtLdkj7YW85xqkaDfL3JSqKWxY+JiJj6JelJSTHwul3S2yXtUFVW/0TSH/f+78jedDskfUbSY5IOSfpHSVv75nuepH+W9HNJ+1R1SK/0TXt97/1KbxkrI9p3Ua+Nv5D0hKQPZKw3r/mNid53/lxVF9AhVSdKjur697bIr2WJCfdmBABIsCyD/wFgJkiqAJCIpAoAiUiqAJCIpAoAiWpdUWV7KYYKRITHfwvS5DGxuroqSVpbW5v4u1kmWeYE9kfEYdeT43CZeWJULEy6TaedfoyhMVFrSBVJFYMmjYn1OLPH/2qzh/lNsswJrEXEtowZLbrMPDEqFibdptNOP8bQmGj12n8sr8EkOhjEsxwfvdGykv64kGxcfJQ8vp4+VQBIRKWKVnRZmdZRp1sCs7O+PUqNm41QqQJAouIq1VGVw+Aeq+7/b7SsOtNgMVGxIguVKgAkKq5SHTSqT6VOlTnpsIqI0LZtjJrJNI99YsA0qFQBIFHxleqkNqpcR1Wx9KkCyEalCgCJiqtUs6rFJn159KmWYdQYxbpjF5uMdWQUAKZFpQoAiYqpVAcrBM4aYxAxgXlApQoAiUiqAJCos8P/Eg/lODmRp8TtC8wClSoAJOqsUqUqxChZVS7VMrpApQoAiUiqAJCIpAoAiYo5+1/CoH8uU81T+uNU6NMvW9vx0ublyFSqAJCo87P/pVUwaEfplSuWS5tHKlSqAJCo8z7Vkvq2SmrLoij9RuCltw/zh0oVABJNVanWvVnwuJ9h8cxL3znxuFw4+w8Ac6JRpZqR5UuvXACgCSpVAEjUqFKd9JHPwCj9MUTcYJFQqQJAoqn6VAEAb0SlCgCJaiXV1dVVqlQA2ACVKgAkIqn2iQitrq523QwAc4ykCgCJSKoAkIikCgCJSKoAkIikCgCJSKoAkKhWUl1bW+NmvmjENrGDpUClCgCJprr136Jdskol1Z4SH/QItIFKFQASTXVDlfV+snnvL5v39gMoB5UqACSq1ac67ux/5mNWqBwXS6nbs9R2YX5RqQJAokZn/+uiGkCpGJVQprZHGLW5valUASDRTCpVoNSKsLT2oDIuXupWsIPzaTMeqVQBIFHdSnW/pN1tNKQgp3fdgDkzUUw0GTVSGOJiclPniXExMW3MJMXc0Jjwol1qCgBd4vAfABKRVAEgEUkVABKRVAEgEUkVABKRVAEgEUkVABKRVAEgEUkVABKRVAEgEUkVABKRVAEgUadJ1fYO29fPelqUi5jAoHmLiZSkavtJ25dkzKsNtv/Q9hO2n7P9P7a/YfutXbdrkZUeE5Jk+yO299o+ZPurto/quk2LrPSYsH2N7bVePDxt+3O2a9/If1kO/38g6YKIOFbSGaruI3t7t01Cl2xfKunjki5WdV/MMyR9qtNGoWtbJH1Y0lZJ56mKjZvqzqTVpGr7eNsP2t5n+0Dv/akDXzvT9mO9vcMDtk/om/5824/aPmh7l+3tTdoREXsiYn/fj16T9OtN5oXplBITkq6R9JWIeDwiDkj6tKRrG84LUyglJiLiSxHx/Yh4OSJ+Jumbki6oO5+2K9UjJH1NVSWwIuklSV8c+M7Vkq6TdLKkVyXdKUm2T5H0kKqK8gRVe4z7bZ84uBDbK71f6Mqohti+0PZzkp6XdIWkL0y3amiolJh4p6RdfZ93STrJ9tsarheaKyUmBl0k6fHaaxMRU78kPSnpkgm+d66kA32fd0j6bN/nsyW9LGmTpI9Jumdg+m9LuqZv2usbtPUUSbdKekfGuvOaz5iQ9J+SLuv7vFlSSPrVrn93i/oqPSYG5nGdpKclba07bduH/1tsf9n2btuHJH1P0nG2N/V9bU/f+92qgnurqr3Wlb09y0HbByVdqGpP1VhUZf0jkv52mvmgmYJi4gVJ/Scr198/32BemEJBMbHenvdL+oyk98Qbuw0n0vYjqm+UdJak8yJir+1zJf1IUv9Tt07re78i6RVVDw7bo2oP9KEW2nWkpDNbmC/GKyUmHpd0jqS/630+R9IzEfFswrxRTykxIduXSbpL0nsj4sdN5pFZqW62fXTf60hJx6jqHznY61i+Zch0V9k+2/YWSbdJui8iXpN0r6TLbV9qe1NvntuHdGCPZfsD6/0otk+XdIek7zRcT0yu2JiQdLekD/aWc5ykT0r6epOVRC3FxoTtd6s6OXVFRDzWdAUzk+rDqn4x669bVZ0MepOqPcoPVR12D7pHVTDvlXS0pBuk6oy9pPdJ+oSkfar2SB8d1uZeB/QLG3RAny3pUdsvqhpe9YSkNipgvFGxMRERj0j6nKTvSnpK1SHlsD9m5Co2JiTdLOlYSQ/3vveC7W/VXUEeUQ0AiZZl8D8AzARJFQASkVQBIBFJFQASkVQBIFGtwf+2px4qsLq6Ou0shlpbW0ubV0R4/Lcg5cRElvXYyoyFPvsj4rDryXG4cTFRZztl54uNltkgfobGRKtXVHU5XMsmL86LcXEyaltOGl9JsbA7YybLbH17DW6PUoZ1NoiToTHB4T8AJGqlUi1hz9PfBqrW+dY0ntjuZSshT/QbVUnXRaUKAInavktVEbL2QOjW+vYrrcLBZObl72/afEGlCgCJlqJSnZc9JLAMFv1Ig0oVABK1UqnS94U2EE+YB1SqAJCo1T7VLitW+lEBdIFKFQAStXpFVRfVIhUqULY6R7DT3vdh1HzaPHqmUgWARCRVAEjU6pCqYZ8ZFgMstzo5ICtf1JkPN1QBgIIsxWWqKBsXi6Akg3FYt3KlUgWARDN5nEoXw5y4STWAaXDrPwAoAEkVAIaIiEb9/CRVAEhEUgWARCRVAEg0k1v/AcCyoFIFgEQLO06VKhlAF6hUASARfaroHNf8Y5FQqQJAooVLqsOugmh6ZQTmG9sdXVi4pAoAXZrJg/+6rhbo2wXKtyhPCKFSBYBEM3lGVRe4nyqALlCpAkAikioWHqMAMEskVQBINJNr/4FBxMbyWZZtTqUKAImWIqnSpwZgVpYiqQLArJBUASARSRUAEpFUASARSRVzxzaXHqNYJFUASNTq4H8AKFkbtxukUgWARFSq6MSi3JAYGESlCgCJqFSx8BgpMH/meZtRqQJAoplUqsP6z8Y9FHCe91SoZ3BbT9vHSuyUqc6DQAe/M0/blEoVABLVrVT3S9o96ZeH7V0Gf1bgHuj0rhswZ2rFxCQmjYkZxw5xMbkNY2KS7dZFXmiwzKExYYazAEAeDv8BIBFJFQASkVQBIBFJFQASkVQBIBFJFQASkVQBIBFJFQASkVQBIBFJFQASkVQBIBFJFQASkVQBIFGnSdX2DtvXz3palIuYwKB5i4mUpGr7SduXZMyrDbb/2vYLfa9f2n6+63YtsjmIiWtsr9k+ZPtp25+zzTPbWjQHMXGt7dcGcsX2uvNZisP/iPiTiHjL+kvS30j6+67bhU5tkfRhSVslnSfpYkk3ddoilOBf+nNFROyoO4NWk6rt420/aHuf7QO996cOfO1M24/1KoYHbJ/QN/35th+1fdD2riZ7jSFterOkKyR9Y9p5ob5SYiIivhQR34+IlyPiZ5K+KemC5muGpkqJiSxtV6pHSPqaqscOrEh6SdIXB75ztaTrJJ0s6VVJd0qS7VMkPSTpdkknqKoi7rd94uBCbK/0fqErE7TpCkn7JH2vyQphaiXGhCRdJOnx2muDDCXFxLts77f9E9s3N+oSioipX5KelHTJBN87V9KBvs87JH227/PZkl6WtEnSxyTdMzD9tyVd0zft9Q3a+h1Jt2asN6+FiYnrJD0taWvXv7dFfpUeE5LOkPRrqpL8b0n6D0l/UXc92z7832L7y7Z32z6kqjo8zvamvq/t6Xu/W9JmVf1cp0u6srdnOWj7oKQLVe2pmrZnRdJ2SXc3nQemU2BMvF/SZyS9JyL2N50PmislJiLipxHxXxHxekT8WNJtkn6/7nzaPtt5o6SzJJ0XEXttnyvpR5L6H1t4Wt/7FUmvqHoa4x5Ve6APJbbnjyT9ICJ+mjhP1FNMTNi+TNJdkt7b+yNCN4qJiQEx0IaJZFaqm20f3fc6UtIxqvpHDvY6lm8ZMt1Vts+2vUXVnuG+iHhN0r2SLrd9qe1NvXluH9KBXcfVkr4+xfSop9iYsP1uVSenroiIxxqvIeoqOSbeY/uk3vvfkHSzpAfqziczqT6s6hez/rpV0hckvUnVHuWHkh4ZMt09qhLdXklHS7pBkiJij6T3SfqEqhNLeyR9dFibex3QL2zUAW37dySdKoZSzVLJMXGzpGMlPez/H5P4rUZriTpKjomLJf2b7Rd77fwHSX9ZdwXd66AFACRYisH/ADArJFUASERSBYBEJFUASERSBYBEtQb/216KoQIRUXvA77KaNCZWV1ff8HltbS1tmibzbmB/RBx2PTkOtyx5QiNigvtHYiZ27twpSbIP31+1Paxv2DIHl73Rd3p257UIC2JoTHD4DwCJqFTRqlGV4CwvOhm2rPX2rP9bo2JFAUbFz7g4m2T7DsZC3XlQqQJAIipVtKKECnUjg+2jYp1vo7bXuO24UTw2jVUqVQBIRKWKVpRaoQ4aVbGiDKOOHKapQOuqGxNUqgCQiEoVqea1T3LUGd95W49l1eaRUN1YoFIFgERUqkg1L32pmA+jqsOmcbXRkUhWrFKpAkAiKlVgCPpSy9Dkiqhh6o4e2KgtXFEFADNEUgWARJ0d/o8q68f9fFzHdZ0bJgwuA0CZ6v6Ntvk3PS7XUKkCQKLOKtVxe5JJO5abDIOgMm0fQ6mQIetGKaOG+rWRC6hUASBR50OqJr2hxaSVzyR7IPpUgcVQ4hERlSoAJJp5pTquMi1xz4PlwY1U5kvdvtVZbF8qVQBIlFKp1rltWheV6bhlUJ0A3ev/O836Wxw1/r1NVKoAkGiqSnXSx8ROMk02+maB+dLmkWL2LQQ3QqUKAImmqlRn+fCtaUzajxsR2rZt2yyahMLRz74Y2nhUOrf+A4AZalSpllKBTmre2ovuUaEuBs7+A8Ccq5VUV1dXqfqwoYggRrChzBhZn9fgq8mybL/h1RSVKgAk6vwuVQCWyyRn4ietFEddxTmuOuXafwCYE6njVOe9L40zvsDsZTwuum5l28Sk01KpAkCiWpXq2tqabP/fXmLeK9NBXFEFtK9O/2fdZ1TVvR/JNP25o1CpAkCiRn2q83LNf130qQLtq/N3Nuk9GJrcMa8tVKoAkKiVcapUfJh33KWqudXVVe3cuXNsP2bdM/dt6F921hE2lSoAJCKpAkAiLlNFJ9o47EIZ1odejtLkoqGsIVSzQKUKAIlIqujc4C3Xpr0F27j5cfKpXeu3CJ30NYlpbuk3qazYIKkCQCL6VFE8Kkusm/SWfl0OiaNSBYBEVKpIlfmgtWnnMU3VQnXc3Liz/22M9hhcHmf/AWBBUKmiFXUq1lGVJNXiYpqX7dr0qItKFQASUamiFVwlhUVRt7KmUgWARHUr1f2SdrfRkIKc3nUD5szQmCjpTPuw+TdYJnExuWXIE9KImDCHaQCQh8N/AEhEUgWARCRVAEhEUgWARCRVAEhEUgWARCRVAEhEUgWARCRVAEj0vxJJxMyCBwYqAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 9 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QQnIe19pXppY",
        "outputId": "6147b05d-26c4-498e-970d-62c8cdc90341"
      },
      "source": [
        "# Split data into Train, Val, Test and flatten the images\n",
        "frac = 0.15\n",
        "\n",
        "n = int(frac*(train.shape[0]))\n",
        "val = train[:n]\n",
        "train = train[n:]\n",
        "\n",
        "train = train.reshape(train.shape[0], -1)\n",
        "val = val.reshape(val.shape[0], -1)\n",
        "test = test.reshape(test.shape[0], -1)\n",
        "\n",
        "print('Train: ', train.shape)\n",
        "print('Val: ', val.shape)\n",
        "print('Test:  ', test.shape)\n",
        "\n",
        "print(\"\\n\\nUnique labels : \", np.unique(train_y))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train:  (51000, 784)\n",
            "Val:  (9000, 784)\n",
            "Test:   (10000, 784)\n",
            "\n",
            "\n",
            "Unique labels :  [0 1 2 3 4 5 6 7 8 9]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Ahz4-jrwtth"
      },
      "source": [
        "# Train and Inference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kQc8nf58wtDY"
      },
      "source": [
        "# RBM config\n",
        "num_hidden = 256 # number of hidden units\n",
        "lr = 0.001 # learning rate for gradient descent\n",
        "n = 1 # number of Gibbs sampling steps\n",
        "batch_size = 100 # mini batch size for gradient update\n",
        "epochs = 300 # number of epochs"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yqk92940ww0h",
        "outputId": "39339022-5300-4cd4-a5bf-ac7c1415e860"
      },
      "source": [
        "rbm_1 = RBM(num_hidden, val.shape[1], lr, n, batch_size, epochs)\n",
        "train_loss, val_loss = rbm_1.Train(train, val)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:35: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 ------> Error => Train : 206.11180392156865, Val : 205.67211111111112\n",
            "Epoch 2 ------> Error => Train : 178.73403921568627, Val : 178.3458888888889\n",
            "Epoch 3 ------> Error => Train : 164.97245098039215, Val : 164.30866666666668\n",
            "Epoch 4 ------> Error => Train : 156.00231372549018, Val : 155.25022222222222\n",
            "Epoch 5 ------> Error => Train : 149.96113725490196, Val : 149.22622222222222\n",
            "Epoch 6 ------> Error => Train : 145.26072549019608, Val : 144.54733333333334\n",
            "Epoch 7 ------> Error => Train : 141.50225490196078, Val : 140.68466666666666\n",
            "Epoch 8 ------> Error => Train : 138.19286274509804, Val : 137.61955555555556\n",
            "Epoch 9 ------> Error => Train : 135.35427450980393, Val : 134.92988888888888\n",
            "Epoch 10 ------> Error => Train : 132.62474509803923, Val : 132.03988888888887\n",
            "Epoch 11 ------> Error => Train : 130.53119607843138, Val : 129.95222222222222\n",
            "Epoch 12 ------> Error => Train : 128.29445098039216, Val : 127.85522222222221\n",
            "Epoch 13 ------> Error => Train : 126.5922156862745, Val : 126.01188888888889\n",
            "Epoch 14 ------> Error => Train : 124.88582352941177, Val : 124.477\n",
            "Epoch 15 ------> Error => Train : 123.37149019607844, Val : 122.69388888888889\n",
            "Epoch 16 ------> Error => Train : 122.00633333333334, Val : 121.5181111111111\n",
            "Epoch 17 ------> Error => Train : 120.67554901960784, Val : 120.26899999999999\n",
            "Epoch 18 ------> Error => Train : 119.46372549019608, Val : 118.97633333333333\n",
            "Epoch 19 ------> Error => Train : 118.27596078431372, Val : 117.85844444444444\n",
            "Epoch 20 ------> Error => Train : 117.10096078431371, Val : 116.60222222222222\n",
            "Epoch 21 ------> Error => Train : 116.27633333333333, Val : 115.75155555555556\n",
            "Epoch 22 ------> Error => Train : 115.15964705882352, Val : 114.71911111111112\n",
            "Epoch 23 ------> Error => Train : 114.26572549019608, Val : 113.87077777777777\n",
            "Epoch 24 ------> Error => Train : 113.38156862745097, Val : 112.96000000000001\n",
            "Epoch 25 ------> Error => Train : 112.6114705882353, Val : 112.3861111111111\n",
            "Epoch 26 ------> Error => Train : 111.88376470588236, Val : 111.25633333333333\n",
            "Epoch 27 ------> Error => Train : 111.10270588235295, Val : 110.70122222222221\n",
            "Epoch 28 ------> Error => Train : 110.5016274509804, Val : 109.87922222222221\n",
            "Epoch 29 ------> Error => Train : 109.84845098039216, Val : 109.406\n",
            "Epoch 30 ------> Error => Train : 109.22845098039215, Val : 109.00466666666667\n",
            "Epoch 31 ------> Error => Train : 108.58098039215687, Val : 108.11744444444444\n",
            "Epoch 32 ------> Error => Train : 107.98543137254902, Val : 107.65366666666667\n",
            "Epoch 33 ------> Error => Train : 107.59858823529413, Val : 107.20955555555555\n",
            "Epoch 34 ------> Error => Train : 107.12858823529412, Val : 106.70655555555555\n",
            "Epoch 35 ------> Error => Train : 106.5116274509804, Val : 106.05711111111111\n",
            "Epoch 36 ------> Error => Train : 106.00431372549019, Val : 105.44477777777777\n",
            "Epoch 37 ------> Error => Train : 105.63645098039217, Val : 105.21433333333334\n",
            "Epoch 38 ------> Error => Train : 105.19064705882353, Val : 104.80577777777778\n",
            "Epoch 39 ------> Error => Train : 104.67766666666667, Val : 104.47566666666665\n",
            "Epoch 40 ------> Error => Train : 104.22005882352941, Val : 103.96944444444445\n",
            "Epoch 41 ------> Error => Train : 103.88011764705882, Val : 103.49255555555555\n",
            "Epoch 42 ------> Error => Train : 103.43758823529411, Val : 103.11955555555556\n",
            "Epoch 43 ------> Error => Train : 102.97115686274509, Val : 102.57477777777777\n",
            "Epoch 44 ------> Error => Train : 102.52156862745099, Val : 102.18877777777777\n",
            "Epoch 45 ------> Error => Train : 102.25817647058824, Val : 102.02144444444444\n",
            "Epoch 46 ------> Error => Train : 101.92764705882352, Val : 101.362\n",
            "Epoch 47 ------> Error => Train : 101.52898039215685, Val : 101.14544444444445\n",
            "Epoch 48 ------> Error => Train : 101.1518431372549, Val : 100.97022222222223\n",
            "Epoch 49 ------> Error => Train : 100.84188235294118, Val : 100.68322222222221\n",
            "Epoch 50 ------> Error => Train : 100.53774509803921, Val : 100.17111111111112\n",
            "Epoch 51 ------> Error => Train : 100.23188235294117, Val : 99.8608888888889\n",
            "Epoch 52 ------> Error => Train : 99.92747058823531, Val : 99.64633333333333\n",
            "Epoch 53 ------> Error => Train : 99.59333333333333, Val : 99.11277777777778\n",
            "Epoch 54 ------> Error => Train : 99.28013725490196, Val : 98.84244444444444\n",
            "Epoch 55 ------> Error => Train : 99.04527450980392, Val : 98.60322222222223\n",
            "Epoch 56 ------> Error => Train : 98.83484313725491, Val : 98.40433333333334\n",
            "Epoch 57 ------> Error => Train : 98.49341176470588, Val : 98.17522222222222\n",
            "Epoch 58 ------> Error => Train : 98.14164705882354, Val : 97.78977777777779\n",
            "Epoch 59 ------> Error => Train : 97.90592156862745, Val : 97.55122222222222\n",
            "Epoch 60 ------> Error => Train : 97.7127450980392, Val : 97.432\n",
            "Epoch 61 ------> Error => Train : 97.50880392156861, Val : 97.27166666666666\n",
            "Epoch 62 ------> Error => Train : 97.23033333333333, Val : 96.86833333333333\n",
            "Epoch 63 ------> Error => Train : 97.00150980392158, Val : 96.76388888888889\n",
            "Epoch 64 ------> Error => Train : 96.7923725490196, Val : 96.58977777777778\n",
            "Epoch 65 ------> Error => Train : 96.53256862745098, Val : 96.21122222222223\n",
            "Epoch 66 ------> Error => Train : 96.28680392156863, Val : 95.92655555555555\n",
            "Epoch 67 ------> Error => Train : 95.96996078431373, Val : 95.7668888888889\n",
            "Epoch 68 ------> Error => Train : 95.7851568627451, Val : 95.57288888888888\n",
            "Epoch 69 ------> Error => Train : 95.6031568627451, Val : 95.42133333333334\n",
            "Epoch 70 ------> Error => Train : 95.32935294117647, Val : 95.12122222222223\n",
            "Epoch 71 ------> Error => Train : 95.07719607843137, Val : 94.78144444444445\n",
            "Epoch 72 ------> Error => Train : 94.90319607843138, Val : 94.75111111111111\n",
            "Epoch 73 ------> Error => Train : 94.8058431372549, Val : 94.43555555555555\n",
            "Epoch 74 ------> Error => Train : 94.59025490196078, Val : 94.32566666666668\n",
            "Epoch 75 ------> Error => Train : 94.35935294117647, Val : 94.01244444444444\n",
            "Epoch 76 ------> Error => Train : 94.13972549019608, Val : 93.89144444444443\n",
            "Epoch 77 ------> Error => Train : 93.95662745098039, Val : 93.66344444444445\n",
            "Epoch 78 ------> Error => Train : 93.76550980392156, Val : 93.34488888888889\n",
            "Epoch 79 ------> Error => Train : 93.47550980392157, Val : 93.25544444444444\n",
            "Epoch 80 ------> Error => Train : 93.30754901960783, Val : 93.027\n",
            "Epoch 81 ------> Error => Train : 93.0748431372549, Val : 92.79077777777778\n",
            "Epoch 82 ------> Error => Train : 92.96890196078431, Val : 92.70022222222222\n",
            "Epoch 83 ------> Error => Train : 92.83335294117647, Val : 92.5081111111111\n",
            "Epoch 84 ------> Error => Train : 92.52776470588235, Val : 92.19422222222221\n",
            "Epoch 85 ------> Error => Train : 92.34221568627451, Val : 92.14655555555555\n",
            "Epoch 86 ------> Error => Train : 92.23423529411764, Val : 91.98822222222223\n",
            "Epoch 87 ------> Error => Train : 92.03447058823528, Val : 91.73477777777778\n",
            "Epoch 88 ------> Error => Train : 91.85127450980391, Val : 91.604\n",
            "Epoch 89 ------> Error => Train : 91.66486274509805, Val : 91.34966666666668\n",
            "Epoch 90 ------> Error => Train : 91.53649019607843, Val : 91.13144444444444\n",
            "Epoch 91 ------> Error => Train : 91.39749019607845, Val : 91.01133333333334\n",
            "Epoch 92 ------> Error => Train : 91.17798039215687, Val : 90.99022222222223\n",
            "Epoch 93 ------> Error => Train : 91.00590196078431, Val : 90.69088888888888\n",
            "Epoch 94 ------> Error => Train : 90.85894117647058, Val : 90.6711111111111\n",
            "Epoch 95 ------> Error => Train : 90.65086274509804, Val : 90.34155555555556\n",
            "Epoch 96 ------> Error => Train : 90.54464705882353, Val : 90.34144444444443\n",
            "Epoch 97 ------> Error => Train : 90.32582352941176, Val : 90.07300000000001\n",
            "Epoch 98 ------> Error => Train : 90.1839411764706, Val : 90.01677777777778\n",
            "Epoch 99 ------> Error => Train : 89.97403921568628, Val : 89.83755555555555\n",
            "Epoch 100 ------> Error => Train : 89.89041176470587, Val : 89.46277777777777\n",
            "Epoch 101 ------> Error => Train : 89.74409803921567, Val : 89.53988888888888\n",
            "Epoch 102 ------> Error => Train : 89.5229411764706, Val : 89.50677777777778\n",
            "Epoch 103 ------> Error => Train : 89.45613725490196, Val : 88.99633333333333\n",
            "Epoch 104 ------> Error => Train : 89.3107450980392, Val : 88.82111111111111\n",
            "Epoch 105 ------> Error => Train : 89.13870588235294, Val : 88.81933333333333\n",
            "Epoch 106 ------> Error => Train : 88.93286274509805, Val : 88.63377777777777\n",
            "Epoch 107 ------> Error => Train : 88.82358823529412, Val : 88.58811111111112\n",
            "Epoch 108 ------> Error => Train : 88.62817647058823, Val : 88.41255555555556\n",
            "Epoch 109 ------> Error => Train : 88.54445098039216, Val : 88.33733333333333\n",
            "Epoch 110 ------> Error => Train : 88.35205882352942, Val : 88.26144444444445\n",
            "Epoch 111 ------> Error => Train : 88.24062745098038, Val : 88.027\n",
            "Epoch 112 ------> Error => Train : 88.03956862745099, Val : 87.88288888888889\n",
            "Epoch 113 ------> Error => Train : 87.94835294117648, Val : 87.72299999999998\n",
            "Epoch 114 ------> Error => Train : 87.8513137254902, Val : 87.5851111111111\n",
            "Epoch 115 ------> Error => Train : 87.67623529411765, Val : 87.495\n",
            "Epoch 116 ------> Error => Train : 87.47701960784313, Val : 87.28155555555557\n",
            "Epoch 117 ------> Error => Train : 87.35307843137255, Val : 87.26788888888889\n",
            "Epoch 118 ------> Error => Train : 87.2096862745098, Val : 86.93477777777778\n",
            "Epoch 119 ------> Error => Train : 87.20766666666665, Val : 86.86033333333333\n",
            "Epoch 120 ------> Error => Train : 87.02452941176472, Val : 86.71688888888889\n",
            "Epoch 121 ------> Error => Train : 86.80139215686273, Val : 86.59233333333333\n",
            "Epoch 122 ------> Error => Train : 86.79203921568627, Val : 86.39477777777779\n",
            "Epoch 123 ------> Error => Train : 86.66915686274511, Val : 86.45511111111111\n",
            "Epoch 124 ------> Error => Train : 86.5294705882353, Val : 86.40744444444445\n",
            "Epoch 125 ------> Error => Train : 86.46068627450981, Val : 86.2298888888889\n",
            "Epoch 126 ------> Error => Train : 86.35617647058824, Val : 86.101\n",
            "Epoch 127 ------> Error => Train : 86.0965294117647, Val : 85.9411111111111\n",
            "Epoch 128 ------> Error => Train : 86.00111764705882, Val : 85.80422222222222\n",
            "Epoch 129 ------> Error => Train : 85.92745098039217, Val : 85.69200000000001\n",
            "Epoch 130 ------> Error => Train : 85.82396078431373, Val : 85.52711111111111\n",
            "Epoch 131 ------> Error => Train : 85.63072549019608, Val : 85.59411111111112\n",
            "Epoch 132 ------> Error => Train : 85.51956862745098, Val : 85.28311111111111\n",
            "Epoch 133 ------> Error => Train : 85.38627450980391, Val : 85.23266666666666\n",
            "Epoch 134 ------> Error => Train : 85.37100000000001, Val : 85.10499999999999\n",
            "Epoch 135 ------> Error => Train : 85.14709803921568, Val : 84.95688888888888\n",
            "Epoch 136 ------> Error => Train : 85.07460784313724, Val : 85.064\n",
            "Epoch 137 ------> Error => Train : 84.90556862745098, Val : 84.713\n",
            "Epoch 138 ------> Error => Train : 84.92623529411765, Val : 84.6621111111111\n",
            "Epoch 139 ------> Error => Train : 84.78821568627451, Val : 84.54866666666668\n",
            "Epoch 140 ------> Error => Train : 84.5907450980392, Val : 84.38477777777777\n",
            "Epoch 141 ------> Error => Train : 84.55870588235294, Val : 84.45955555555555\n",
            "Epoch 142 ------> Error => Train : 84.36339215686274, Val : 84.32566666666666\n",
            "Epoch 143 ------> Error => Train : 84.30131372549019, Val : 84.193\n",
            "Epoch 144 ------> Error => Train : 84.2404705882353, Val : 83.89933333333333\n",
            "Epoch 145 ------> Error => Train : 84.07239215686275, Val : 83.89422222222223\n",
            "Epoch 146 ------> Error => Train : 83.90374509803922, Val : 83.80722222222222\n",
            "Epoch 147 ------> Error => Train : 83.88149019607843, Val : 83.78166666666667\n",
            "Epoch 148 ------> Error => Train : 83.79464705882353, Val : 83.60466666666667\n",
            "Epoch 149 ------> Error => Train : 83.55043137254901, Val : 83.41055555555556\n",
            "Epoch 150 ------> Error => Train : 83.4968431372549, Val : 83.40899999999999\n",
            "Epoch 151 ------> Error => Train : 83.41680392156863, Val : 83.34533333333334\n",
            "Epoch 152 ------> Error => Train : 83.32703921568628, Val : 83.17744444444445\n",
            "Epoch 153 ------> Error => Train : 83.28096078431372, Val : 83.05288888888889\n",
            "Epoch 154 ------> Error => Train : 83.21884313725491, Val : 82.97411111111111\n",
            "Epoch 155 ------> Error => Train : 83.05996078431372, Val : 82.84299999999999\n",
            "Epoch 156 ------> Error => Train : 83.01154901960784, Val : 82.77444444444444\n",
            "Epoch 157 ------> Error => Train : 82.91284313725491, Val : 82.70255555555556\n",
            "Epoch 158 ------> Error => Train : 82.66394117647059, Val : 82.4481111111111\n",
            "Epoch 159 ------> Error => Train : 82.6513137254902, Val : 82.49811111111111\n",
            "Epoch 160 ------> Error => Train : 82.55143137254902, Val : 82.3458888888889\n",
            "Epoch 161 ------> Error => Train : 82.51613725490196, Val : 82.3368888888889\n",
            "Epoch 162 ------> Error => Train : 82.35249019607843, Val : 82.19044444444444\n",
            "Epoch 163 ------> Error => Train : 82.32782352941177, Val : 82.1511111111111\n",
            "Epoch 164 ------> Error => Train : 82.1393137254902, Val : 82.09133333333332\n",
            "Epoch 165 ------> Error => Train : 82.03307843137254, Val : 81.97611111111112\n",
            "Epoch 166 ------> Error => Train : 81.99866666666667, Val : 82.00444444444445\n",
            "Epoch 167 ------> Error => Train : 81.93927450980391, Val : 81.79811111111111\n",
            "Epoch 168 ------> Error => Train : 81.8650980392157, Val : 81.58588888888889\n",
            "Epoch 169 ------> Error => Train : 81.76654901960785, Val : 81.40588888888888\n",
            "Epoch 170 ------> Error => Train : 81.66707843137254, Val : 81.46144444444445\n",
            "Epoch 171 ------> Error => Train : 81.55398039215686, Val : 81.37177777777777\n",
            "Epoch 172 ------> Error => Train : 81.49658823529413, Val : 81.40522222222222\n",
            "Epoch 173 ------> Error => Train : 81.33227450980392, Val : 81.10466666666667\n",
            "Epoch 174 ------> Error => Train : 81.28109803921569, Val : 80.98166666666667\n",
            "Epoch 175 ------> Error => Train : 81.1995294117647, Val : 81.08077777777777\n",
            "Epoch 176 ------> Error => Train : 81.0811568627451, Val : 80.78833333333333\n",
            "Epoch 177 ------> Error => Train : 81.05211764705882, Val : 80.91522222222221\n",
            "Epoch 178 ------> Error => Train : 81.01911764705882, Val : 80.66188888888888\n",
            "Epoch 179 ------> Error => Train : 80.80135294117648, Val : 80.79122222222222\n",
            "Epoch 180 ------> Error => Train : 80.762, Val : 80.63855555555556\n",
            "Epoch 181 ------> Error => Train : 80.63643137254903, Val : 80.47177777777777\n",
            "Epoch 182 ------> Error => Train : 80.60121568627451, Val : 80.44044444444444\n",
            "Epoch 183 ------> Error => Train : 80.55182352941176, Val : 80.354\n",
            "Epoch 184 ------> Error => Train : 80.44756862745098, Val : 80.37722222222223\n",
            "Epoch 185 ------> Error => Train : 80.34492156862746, Val : 80.35355555555556\n",
            "Epoch 186 ------> Error => Train : 80.29111764705881, Val : 80.29822222222222\n",
            "Epoch 187 ------> Error => Train : 80.17674509803922, Val : 80.0868888888889\n",
            "Epoch 188 ------> Error => Train : 80.07227450980392, Val : 79.88166666666666\n",
            "Epoch 189 ------> Error => Train : 80.09386274509805, Val : 79.856\n",
            "Epoch 190 ------> Error => Train : 79.9584705882353, Val : 79.98522222222222\n",
            "Epoch 191 ------> Error => Train : 79.90954901960785, Val : 79.72922222222222\n",
            "Epoch 192 ------> Error => Train : 79.83827450980392, Val : 79.77266666666667\n",
            "Epoch 193 ------> Error => Train : 79.7516862745098, Val : 79.72011111111111\n",
            "Epoch 194 ------> Error => Train : 79.62566666666667, Val : 79.54577777777777\n",
            "Epoch 195 ------> Error => Train : 79.57813725490196, Val : 79.36977777777778\n",
            "Epoch 196 ------> Error => Train : 79.47574509803921, Val : 79.48033333333333\n",
            "Epoch 197 ------> Error => Train : 79.5302156862745, Val : 79.19588888888889\n",
            "Epoch 198 ------> Error => Train : 79.32925490196078, Val : 79.10722222222222\n",
            "Epoch 199 ------> Error => Train : 79.31623529411765, Val : 79.1211111111111\n",
            "Epoch 200 ------> Error => Train : 79.24170588235296, Val : 79.08055555555555\n",
            "Epoch 201 ------> Error => Train : 79.10292156862745, Val : 78.95955555555555\n",
            "Epoch 202 ------> Error => Train : 79.06911764705883, Val : 78.84222222222222\n",
            "Epoch 203 ------> Error => Train : 78.92468627450981, Val : 78.85644444444445\n",
            "Epoch 204 ------> Error => Train : 78.90952941176471, Val : 78.76233333333333\n",
            "Epoch 205 ------> Error => Train : 78.86035294117647, Val : 78.703\n",
            "Epoch 206 ------> Error => Train : 78.75, Val : 78.71111111111111\n",
            "Epoch 207 ------> Error => Train : 78.73582352941176, Val : 78.56144444444445\n",
            "Epoch 208 ------> Error => Train : 78.64658823529412, Val : 78.40577777777779\n",
            "Epoch 209 ------> Error => Train : 78.58005882352941, Val : 78.48344444444444\n",
            "Epoch 210 ------> Error => Train : 78.46211764705882, Val : 78.446\n",
            "Epoch 211 ------> Error => Train : 78.37896078431373, Val : 78.19844444444445\n",
            "Epoch 212 ------> Error => Train : 78.30672549019607, Val : 78.21633333333332\n",
            "Epoch 213 ------> Error => Train : 78.28225490196078, Val : 78.19811111111112\n",
            "Epoch 214 ------> Error => Train : 78.23350980392158, Val : 78.13155555555556\n",
            "Epoch 215 ------> Error => Train : 78.10137254901962, Val : 78.0218888888889\n",
            "Epoch 216 ------> Error => Train : 78.07703921568628, Val : 77.8618888888889\n",
            "Epoch 217 ------> Error => Train : 77.96366666666667, Val : 78.00555555555556\n",
            "Epoch 218 ------> Error => Train : 77.95796078431373, Val : 78.05433333333335\n",
            "Epoch 219 ------> Error => Train : 77.9044705882353, Val : 77.76144444444445\n",
            "Epoch 220 ------> Error => Train : 77.84194117647058, Val : 77.70077777777777\n",
            "Epoch 221 ------> Error => Train : 77.77176470588235, Val : 77.55133333333333\n",
            "Epoch 222 ------> Error => Train : 77.71041176470588, Val : 77.54599999999999\n",
            "Epoch 223 ------> Error => Train : 77.60527450980392, Val : 77.51855555555557\n",
            "Epoch 224 ------> Error => Train : 77.52288235294118, Val : 77.37122222222223\n",
            "Epoch 225 ------> Error => Train : 77.49709803921567, Val : 77.29666666666667\n",
            "Epoch 226 ------> Error => Train : 77.33735294117646, Val : 77.321\n",
            "Epoch 227 ------> Error => Train : 77.3424705882353, Val : 77.23288888888888\n",
            "Epoch 228 ------> Error => Train : 77.28570588235293, Val : 77.14822222222222\n",
            "Epoch 229 ------> Error => Train : 77.24356862745097, Val : 77.11111111111111\n",
            "Epoch 230 ------> Error => Train : 77.16464705882353, Val : 77.09977777777777\n",
            "Epoch 231 ------> Error => Train : 77.06049019607843, Val : 77.08955555555556\n",
            "Epoch 232 ------> Error => Train : 77.01833333333333, Val : 76.96366666666665\n",
            "Epoch 233 ------> Error => Train : 76.951, Val : 76.955\n",
            "Epoch 234 ------> Error => Train : 76.93564705882352, Val : 76.82055555555556\n",
            "Epoch 235 ------> Error => Train : 76.8256862745098, Val : 76.76255555555556\n",
            "Epoch 236 ------> Error => Train : 76.75049019607843, Val : 76.57288888888888\n",
            "Epoch 237 ------> Error => Train : 76.67274509803923, Val : 76.69222222222223\n",
            "Epoch 238 ------> Error => Train : 76.70507843137256, Val : 76.5761111111111\n",
            "Epoch 239 ------> Error => Train : 76.55154901960785, Val : 76.45633333333333\n",
            "Epoch 240 ------> Error => Train : 76.55688235294119, Val : 76.36677777777777\n",
            "Epoch 241 ------> Error => Train : 76.4321568627451, Val : 76.36611111111111\n",
            "Epoch 242 ------> Error => Train : 76.45209803921568, Val : 76.31044444444444\n",
            "Epoch 243 ------> Error => Train : 76.37229411764704, Val : 76.21477777777778\n",
            "Epoch 244 ------> Error => Train : 76.29976470588235, Val : 76.14144444444443\n",
            "Epoch 245 ------> Error => Train : 76.25484313725491, Val : 76.14333333333335\n",
            "Epoch 246 ------> Error => Train : 76.20927450980392, Val : 76.29433333333333\n",
            "Epoch 247 ------> Error => Train : 76.05335294117647, Val : 75.89877777777778\n",
            "Epoch 248 ------> Error => Train : 76.12607843137255, Val : 75.95777777777778\n",
            "Epoch 249 ------> Error => Train : 76.04392156862745, Val : 75.99355555555556\n",
            "Epoch 250 ------> Error => Train : 75.9477450980392, Val : 75.91433333333333\n",
            "Epoch 251 ------> Error => Train : 75.85419607843137, Val : 75.764\n",
            "Epoch 252 ------> Error => Train : 75.8241568627451, Val : 75.69633333333334\n",
            "Epoch 253 ------> Error => Train : 75.80811764705882, Val : 75.6181111111111\n",
            "Epoch 254 ------> Error => Train : 75.78219607843138, Val : 75.78244444444445\n",
            "Epoch 255 ------> Error => Train : 75.7930588235294, Val : 75.68544444444444\n",
            "Epoch 256 ------> Error => Train : 75.61725490196079, Val : 75.56133333333334\n",
            "Epoch 257 ------> Error => Train : 75.54433333333333, Val : 75.44444444444446\n",
            "Epoch 258 ------> Error => Train : 75.53901960784313, Val : 75.43077777777779\n",
            "Epoch 259 ------> Error => Train : 75.37564705882353, Val : 75.44655555555556\n",
            "Epoch 260 ------> Error => Train : 75.38998039215686, Val : 75.21655555555556\n",
            "Epoch 261 ------> Error => Train : 75.40945098039215, Val : 75.30055555555555\n",
            "Epoch 262 ------> Error => Train : 75.27941176470588, Val : 75.25055555555556\n",
            "Epoch 263 ------> Error => Train : 75.24933333333333, Val : 75.30244444444443\n",
            "Epoch 264 ------> Error => Train : 75.18762745098039, Val : 75.10144444444444\n",
            "Epoch 265 ------> Error => Train : 75.14105882352942, Val : 74.97322222222222\n",
            "Epoch 266 ------> Error => Train : 75.0680980392157, Val : 75.10322222222223\n",
            "Epoch 267 ------> Error => Train : 74.96370588235294, Val : 74.91422222222222\n",
            "Epoch 268 ------> Error => Train : 74.99025490196078, Val : 74.91533333333334\n",
            "Epoch 269 ------> Error => Train : 74.85696078431373, Val : 74.75144444444445\n",
            "Epoch 270 ------> Error => Train : 74.83613725490196, Val : 74.86655555555555\n",
            "Epoch 271 ------> Error => Train : 74.75721568627452, Val : 74.74388888888889\n",
            "Epoch 272 ------> Error => Train : 74.79184313725492, Val : 74.73233333333333\n",
            "Epoch 273 ------> Error => Train : 74.7288431372549, Val : 74.648\n",
            "Epoch 274 ------> Error => Train : 74.69488235294118, Val : 74.53622222222222\n",
            "Epoch 275 ------> Error => Train : 74.54635294117648, Val : 74.48733333333334\n",
            "Epoch 276 ------> Error => Train : 74.6352156862745, Val : 74.57422222222223\n",
            "Epoch 277 ------> Error => Train : 74.50870588235294, Val : 74.35233333333333\n",
            "Epoch 278 ------> Error => Train : 74.43625490196078, Val : 74.42955555555555\n",
            "Epoch 279 ------> Error => Train : 74.46709803921567, Val : 74.422\n",
            "Epoch 280 ------> Error => Train : 74.34317647058823, Val : 74.22800000000001\n",
            "Epoch 281 ------> Error => Train : 74.35862745098039, Val : 74.3438888888889\n",
            "Epoch 282 ------> Error => Train : 74.3171568627451, Val : 74.19655555555556\n",
            "Epoch 283 ------> Error => Train : 74.2079411764706, Val : 74.09433333333334\n",
            "Epoch 284 ------> Error => Train : 74.16086274509803, Val : 74.10033333333332\n",
            "Epoch 285 ------> Error => Train : 74.18188235294119, Val : 74.16188888888888\n",
            "Epoch 286 ------> Error => Train : 74.03992156862745, Val : 73.86788888888888\n",
            "Epoch 287 ------> Error => Train : 73.94123529411765, Val : 74.08666666666667\n",
            "Epoch 288 ------> Error => Train : 73.9082156862745, Val : 74.00855555555555\n",
            "Epoch 289 ------> Error => Train : 74.0053137254902, Val : 73.8808888888889\n",
            "Epoch 290 ------> Error => Train : 73.85064705882354, Val : 73.80122222222222\n",
            "Epoch 291 ------> Error => Train : 73.7661568627451, Val : 73.7941111111111\n",
            "Epoch 292 ------> Error => Train : 73.84133333333332, Val : 73.83833333333332\n",
            "Epoch 293 ------> Error => Train : 73.69474509803922, Val : 73.73855555555556\n",
            "Epoch 294 ------> Error => Train : 73.67080392156862, Val : 73.738\n",
            "Epoch 295 ------> Error => Train : 73.65519607843137, Val : 73.62866666666667\n",
            "Epoch 296 ------> Error => Train : 73.5907450980392, Val : 73.60177777777777\n",
            "Epoch 297 ------> Error => Train : 73.63080392156863, Val : 73.55833333333334\n",
            "Epoch 298 ------> Error => Train : 73.49292156862745, Val : 73.56622222222222\n",
            "Epoch 299 ------> Error => Train : 73.44043137254903, Val : 73.37988888888889\n",
            "Epoch 300 ------> Error => Train : 73.43562745098039, Val : 73.3378888888889\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "_ifaWec_XhEI",
        "outputId": "f6906710-578e-465b-fcde-c6106246e63f"
      },
      "source": [
        "fig = plt.figure()\n",
        "plt.plot(train_loss, c='r', label=\"Train\")\n",
        "plt.plot(val_loss, c='g', label=\"Val\")\n",
        "plt.legend()\n",
        "plt.title(\"Reconstruction Error\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Error\")"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Error')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JQwpFNiAidEy"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CsiF1C83ipcJ"
      },
      "source": [
        "path = F\"/content/gdrive/My Drive/rbm_1.pkl\" \n",
        "pickle.dump([rbm_1.W, rbm_1.b_v, rbm_1.b_h], open(path, \"wb\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1D9BR87iw4id"
      },
      "source": [
        "# Test data and Image Reconstruction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        },
        "id": "-IXYtLaBw3x1",
        "outputId": "353e3b72-2191-458b-a51a-f6a3bedaa056"
      },
      "source": [
        "print(\"\\n\\nOriginal Images ....\")\n",
        "fig1 = plt.figure()\n",
        "for i in range(9):\n",
        "  plt.subplot(3,3,i+1)\n",
        "  plt.tight_layout()\n",
        "  plt.imshow(test[i].reshape((28,28)), cmap='gray', interpolation='none')\n",
        "  plt.title(\"Digit: {}\".format(test_y[i]))\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Original Images ....\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 9 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "DkNVwPuFxCDQ",
        "outputId": "cee2d17e-ee76-42ad-c8b2-2d79f5c4545e"
      },
      "source": [
        "print(\"\\n\\nSampled images....\")\n",
        "fig2 = plt.figure()\n",
        "for i in range(9):\n",
        "  plt.subplot(3,3,i+1)\n",
        "  plt.tight_layout()\n",
        "\n",
        "  # 1 step sampling\n",
        "  img = rbm_1.reconstruct_image(test[i].T.reshape((784,1)))\n",
        "\n",
        "  plt.imshow(img.reshape((28,28)), cmap='gray', interpolation='none')\n",
        "  plt.title(\"Digit: {}\".format(test_y[i]))\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Sampled images....\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:35: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 9 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U5esCYO8AOi2"
      },
      "source": [
        "# Train 2nd RBM to improve the prior"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aQR-nZkRLhqA"
      },
      "source": [
        "class RBM_prior():\n",
        "    def __init__(self, num_hidden, num_visible, lr, n, batch_size, epochs, W_old, b_v_old, b_h_old):\n",
        "        self.num_hidden = num_hidden\n",
        "        self.num_visible = num_visible\n",
        "        self.lr = lr\n",
        "        self.n = n\n",
        "        self.batch_size = batch_size\n",
        "        self.epochs = epochs\n",
        "        self.W_old = W_old\n",
        "        self.b_v_old = b_v_old\n",
        "        self.b_h_old = b_h_old\n",
        "\n",
        "        self.W = np.random.randn(num_hidden, num_visible)/np.sqrt(0.5*(num_visible + num_hidden)) # weights\n",
        "\n",
        "        self.b_h = np.zeros((num_hidden, 1)) # bias latent\n",
        "        self.b_v = np.zeros((num_visible, 1)) # bias visible\n",
        "\n",
        "        self.dW = []\n",
        "        self.db_h = []\n",
        "        self.db_v = []\n",
        "\n",
        "    def sigmoid(self, x):  \n",
        "        #Sigmoid activation \n",
        "        #Implemented interms  of tanh for increased stability\n",
        "        return .5 * (1 + np.tanh(.5 * x))\n",
        "\n",
        "    \n",
        "    def bernoulli_array(self, prob_array, dim):\n",
        "        # Simulating Bernoulli from uniform\n",
        "        sample = np.zeros(dim)\n",
        "\n",
        "        # Draw x~Uni[0,1]\n",
        "        uni_sample = np.random.uniform(0, 1, dim)\n",
        "\n",
        "        # return 1 if x < p else return 0\n",
        "        diff = uni_sample - prob_array\n",
        "        coords = np.argwhere(diff<0)\n",
        "        sample[[*coords.T]] = 1  \n",
        "\n",
        "        return sample\n",
        "\n",
        "    def gibbs_sampling(self, h_0):\n",
        "\n",
        "        h = h_0.copy()\n",
        "\n",
        "        for i in range(self.n):\n",
        "\n",
        "            # (v x h) @ (h x b) + (v x 1) = (v x b)\n",
        "            p_v_h = self.sigmoid(self.W.T @ h + self.b_v)\n",
        "            v = self.bernoulli_array(p_v_h, (p_v_h.shape[0], p_v_h.shape[1]))\n",
        "\n",
        "            # (h x v) @ (v x b) + (h x 1) = (h x b)\n",
        "            p_h_v = self.sigmoid(self.W @ v + self.b_h)\n",
        "            h = self.bernoulli_array(p_h_v, (p_h_v.shape[0], p_h_v.shape[1]))\n",
        "\n",
        "        return v, h, p_h_v\n",
        "\n",
        "    def hidden_to_visible(self, h):\n",
        "\n",
        "        h = h.T.copy()\n",
        "\n",
        "        # (v x h) @ (h x b) + (v x 1) = (v x b)\n",
        "        p_v_h = self.sigmoid(self.W.T @ h + self.b_v)\n",
        "        v = self.bernoulli_array(p_v_h, (p_v_h.shape[0], p_v_h.shape[1]))\n",
        "\n",
        "        return v.T\n",
        "\n",
        "    def visible_to_hidden(self, v):\n",
        "\n",
        "        v = v.T.copy()\n",
        "\n",
        "        # (h x v) @ (v x b) + (h x 1) = (h x b)\n",
        "        p_h_v = self.sigmoid(self.W @ v + self.b_h)\n",
        "        h = self.bernoulli_array(p_h_v, (p_h_v.shape[0], p_h_v.shape[1]))\n",
        "\n",
        "        return h.T\n",
        "\n",
        "    def gradient_descent(self, v_0, p_h_v_0, v_n, p_h_v_n):\n",
        "\n",
        "        # Compute the gradients\n",
        "        # (h x b) @ (b x v) - (h x b) @ (b x v) = (h x v)\n",
        "        self.dW = (p_h_v_0 @ v_0 - p_h_v_n @ v_n)/self.batch_size\n",
        "        self.db_h = np.mean(p_h_v_0 - p_h_v_n, axis=1)[:, np.newaxis]\n",
        "        self.db_v = np.mean(v_0 - v_n, axis=0)[:, np.newaxis]\n",
        "        \n",
        "        # Weight update\n",
        "        self.W   = self.W   + self.lr * self.dW\n",
        "        self.b_h = self.b_h + self.lr * self.db_h\n",
        "        self.b_v = self.b_v + self.lr * self.db_v\n",
        "\n",
        "\n",
        "    def reconstruction_error(self, v):\n",
        "        # Sample hidden state\n",
        "        p_h_v = self.sigmoid(self.W @ v + self.b_h)\n",
        "        h = self.bernoulli_array(p_h_v, (p_h_v.shape[0], p_h_v.shape[1]))\n",
        "\n",
        "        # Sample viible state\n",
        "        p_v_h = self.sigmoid(self.W.T @ h + self.b_v)\n",
        "        v_sampled = self.bernoulli_array(p_v_h, (p_v_h.shape[0], p_v_h.shape[1]))    \n",
        "\n",
        "        return np.sum(np.mean((v-v_sampled)**2, axis=1), axis=0)\n",
        "\n",
        "\n",
        "    def reconstruct_image(self, v):\n",
        "        # Sample hidden state\n",
        "        p_h_v = self.sigmoid(self.W @ v + self.b_h)\n",
        "        h = self.bernoulli_array(p_h_v, (p_h_v.shape[0], p_h_v.shape[1]))\n",
        "\n",
        "        # Sample viible state\n",
        "        p_v_h = self.sigmoid(self.W.T @ h + self.b_v)\n",
        "        v_sampled = self.bernoulli_array(p_v_h, (p_v_h.shape[0], p_v_h.shape[1]))    \n",
        "\n",
        "        return v_sampled\n",
        "\n",
        "\n",
        "    def Train(self, train, val):\n",
        "\n",
        "        num_batches = int(train.shape[0]/self.batch_size)\n",
        "        train_loss = []\n",
        "        val_loss = []\n",
        "\n",
        "        for epoch in range(self.epochs):\n",
        "\n",
        "            # Shuffling the data\n",
        "            train = np.random.permutation(train)\n",
        "\n",
        "            # Splitting data into batches\n",
        "            batches = np.array_split(train, num_batches)\n",
        "\n",
        "            for i in range(num_batches):\n",
        "\n",
        "                # ---- From first RBM -----\n",
        "                # visible units from data\n",
        "                v_0 = batches[i].T\n",
        "\n",
        "                # (h x v) @ (v x b) + (h x 1) = (h x b)\n",
        "                p_h_v_0 = self.sigmoid(self.W_old @ v_0 + self.b_h_old)\n",
        "                h_0 = self.bernoulli_array(p_h_v_0, (p_h_v_0.shape[0], p_h_v_0.shape[1]))\n",
        "\n",
        "                # ---- For prior RBM -----\n",
        "\n",
        "                # (l x h) @ (h x b) + (l x 1) = (l x b)\n",
        "                p_l_h_0 = self.sigmoid(self.W @ h_0 + self.b_h)\n",
        "                l_0 = self.bernoulli_array(p_l_h_0, (p_l_h_0.shape[0], p_l_h_0.shape[1]))\n",
        "\n",
        "                # Run the markov chain\n",
        "                h_n, l_n, p_l_h_n = self.gibbs_sampling(l_0)\n",
        "\n",
        "                # Compute gradients\n",
        "                self.gradient_descent(h_0.T, p_l_h_0, h_n.T, p_l_h_n)\n",
        "\n",
        "            # Compute reconstruction errror\n",
        "            v_0 = train.T\n",
        "            p_h_v_0 = self.sigmoid(self.W_old @ v_0 + self.b_h_old)\n",
        "            h_0 = self.bernoulli_array(p_h_v_0, (p_h_v_0.shape[0], p_h_v_0.shape[1]))\n",
        "            error_train = self.reconstruction_error(h_0)\n",
        "\n",
        "            v_0 = val.T\n",
        "            p_h_v_0 = self.sigmoid(self.W_old @ v_0 + self.b_h_old)\n",
        "            h_0 = self.bernoulli_array(p_h_v_0, (p_h_v_0.shape[0], p_h_v_0.shape[1]))\n",
        "            error_val = self.reconstruction_error(h_0)\n",
        "\n",
        "            print(f\"Epoch {epoch+1} ------> Error => Train : {error_train}, Val : {error_val}\")\n",
        " \n",
        "            train_loss.append(error_train)\n",
        "            val_loss.append(error_val)\n",
        "\n",
        "        return train_loss, val_loss\n",
        "\n"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nQz-pF_eATGx"
      },
      "source": [
        "# RBM config\n",
        "num_hidden = 64 # number of hidden units\n",
        "num_visible = 256 # number of hidden units\n",
        "lr = 0.001 # learning rate for gradient descent\n",
        "n = 1 # number of Gibbs sampling steps\n",
        "batch_size = 100 # mini batch size for gradient update\n",
        "epochs = 300 # number of epochs"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MrMUQKpfBAxD",
        "outputId": "74d93513-4725-4999-aac4-b13d3ad0aee6"
      },
      "source": [
        "rbm_2 = RBM_prior(num_hidden, num_visible, lr, n, batch_size, epochs, rbm_1.W, rbm_1.b_v, rbm_1.b_h)\n",
        "train_loss, val_loss = rbm_2.Train(train, val)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:38: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 ------> Error => Train : 85.66933333333333, Val : 85.92922222222222\n",
            "Epoch 2 ------> Error => Train : 78.24162745098039, Val : 78.45\n",
            "Epoch 3 ------> Error => Train : 71.18613725490195, Val : 71.10533333333333\n",
            "Epoch 4 ------> Error => Train : 66.22749019607843, Val : 66.29711111111112\n",
            "Epoch 5 ------> Error => Train : 62.97919607843137, Val : 63.10011111111112\n",
            "Epoch 6 ------> Error => Train : 60.63778431372549, Val : 60.760222222222225\n",
            "Epoch 7 ------> Error => Train : 58.86390196078432, Val : 58.885777777777776\n",
            "Epoch 8 ------> Error => Train : 57.402686274509804, Val : 57.36944444444444\n",
            "Epoch 9 ------> Error => Train : 56.349215686274505, Val : 56.38733333333333\n",
            "Epoch 10 ------> Error => Train : 55.35413725490196, Val : 55.42644444444444\n",
            "Epoch 11 ------> Error => Train : 54.57341176470588, Val : 54.71366666666667\n",
            "Epoch 12 ------> Error => Train : 53.817921568627455, Val : 53.86944444444444\n",
            "Epoch 13 ------> Error => Train : 53.18082352941177, Val : 53.1891111111111\n",
            "Epoch 14 ------> Error => Train : 52.588313725490195, Val : 52.598555555555556\n",
            "Epoch 15 ------> Error => Train : 52.04919607843137, Val : 52.044\n",
            "Epoch 16 ------> Error => Train : 51.501333333333335, Val : 51.52344444444444\n",
            "Epoch 17 ------> Error => Train : 51.06335294117647, Val : 51.135000000000005\n",
            "Epoch 18 ------> Error => Train : 50.554, Val : 50.56588888888889\n",
            "Epoch 19 ------> Error => Train : 50.108000000000004, Val : 50.15777777777778\n",
            "Epoch 20 ------> Error => Train : 49.72007843137254, Val : 49.665\n",
            "Epoch 21 ------> Error => Train : 49.369882352941175, Val : 49.41788888888889\n",
            "Epoch 22 ------> Error => Train : 49.01556862745098, Val : 48.982\n",
            "Epoch 23 ------> Error => Train : 48.68607843137255, Val : 48.696777777777775\n",
            "Epoch 24 ------> Error => Train : 48.335607843137254, Val : 48.29988888888889\n",
            "Epoch 25 ------> Error => Train : 48.035274509803926, Val : 48.01811111111111\n",
            "Epoch 26 ------> Error => Train : 47.713470588235296, Val : 47.78077777777777\n",
            "Epoch 27 ------> Error => Train : 47.46178431372549, Val : 47.54488888888889\n",
            "Epoch 28 ------> Error => Train : 47.1715294117647, Val : 47.14944444444444\n",
            "Epoch 29 ------> Error => Train : 46.88447058823529, Val : 46.88733333333333\n",
            "Epoch 30 ------> Error => Train : 46.69645098039216, Val : 46.599222222222224\n",
            "Epoch 31 ------> Error => Train : 46.44335294117647, Val : 46.51111111111111\n",
            "Epoch 32 ------> Error => Train : 46.14794117647059, Val : 46.229888888888894\n",
            "Epoch 33 ------> Error => Train : 45.90578431372549, Val : 46.047333333333334\n",
            "Epoch 34 ------> Error => Train : 45.64535294117647, Val : 45.719111111111104\n",
            "Epoch 35 ------> Error => Train : 45.44947058823529, Val : 45.528888888888886\n",
            "Epoch 36 ------> Error => Train : 45.23829411764706, Val : 45.21588888888889\n",
            "Epoch 37 ------> Error => Train : 44.98552941176471, Val : 45.016333333333336\n",
            "Epoch 38 ------> Error => Train : 44.79843137254902, Val : 44.830666666666666\n",
            "Epoch 39 ------> Error => Train : 44.57321568627451, Val : 44.70811111111111\n",
            "Epoch 40 ------> Error => Train : 44.411392156862746, Val : 44.459111111111106\n",
            "Epoch 41 ------> Error => Train : 44.15135294117647, Val : 44.211555555555556\n",
            "Epoch 42 ------> Error => Train : 43.98180392156863, Val : 44.06588888888889\n",
            "Epoch 43 ------> Error => Train : 43.77358823529411, Val : 43.853111111111104\n",
            "Epoch 44 ------> Error => Train : 43.53666666666667, Val : 43.567\n",
            "Epoch 45 ------> Error => Train : 43.322980392156865, Val : 43.41666666666667\n",
            "Epoch 46 ------> Error => Train : 43.11929411764706, Val : 43.166777777777774\n",
            "Epoch 47 ------> Error => Train : 43.001372549019614, Val : 43.05344444444444\n",
            "Epoch 48 ------> Error => Train : 42.74880392156863, Val : 42.76788888888889\n",
            "Epoch 49 ------> Error => Train : 42.61821568627451, Val : 42.643\n",
            "Epoch 50 ------> Error => Train : 42.41949019607843, Val : 42.58133333333333\n",
            "Epoch 51 ------> Error => Train : 42.23790196078431, Val : 42.29188888888889\n",
            "Epoch 52 ------> Error => Train : 42.07639215686275, Val : 42.04666666666667\n",
            "Epoch 53 ------> Error => Train : 41.85880392156862, Val : 41.94466666666667\n",
            "Epoch 54 ------> Error => Train : 41.74111764705883, Val : 41.77811111111111\n",
            "Epoch 55 ------> Error => Train : 41.55905882352941, Val : 41.63188888888888\n",
            "Epoch 56 ------> Error => Train : 41.392568627450984, Val : 41.498333333333335\n",
            "Epoch 57 ------> Error => Train : 41.20774509803921, Val : 41.25355555555556\n",
            "Epoch 58 ------> Error => Train : 41.107392156862744, Val : 41.18888888888888\n",
            "Epoch 59 ------> Error => Train : 40.925705882352936, Val : 41.032444444444444\n",
            "Epoch 60 ------> Error => Train : 40.757549019607836, Val : 40.907888888888884\n",
            "Epoch 61 ------> Error => Train : 40.64111764705882, Val : 40.64355555555555\n",
            "Epoch 62 ------> Error => Train : 40.498176470588234, Val : 40.53622222222222\n",
            "Epoch 63 ------> Error => Train : 40.33717647058823, Val : 40.43388888888889\n",
            "Epoch 64 ------> Error => Train : 40.211176470588235, Val : 40.281111111111116\n",
            "Epoch 65 ------> Error => Train : 40.09358823529412, Val : 40.151333333333326\n",
            "Epoch 66 ------> Error => Train : 39.94927450980392, Val : 39.81688888888889\n",
            "Epoch 67 ------> Error => Train : 39.85074509803922, Val : 39.85488888888889\n",
            "Epoch 68 ------> Error => Train : 39.68696078431372, Val : 39.66288888888889\n",
            "Epoch 69 ------> Error => Train : 39.573392156862745, Val : 39.653333333333336\n",
            "Epoch 70 ------> Error => Train : 39.47503921568628, Val : 39.47077777777778\n",
            "Epoch 71 ------> Error => Train : 39.33268627450981, Val : 39.434888888888885\n",
            "Epoch 72 ------> Error => Train : 39.17380392156863, Val : 39.281222222222226\n",
            "Epoch 73 ------> Error => Train : 39.07860784313726, Val : 39.18355555555556\n",
            "Epoch 74 ------> Error => Train : 39.001509803921564, Val : 39.07066666666667\n",
            "Epoch 75 ------> Error => Train : 38.84323529411765, Val : 39.000777777777785\n",
            "Epoch 76 ------> Error => Train : 38.771725490196076, Val : 38.81988888888888\n",
            "Epoch 77 ------> Error => Train : 38.65466666666667, Val : 38.76611111111111\n",
            "Epoch 78 ------> Error => Train : 38.570764705882354, Val : 38.61677777777778\n",
            "Epoch 79 ------> Error => Train : 38.422333333333334, Val : 38.52133333333333\n",
            "Epoch 80 ------> Error => Train : 38.3816862745098, Val : 38.42955555555555\n",
            "Epoch 81 ------> Error => Train : 38.257156862745106, Val : 38.345\n",
            "Epoch 82 ------> Error => Train : 38.173647058823526, Val : 38.216\n",
            "Epoch 83 ------> Error => Train : 38.106862745098034, Val : 38.16644444444444\n",
            "Epoch 84 ------> Error => Train : 37.990490196078426, Val : 38.13077777777777\n",
            "Epoch 85 ------> Error => Train : 37.92566666666667, Val : 38.03022222222222\n",
            "Epoch 86 ------> Error => Train : 37.79982352941177, Val : 38.00033333333333\n",
            "Epoch 87 ------> Error => Train : 37.74164705882353, Val : 37.82866666666667\n",
            "Epoch 88 ------> Error => Train : 37.64617647058824, Val : 37.733111111111114\n",
            "Epoch 89 ------> Error => Train : 37.57941176470588, Val : 37.639222222222216\n",
            "Epoch 90 ------> Error => Train : 37.4881568627451, Val : 37.595444444444446\n",
            "Epoch 91 ------> Error => Train : 37.39739215686274, Val : 37.46644444444445\n",
            "Epoch 92 ------> Error => Train : 37.32498039215686, Val : 37.394444444444446\n",
            "Epoch 93 ------> Error => Train : 37.24949019607843, Val : 37.287333333333336\n",
            "Epoch 94 ------> Error => Train : 37.15458823529411, Val : 37.303444444444445\n",
            "Epoch 95 ------> Error => Train : 37.11229411764706, Val : 37.20744444444445\n",
            "Epoch 96 ------> Error => Train : 37.03027450980392, Val : 37.120666666666665\n",
            "Epoch 97 ------> Error => Train : 36.99296078431372, Val : 37.09811111111111\n",
            "Epoch 98 ------> Error => Train : 36.94270588235294, Val : 37.000888888888895\n",
            "Epoch 99 ------> Error => Train : 36.80988235294117, Val : 36.94388888888889\n",
            "Epoch 100 ------> Error => Train : 36.77007843137255, Val : 36.79744444444445\n",
            "Epoch 101 ------> Error => Train : 36.70705882352941, Val : 36.760333333333335\n",
            "Epoch 102 ------> Error => Train : 36.631019607843136, Val : 36.67722222222223\n",
            "Epoch 103 ------> Error => Train : 36.57452941176471, Val : 36.662222222222226\n",
            "Epoch 104 ------> Error => Train : 36.47252941176471, Val : 36.56344444444444\n",
            "Epoch 105 ------> Error => Train : 36.456196078431375, Val : 36.54588888888889\n",
            "Epoch 106 ------> Error => Train : 36.39176470588235, Val : 36.47888888888889\n",
            "Epoch 107 ------> Error => Train : 36.32833333333333, Val : 36.46322222222222\n",
            "Epoch 108 ------> Error => Train : 36.288039215686275, Val : 36.34011111111111\n",
            "Epoch 109 ------> Error => Train : 36.181254901960784, Val : 36.24455555555556\n",
            "Epoch 110 ------> Error => Train : 36.129411764705885, Val : 36.19811111111111\n",
            "Epoch 111 ------> Error => Train : 36.08656862745098, Val : 36.126888888888885\n",
            "Epoch 112 ------> Error => Train : 36.083176470588235, Val : 36.08144444444444\n",
            "Epoch 113 ------> Error => Train : 35.96690196078431, Val : 36.065111111111115\n",
            "Epoch 114 ------> Error => Train : 35.85666666666667, Val : 36.03888888888889\n",
            "Epoch 115 ------> Error => Train : 35.822686274509806, Val : 35.86611111111111\n",
            "Epoch 116 ------> Error => Train : 35.777156862745095, Val : 35.94811111111111\n",
            "Epoch 117 ------> Error => Train : 35.736745098039215, Val : 35.77688888888889\n",
            "Epoch 118 ------> Error => Train : 35.6538431372549, Val : 35.78822222222222\n",
            "Epoch 119 ------> Error => Train : 35.64494117647059, Val : 35.645222222222216\n",
            "Epoch 120 ------> Error => Train : 35.54409803921568, Val : 35.699111111111115\n",
            "Epoch 121 ------> Error => Train : 35.52654901960784, Val : 35.68511111111111\n",
            "Epoch 122 ------> Error => Train : 35.45413725490196, Val : 35.55022222222222\n",
            "Epoch 123 ------> Error => Train : 35.408725490196076, Val : 35.46233333333333\n",
            "Epoch 124 ------> Error => Train : 35.371294117647054, Val : 35.367666666666665\n",
            "Epoch 125 ------> Error => Train : 35.31880392156863, Val : 35.422222222222224\n",
            "Epoch 126 ------> Error => Train : 35.319078431372546, Val : 35.38111111111111\n",
            "Epoch 127 ------> Error => Train : 35.18341176470588, Val : 35.34266666666666\n",
            "Epoch 128 ------> Error => Train : 35.20803921568627, Val : 35.29277777777777\n",
            "Epoch 129 ------> Error => Train : 35.12452941176471, Val : 35.214\n",
            "Epoch 130 ------> Error => Train : 35.05368627450981, Val : 35.14777777777778\n",
            "Epoch 131 ------> Error => Train : 35.042686274509805, Val : 35.101444444444446\n",
            "Epoch 132 ------> Error => Train : 34.987, Val : 35.01466666666667\n",
            "Epoch 133 ------> Error => Train : 34.90545098039216, Val : 34.99377777777778\n",
            "Epoch 134 ------> Error => Train : 34.883764705882356, Val : 35.01277777777778\n",
            "Epoch 135 ------> Error => Train : 34.831784313725485, Val : 34.888222222222225\n",
            "Epoch 136 ------> Error => Train : 34.7698431372549, Val : 34.861777777777775\n",
            "Epoch 137 ------> Error => Train : 34.74256862745098, Val : 34.733555555555554\n",
            "Epoch 138 ------> Error => Train : 34.68335294117647, Val : 34.77477777777778\n",
            "Epoch 139 ------> Error => Train : 34.626333333333335, Val : 34.635999999999996\n",
            "Epoch 140 ------> Error => Train : 34.55376470588236, Val : 34.714888888888886\n",
            "Epoch 141 ------> Error => Train : 34.54737254901961, Val : 34.648777777777774\n",
            "Epoch 142 ------> Error => Train : 34.49594117647059, Val : 34.58922222222222\n",
            "Epoch 143 ------> Error => Train : 34.4577843137255, Val : 34.538\n",
            "Epoch 144 ------> Error => Train : 34.42270588235294, Val : 34.49811111111111\n",
            "Epoch 145 ------> Error => Train : 34.373333333333335, Val : 34.42622222222222\n",
            "Epoch 146 ------> Error => Train : 34.317843137254904, Val : 34.38744444444444\n",
            "Epoch 147 ------> Error => Train : 34.29196078431373, Val : 34.403\n",
            "Epoch 148 ------> Error => Train : 34.30601960784314, Val : 34.327\n",
            "Epoch 149 ------> Error => Train : 34.21943137254902, Val : 34.18066666666667\n",
            "Epoch 150 ------> Error => Train : 34.157823529411765, Val : 34.346777777777774\n",
            "Epoch 151 ------> Error => Train : 34.159960784313725, Val : 34.138777777777776\n",
            "Epoch 152 ------> Error => Train : 34.086078431372556, Val : 34.181\n",
            "Epoch 153 ------> Error => Train : 34.03870588235294, Val : 34.19588888888889\n",
            "Epoch 154 ------> Error => Train : 34.03774509803921, Val : 34.123111111111115\n",
            "Epoch 155 ------> Error => Train : 33.964549019607844, Val : 34.08666666666666\n",
            "Epoch 156 ------> Error => Train : 33.898137254901954, Val : 33.97611111111111\n",
            "Epoch 157 ------> Error => Train : 33.89607843137255, Val : 34.05577777777778\n",
            "Epoch 158 ------> Error => Train : 33.87780392156863, Val : 33.95144444444445\n",
            "Epoch 159 ------> Error => Train : 33.80439215686275, Val : 33.82844444444444\n",
            "Epoch 160 ------> Error => Train : 33.810901960784314, Val : 33.90144444444445\n",
            "Epoch 161 ------> Error => Train : 33.72607843137255, Val : 33.85611111111111\n",
            "Epoch 162 ------> Error => Train : 33.686, Val : 33.769222222222226\n",
            "Epoch 163 ------> Error => Train : 33.66633333333333, Val : 33.79322222222223\n",
            "Epoch 164 ------> Error => Train : 33.62421568627451, Val : 33.644444444444446\n",
            "Epoch 165 ------> Error => Train : 33.57025490196079, Val : 33.687666666666665\n",
            "Epoch 166 ------> Error => Train : 33.55949019607843, Val : 33.584666666666664\n",
            "Epoch 167 ------> Error => Train : 33.52009803921568, Val : 33.647777777777776\n",
            "Epoch 168 ------> Error => Train : 33.49584313725491, Val : 33.611666666666665\n",
            "Epoch 169 ------> Error => Train : 33.45921568627451, Val : 33.46966666666667\n",
            "Epoch 170 ------> Error => Train : 33.414, Val : 33.47611111111111\n",
            "Epoch 171 ------> Error => Train : 33.35182352941176, Val : 33.41777777777777\n",
            "Epoch 172 ------> Error => Train : 33.354313725490194, Val : 33.443777777777775\n",
            "Epoch 173 ------> Error => Train : 33.32345098039215, Val : 33.373555555555555\n",
            "Epoch 174 ------> Error => Train : 33.25350980392157, Val : 33.31366666666666\n",
            "Epoch 175 ------> Error => Train : 33.23749019607843, Val : 33.29488888888889\n",
            "Epoch 176 ------> Error => Train : 33.193254901960785, Val : 33.315666666666665\n",
            "Epoch 177 ------> Error => Train : 33.17358823529412, Val : 33.236666666666665\n",
            "Epoch 178 ------> Error => Train : 33.15690196078431, Val : 33.25811111111111\n",
            "Epoch 179 ------> Error => Train : 33.10896078431372, Val : 33.22933333333333\n",
            "Epoch 180 ------> Error => Train : 33.110058823529414, Val : 33.148555555555554\n",
            "Epoch 181 ------> Error => Train : 33.04590196078432, Val : 33.15233333333334\n",
            "Epoch 182 ------> Error => Train : 33.025803921568624, Val : 33.10766666666667\n",
            "Epoch 183 ------> Error => Train : 32.96666666666667, Val : 33.028888888888886\n",
            "Epoch 184 ------> Error => Train : 32.98856862745099, Val : 33.05855555555556\n",
            "Epoch 185 ------> Error => Train : 32.922000000000004, Val : 33.05488888888889\n",
            "Epoch 186 ------> Error => Train : 32.85356862745098, Val : 33.08866666666667\n",
            "Epoch 187 ------> Error => Train : 32.87192156862745, Val : 32.95355555555555\n",
            "Epoch 188 ------> Error => Train : 32.82378431372549, Val : 32.93488888888889\n",
            "Epoch 189 ------> Error => Train : 32.79694117647059, Val : 32.87422222222222\n",
            "Epoch 190 ------> Error => Train : 32.800745098039215, Val : 32.87755555555556\n",
            "Epoch 191 ------> Error => Train : 32.74478431372549, Val : 32.78788888888889\n",
            "Epoch 192 ------> Error => Train : 32.7085294117647, Val : 32.91377777777778\n",
            "Epoch 193 ------> Error => Train : 32.64494117647059, Val : 32.70644444444444\n",
            "Epoch 194 ------> Error => Train : 32.648568627450985, Val : 32.73811111111111\n",
            "Epoch 195 ------> Error => Train : 32.59743137254902, Val : 32.71777777777778\n",
            "Epoch 196 ------> Error => Train : 32.563039215686274, Val : 32.612111111111105\n",
            "Epoch 197 ------> Error => Train : 32.552313725490194, Val : 32.60944444444445\n",
            "Epoch 198 ------> Error => Train : 32.52852941176471, Val : 32.58155555555555\n",
            "Epoch 199 ------> Error => Train : 32.48409803921569, Val : 32.590444444444444\n",
            "Epoch 200 ------> Error => Train : 32.4798431372549, Val : 32.46688888888889\n",
            "Epoch 201 ------> Error => Train : 32.427294117647065, Val : 32.55111111111111\n",
            "Epoch 202 ------> Error => Train : 32.40723529411765, Val : 32.513555555555556\n",
            "Epoch 203 ------> Error => Train : 32.398823529411764, Val : 32.507888888888886\n",
            "Epoch 204 ------> Error => Train : 32.347352941176474, Val : 32.435\n",
            "Epoch 205 ------> Error => Train : 32.26249019607843, Val : 32.40444444444445\n",
            "Epoch 206 ------> Error => Train : 32.294980392156866, Val : 32.39266666666667\n",
            "Epoch 207 ------> Error => Train : 32.27552941176471, Val : 32.36211111111111\n",
            "Epoch 208 ------> Error => Train : 32.259235294117644, Val : 32.312666666666665\n",
            "Epoch 209 ------> Error => Train : 32.229705882352945, Val : 32.30733333333333\n",
            "Epoch 210 ------> Error => Train : 32.19733333333333, Val : 32.28644444444444\n",
            "Epoch 211 ------> Error => Train : 32.19339215686274, Val : 32.348444444444446\n",
            "Epoch 212 ------> Error => Train : 32.12352941176471, Val : 32.25077777777778\n",
            "Epoch 213 ------> Error => Train : 32.11041176470589, Val : 32.15722222222222\n",
            "Epoch 214 ------> Error => Train : 32.11345098039216, Val : 32.17733333333333\n",
            "Epoch 215 ------> Error => Train : 32.040333333333336, Val : 32.224555555555554\n",
            "Epoch 216 ------> Error => Train : 32.053666666666665, Val : 32.10355555555555\n",
            "Epoch 217 ------> Error => Train : 32.00662745098039, Val : 32.144\n",
            "Epoch 218 ------> Error => Train : 32.01607843137255, Val : 32.12266666666667\n",
            "Epoch 219 ------> Error => Train : 31.96625490196078, Val : 32.04077777777778\n",
            "Epoch 220 ------> Error => Train : 31.928529411764707, Val : 32.06088888888889\n",
            "Epoch 221 ------> Error => Train : 31.89709803921568, Val : 31.977333333333334\n",
            "Epoch 222 ------> Error => Train : 31.887392156862745, Val : 32.01744444444444\n",
            "Epoch 223 ------> Error => Train : 31.84758823529412, Val : 32.062444444444445\n",
            "Epoch 224 ------> Error => Train : 31.84376470588235, Val : 32.00088888888889\n",
            "Epoch 225 ------> Error => Train : 31.813372549019608, Val : 31.938444444444443\n",
            "Epoch 226 ------> Error => Train : 31.786156862745102, Val : 31.831555555555553\n",
            "Epoch 227 ------> Error => Train : 31.731882352941177, Val : 31.840333333333334\n",
            "Epoch 228 ------> Error => Train : 31.740372549019607, Val : 31.889999999999997\n",
            "Epoch 229 ------> Error => Train : 31.71192156862745, Val : 31.773333333333333\n",
            "Epoch 230 ------> Error => Train : 31.66786274509804, Val : 31.746\n",
            "Epoch 231 ------> Error => Train : 31.675549019607843, Val : 31.736222222222224\n",
            "Epoch 232 ------> Error => Train : 31.63003921568627, Val : 31.675111111111114\n",
            "Epoch 233 ------> Error => Train : 31.622352941176466, Val : 31.74666666666667\n",
            "Epoch 234 ------> Error => Train : 31.57374509803922, Val : 31.660000000000004\n",
            "Epoch 235 ------> Error => Train : 31.547823529411765, Val : 31.77133333333333\n",
            "Epoch 236 ------> Error => Train : 31.561686274509803, Val : 31.68011111111111\n",
            "Epoch 237 ------> Error => Train : 31.538941176470587, Val : 31.58277777777778\n",
            "Epoch 238 ------> Error => Train : 31.499333333333333, Val : 31.619\n",
            "Epoch 239 ------> Error => Train : 31.499901960784314, Val : 31.599555555555554\n",
            "Epoch 240 ------> Error => Train : 31.45654901960784, Val : 31.555333333333333\n",
            "Epoch 241 ------> Error => Train : 31.445647058823532, Val : 31.53088888888889\n",
            "Epoch 242 ------> Error => Train : 31.446509803921572, Val : 31.47111111111111\n",
            "Epoch 243 ------> Error => Train : 31.37701960784314, Val : 31.46922222222222\n",
            "Epoch 244 ------> Error => Train : 31.354058823529414, Val : 31.473555555555556\n",
            "Epoch 245 ------> Error => Train : 31.325313725490197, Val : 31.362666666666662\n",
            "Epoch 246 ------> Error => Train : 31.36311764705883, Val : 31.41411111111111\n",
            "Epoch 247 ------> Error => Train : 31.32666666666667, Val : 31.397333333333332\n",
            "Epoch 248 ------> Error => Train : 31.296882352941175, Val : 31.413222222222217\n",
            "Epoch 249 ------> Error => Train : 31.258686274509806, Val : 31.342333333333332\n",
            "Epoch 250 ------> Error => Train : 31.22352941176471, Val : 31.379\n",
            "Epoch 251 ------> Error => Train : 31.23374509803922, Val : 31.341\n",
            "Epoch 252 ------> Error => Train : 31.17235294117647, Val : 31.254888888888885\n",
            "Epoch 253 ------> Error => Train : 31.193450980392157, Val : 31.235222222222223\n",
            "Epoch 254 ------> Error => Train : 31.163117647058822, Val : 31.201\n",
            "Epoch 255 ------> Error => Train : 31.121803921568628, Val : 31.178111111111107\n",
            "Epoch 256 ------> Error => Train : 31.10666666666667, Val : 31.129555555555555\n",
            "Epoch 257 ------> Error => Train : 31.107254901960786, Val : 31.141888888888893\n",
            "Epoch 258 ------> Error => Train : 31.032941176470587, Val : 31.076999999999998\n",
            "Epoch 259 ------> Error => Train : 31.024980392156863, Val : 31.083333333333336\n",
            "Epoch 260 ------> Error => Train : 31.033941176470588, Val : 31.194\n",
            "Epoch 261 ------> Error => Train : 31.02943137254902, Val : 31.028222222222226\n",
            "Epoch 262 ------> Error => Train : 30.963549019607843, Val : 31.134888888888888\n",
            "Epoch 263 ------> Error => Train : 30.93886274509804, Val : 31.054222222222222\n",
            "Epoch 264 ------> Error => Train : 30.895960784313726, Val : 30.99822222222222\n",
            "Epoch 265 ------> Error => Train : 30.926156862745096, Val : 30.98566666666666\n",
            "Epoch 266 ------> Error => Train : 30.913450980392156, Val : 31.007555555555555\n",
            "Epoch 267 ------> Error => Train : 30.889, Val : 30.938444444444443\n",
            "Epoch 268 ------> Error => Train : 30.858509803921567, Val : 30.891222222222222\n",
            "Epoch 269 ------> Error => Train : 30.82558823529412, Val : 30.910444444444444\n",
            "Epoch 270 ------> Error => Train : 30.793607843137256, Val : 30.938111111111112\n",
            "Epoch 271 ------> Error => Train : 30.808235294117644, Val : 30.873000000000005\n",
            "Epoch 272 ------> Error => Train : 30.810392156862747, Val : 30.738444444444443\n",
            "Epoch 273 ------> Error => Train : 30.743803921568627, Val : 30.901444444444444\n",
            "Epoch 274 ------> Error => Train : 30.689509803921567, Val : 30.83788888888889\n",
            "Epoch 275 ------> Error => Train : 30.71558823529412, Val : 30.85111111111111\n",
            "Epoch 276 ------> Error => Train : 30.681450980392157, Val : 30.897444444444446\n",
            "Epoch 277 ------> Error => Train : 30.674392156862744, Val : 30.811777777777777\n",
            "Epoch 278 ------> Error => Train : 30.662411764705883, Val : 30.772666666666666\n",
            "Epoch 279 ------> Error => Train : 30.599725490196075, Val : 30.742222222222225\n",
            "Epoch 280 ------> Error => Train : 30.600490196078432, Val : 30.64622222222222\n",
            "Epoch 281 ------> Error => Train : 30.57821568627451, Val : 30.688111111111112\n",
            "Epoch 282 ------> Error => Train : 30.59727450980392, Val : 30.67011111111111\n",
            "Epoch 283 ------> Error => Train : 30.55843137254902, Val : 30.735111111111113\n",
            "Epoch 284 ------> Error => Train : 30.554411764705883, Val : 30.634999999999998\n",
            "Epoch 285 ------> Error => Train : 30.529274509803923, Val : 30.583777777777776\n",
            "Epoch 286 ------> Error => Train : 30.476666666666667, Val : 30.567999999999998\n",
            "Epoch 287 ------> Error => Train : 30.46978431372549, Val : 30.622222222222224\n",
            "Epoch 288 ------> Error => Train : 30.466941176470584, Val : 30.600333333333335\n",
            "Epoch 289 ------> Error => Train : 30.420529411764708, Val : 30.55788888888889\n",
            "Epoch 290 ------> Error => Train : 30.375431372549016, Val : 30.56722222222222\n",
            "Epoch 291 ------> Error => Train : 30.430627450980392, Val : 30.502333333333333\n",
            "Epoch 292 ------> Error => Train : 30.4151568627451, Val : 30.529222222222224\n",
            "Epoch 293 ------> Error => Train : 30.37929411764706, Val : 30.443111111111108\n",
            "Epoch 294 ------> Error => Train : 30.354823529411767, Val : 30.467999999999996\n",
            "Epoch 295 ------> Error => Train : 30.340627450980392, Val : 30.443333333333335\n",
            "Epoch 296 ------> Error => Train : 30.31405882352941, Val : 30.42988888888889\n",
            "Epoch 297 ------> Error => Train : 30.28586274509804, Val : 30.34022222222222\n",
            "Epoch 298 ------> Error => Train : 30.275235294117646, Val : 30.31588888888889\n",
            "Epoch 299 ------> Error => Train : 30.258058823529414, Val : 30.35511111111111\n",
            "Epoch 300 ------> Error => Train : 30.226058823529407, Val : 30.296666666666667\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "ItQtXCLeXbsR",
        "outputId": "37bab1ba-bfb3-4e03-bff5-2e819a741213"
      },
      "source": [
        "fig = plt.figure()\n",
        "plt.plot(train_loss, c='r', label=\"Train\")\n",
        "plt.plot(val_loss, c='g', label=\"Val\")\n",
        "plt.legend()\n",
        "plt.title(\"Reconstruction Error\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Error\")"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Error')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BW213VEpBGeY"
      },
      "source": [
        "# Train new RBM using the prior"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wywSmfoJBFgS"
      },
      "source": [
        "class RBM_new():\n",
        "    def __init__(self, num_hidden, num_visible, lr, n, batch_size, epochs, W_prior, b_v_prior, b_h_prior):\n",
        "        self.num_hidden = num_hidden\n",
        "        self.num_visible = num_visible\n",
        "        self.lr = lr\n",
        "        self.n = n\n",
        "        self.batch_size = batch_size\n",
        "        self.epochs = epochs\n",
        "        self.W_prior = W_prior\n",
        "        self.b_v_prior = b_v_prior\n",
        "        self.b_h_prior = b_h_prior\n",
        "\n",
        "        self.W = np.random.randn(num_hidden, num_visible)/np.sqrt(0.5*(num_visible + num_hidden)) # weights\n",
        "\n",
        "        self.b_h = np.zeros((num_hidden, 1)) # bias latent\n",
        "        self.b_v = np.zeros((num_visible, 1)) # bias visible\n",
        "\n",
        "        self.dW = []\n",
        "        self.db_h = []\n",
        "        self.db_v = []\n",
        "\n",
        "    def sigmoid(self, x):  \n",
        "        #Sigmoid activation \n",
        "        #Implemented interms  of tanh for increased stability\n",
        "        return .5 * (1 + np.tanh(.5 * x))\n",
        "\n",
        "    \n",
        "    def bernoulli_array(self, prob_array, dim):\n",
        "        # Simulating Bernoulli from uniform\n",
        "        sample = np.zeros(dim)\n",
        "\n",
        "        # Draw x~Uni[0,1]\n",
        "        uni_sample = np.random.uniform(0, 1, dim)\n",
        "\n",
        "        # return 1 if x < p else return 0\n",
        "        diff = uni_sample - prob_array\n",
        "        coords = np.argwhere(diff<0)\n",
        "        sample[[*coords.T]] = 1  \n",
        "\n",
        "        return sample\n",
        "\n",
        "    def gibbs_sampling(self, h_0):\n",
        "\n",
        "        h = h_0.copy()\n",
        "\n",
        "        for i in range(self.n):\n",
        "\n",
        "            # (v x h) @ (h x b) + (v x 1) = (v x b)\n",
        "            p_v_h = self.sigmoid(self.W.T @ h + self.b_v)\n",
        "            v = self.bernoulli_array(p_v_h, (p_v_h.shape[0], p_v_h.shape[1]))\n",
        "\n",
        "            # (h x v) @ (v x b) + (h x 1) = (h x b)\n",
        "            p_h_v = self.sigmoid(self.W @ v + self.b_h)\n",
        "            h = self.bernoulli_array(p_h_v, (p_h_v.shape[0], p_h_v.shape[1]))\n",
        "\n",
        "        return v, h, p_h_v\n",
        "\n",
        "    def hidden_to_visible(self, h):\n",
        "\n",
        "        h = h.T.copy()\n",
        "\n",
        "        # (v x h) @ (h x b) + (v x 1) = (v x b)\n",
        "        p_v_h = self.sigmoid(self.W.T @ h + self.b_v)\n",
        "        v = self.bernoulli_array(p_v_h, (p_v_h.shape[0], p_v_h.shape[1]))\n",
        "\n",
        "        return v.T\n",
        "\n",
        "    def visible_to_hidden(self, v):\n",
        "\n",
        "        v = v.T.copy()\n",
        "\n",
        "        # (h x v) @ (v x b) + (h x 1) = (h x b)\n",
        "        p_h_v = self.sigmoid(self.W @ v + self.b_h)\n",
        "        h = self.bernoulli_array(p_h_v, (p_h_v.shape[0], p_h_v.shape[1]))\n",
        "\n",
        "        return h.T\n",
        "\n",
        "    def gradient_descent(self, v_0, p_h_v_0, v_n, p_h_v_n):\n",
        "\n",
        "        # Compute the gradients\n",
        "        # (h x b) @ (b x v) - (h x b) @ (b x v) = (h x v)\n",
        "        self.dW = (p_h_v_0 @ v_0 - p_h_v_n @ v_n)/self.batch_size\n",
        "        self.db_h = np.mean(p_h_v_0 - p_h_v_n, axis=1)[:, np.newaxis]\n",
        "        self.db_v = np.mean(v_0 - v_n, axis=0)[:, np.newaxis]\n",
        "        \n",
        "        # Weight update\n",
        "        self.W   = self.W   + self.lr * self.dW\n",
        "        self.b_h = self.b_h + self.lr * self.db_h\n",
        "        self.b_v = self.b_v + self.lr * self.db_v\n",
        "\n",
        "\n",
        "    def reconstruction_error(self, v):\n",
        "        # Sample hidden state\n",
        "        p_h_v = self.sigmoid(self.W @ v + self.b_h)\n",
        "        h = self.bernoulli_array(p_h_v, (p_h_v.shape[0], p_h_v.shape[1]))\n",
        "\n",
        "        # For prior RBM\n",
        "        p_l_h = self.sigmoid(self.W_prior @ h + self.b_h_prior)\n",
        "        l = self.bernoulli_array(p_l_h, (p_l_h.shape[0], p_l_h.shape[1]))\n",
        "\n",
        "        p_h_l = self.sigmoid(self.W_prior.T @ l + self.b_v_prior)\n",
        "        h_cap = self.bernoulli_array(p_h_l, (p_h_l.shape[0], p_h_l.shape[1]))\n",
        "\n",
        "        # Sample viible state\n",
        "        p_v_h = self.sigmoid(self.W.T @ h_cap + self.b_v)\n",
        "        v_sampled = self.bernoulli_array(p_v_h, (p_v_h.shape[0], p_v_h.shape[1]))    \n",
        "\n",
        "        return np.sum(np.mean((v-v_sampled)**2, axis=1), axis=0)\n",
        "\n",
        "\n",
        "    def reconstruct_image(self, v):\n",
        "        # Sample hidden state\n",
        "        p_h_v = self.sigmoid(self.W @ v + self.b_h)\n",
        "        h = self.bernoulli_array(p_h_v, (p_h_v.shape[0], p_h_v.shape[1]))\n",
        "\n",
        "        # For prior RBM\n",
        "        p_l_h = self.sigmoid(self.W_prior @ h + self.b_h_prior)\n",
        "        l = self.bernoulli_array(p_l_h, (p_l_h.shape[0], p_l_h.shape[1]))\n",
        "\n",
        "        p_h_l = self.sigmoid(self.W_prior.T @ l + self.b_v_prior)\n",
        "        h_cap = self.bernoulli_array(p_h_l, (p_h_l.shape[0], p_h_l.shape[1]))\n",
        "\n",
        "        # Sample viible state\n",
        "        p_v_h = self.sigmoid(self.W.T @ h_cap + self.b_v)\n",
        "        v_sampled = self.bernoulli_array(p_v_h, (p_v_h.shape[0], p_v_h.shape[1]))    \n",
        "\n",
        "        return v_sampled\n",
        "\n",
        "\n",
        "    def Train(self, train, val):\n",
        "\n",
        "        num_batches = int(train.shape[0]/self.batch_size)\n",
        "        train_loss = []\n",
        "        val_loss = []\n",
        "\n",
        "        for epoch in range(self.epochs):\n",
        "\n",
        "            # Shuffling the data\n",
        "            train = np.random.permutation(train)\n",
        "\n",
        "            # Splitting data into batches\n",
        "            batches = np.array_split(train, num_batches)\n",
        "\n",
        "            for i in range(num_batches):\n",
        "\n",
        "                # visible units from data\n",
        "                v_0 = batches[i].T\n",
        "\n",
        "                # (h x v) @ (v x b) + (h x 1) = (h x b)\n",
        "                p_h_v_0 = self.sigmoid(self.W @ v_0 + self.b_h)\n",
        "                h_0 = self.bernoulli_array(p_h_v_0, (p_h_v_0.shape[0], p_h_v_0.shape[1]))\n",
        "\n",
        "                # For prior RBM\n",
        "                p_l_h_0 = self.sigmoid(self.W_prior @ h_0 + self.b_h_prior)\n",
        "                l_0 = self.bernoulli_array(p_l_h_0, (p_l_h_0.shape[0], p_l_h_0.shape[1]))\n",
        "\n",
        "                p_h_l_0 = self.sigmoid(self.W_prior.T @ l_0 + self.b_v_prior)\n",
        "                h_0_cap = self.bernoulli_array(p_h_l_0, (p_h_l_0.shape[0], p_h_l_0.shape[1]))\n",
        "\n",
        "                # Run the markov chain\n",
        "                v_n, h_n, p_h_v_n = self.gibbs_sampling(h_0_cap)\n",
        "\n",
        "                # Compute gradients\n",
        "                self.gradient_descent(v_0.T, p_h_v_0, v_n.T, p_h_v_n)\n",
        "\n",
        "            # Compute reconstruction errror\n",
        "            error_train = self.reconstruction_error(train.T)\n",
        "            error_val = self.reconstruction_error(val.T)\n",
        "\n",
        "            print(f\"Epoch {epoch+1} ------> Error => Train : {error_train}, Val : {error_val}\")\n",
        " \n",
        "            train_loss.append(error_train)\n",
        "            val_loss.append(error_val)\n",
        "\n",
        "        return train_loss, val_loss"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_W6sZcHhD0pw"
      },
      "source": [
        "# RBM config\n",
        "num_hidden = 256 # number of hidden units\n",
        "lr = 0.001 # learning rate for gradient descent\n",
        "n = 1 # number of Gibbs sampling steps\n",
        "batch_size = 100 # mini batch size for gradient update\n",
        "epochs = 300 # number of epochs"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RyZEZdMyD5-4",
        "outputId": "9cd6dad6-2905-44e7-9010-0cd13c844ffd"
      },
      "source": [
        "rbm_3 = RBM_new(num_hidden, val.shape[1], lr, n, batch_size, epochs, rbm_2.W, rbm_2.b_v, rbm_2.b_h)\n",
        "train_loss, val_loss = rbm_3.Train(train, val)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:38: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 ------> Error => Train : 257.2061960784314, Val : 257.2705555555556\n",
            "Epoch 2 ------> Error => Train : 250.7115882352941, Val : 250.72222222222223\n",
            "Epoch 3 ------> Error => Train : 244.75584313725489, Val : 244.60577777777777\n",
            "Epoch 4 ------> Error => Train : 238.8976274509804, Val : 238.66133333333335\n",
            "Epoch 5 ------> Error => Train : 235.13611764705882, Val : 235.02766666666668\n",
            "Epoch 6 ------> Error => Train : 231.06750980392155, Val : 231.26144444444444\n",
            "Epoch 7 ------> Error => Train : 228.8303137254902, Val : 229.56566666666663\n",
            "Epoch 8 ------> Error => Train : 226.37898039215685, Val : 225.88100000000003\n",
            "Epoch 9 ------> Error => Train : 224.33611764705884, Val : 223.47433333333333\n",
            "Epoch 10 ------> Error => Train : 221.37058823529412, Val : 221.64322222222222\n",
            "Epoch 11 ------> Error => Train : 220.29009803921568, Val : 220.07033333333334\n",
            "Epoch 12 ------> Error => Train : 219.86203921568625, Val : 220.78522222222222\n",
            "Epoch 13 ------> Error => Train : 218.63096078431371, Val : 217.127\n",
            "Epoch 14 ------> Error => Train : 217.29172549019606, Val : 217.6281111111111\n",
            "Epoch 15 ------> Error => Train : 216.56772549019607, Val : 216.37633333333332\n",
            "Epoch 16 ------> Error => Train : 215.49966666666666, Val : 214.554\n",
            "Epoch 17 ------> Error => Train : 215.2634117647059, Val : 216.57155555555556\n",
            "Epoch 18 ------> Error => Train : 214.9621176470588, Val : 215.35733333333334\n",
            "Epoch 19 ------> Error => Train : 214.63050980392157, Val : 213.73844444444444\n",
            "Epoch 20 ------> Error => Train : 214.23637254901962, Val : 214.1751111111111\n",
            "Epoch 21 ------> Error => Train : 213.55929411764706, Val : 213.701\n",
            "Epoch 22 ------> Error => Train : 213.89266666666668, Val : 213.62088888888889\n",
            "Epoch 23 ------> Error => Train : 213.0728431372549, Val : 212.1571111111111\n",
            "Epoch 24 ------> Error => Train : 212.82594117647056, Val : 213.04066666666665\n",
            "Epoch 25 ------> Error => Train : 212.44001960784314, Val : 212.024\n",
            "Epoch 26 ------> Error => Train : 212.11472549019607, Val : 211.69377777777777\n",
            "Epoch 27 ------> Error => Train : 211.92180392156862, Val : 211.86277777777778\n",
            "Epoch 28 ------> Error => Train : 211.49188235294116, Val : 211.64355555555554\n",
            "Epoch 29 ------> Error => Train : 211.00776470588235, Val : 211.63155555555556\n",
            "Epoch 30 ------> Error => Train : 211.1753725490196, Val : 210.73844444444444\n",
            "Epoch 31 ------> Error => Train : 211.2564117647059, Val : 211.10655555555553\n",
            "Epoch 32 ------> Error => Train : 211.58362745098037, Val : 210.16044444444444\n",
            "Epoch 33 ------> Error => Train : 211.0680588235294, Val : 209.62955555555556\n",
            "Epoch 34 ------> Error => Train : 210.96343137254905, Val : 210.774\n",
            "Epoch 35 ------> Error => Train : 210.57709803921568, Val : 210.76188888888888\n",
            "Epoch 36 ------> Error => Train : 210.17352941176472, Val : 210.1561111111111\n",
            "Epoch 37 ------> Error => Train : 209.89892156862743, Val : 208.90133333333335\n",
            "Epoch 38 ------> Error => Train : 210.26350980392158, Val : 210.43144444444445\n",
            "Epoch 39 ------> Error => Train : 209.92117647058825, Val : 209.37311111111111\n",
            "Epoch 40 ------> Error => Train : 209.89323529411763, Val : 208.16444444444443\n",
            "Epoch 41 ------> Error => Train : 209.437, Val : 208.7837777777778\n",
            "Epoch 42 ------> Error => Train : 209.7578039215686, Val : 208.39766666666668\n",
            "Epoch 43 ------> Error => Train : 209.41733333333332, Val : 208.82100000000003\n",
            "Epoch 44 ------> Error => Train : 208.69088235294117, Val : 208.51833333333335\n",
            "Epoch 45 ------> Error => Train : 209.07217647058823, Val : 208.21277777777777\n",
            "Epoch 46 ------> Error => Train : 210.0851568627451, Val : 210.51644444444443\n",
            "Epoch 47 ------> Error => Train : 209.66407843137256, Val : 209.01611111111112\n",
            "Epoch 48 ------> Error => Train : 210.62968627450982, Val : 210.25944444444445\n",
            "Epoch 49 ------> Error => Train : 210.07813725490197, Val : 211.63033333333334\n",
            "Epoch 50 ------> Error => Train : 210.04209803921572, Val : 209.4688888888889\n",
            "Epoch 51 ------> Error => Train : 209.92825490196077, Val : 209.64111111111112\n",
            "Epoch 52 ------> Error => Train : 209.77935294117646, Val : 209.11922222222222\n",
            "Epoch 53 ------> Error => Train : 210.2080588235294, Val : 209.85466666666667\n",
            "Epoch 54 ------> Error => Train : 210.04990196078433, Val : 209.0808888888889\n",
            "Epoch 55 ------> Error => Train : 209.52633333333335, Val : 208.90922222222224\n",
            "Epoch 56 ------> Error => Train : 209.9880588235294, Val : 209.45811111111112\n",
            "Epoch 57 ------> Error => Train : 209.93400000000003, Val : 209.83311111111112\n",
            "Epoch 58 ------> Error => Train : 209.7757450980392, Val : 209.15411111111112\n",
            "Epoch 59 ------> Error => Train : 209.2018431372549, Val : 208.79899999999998\n",
            "Epoch 60 ------> Error => Train : 209.20294117647057, Val : 209.46922222222221\n",
            "Epoch 61 ------> Error => Train : 209.2303137254902, Val : 208.67766666666665\n",
            "Epoch 62 ------> Error => Train : 208.8835882352941, Val : 209.55977777777778\n",
            "Epoch 63 ------> Error => Train : 208.85719607843137, Val : 207.60288888888888\n",
            "Epoch 64 ------> Error => Train : 209.0712156862745, Val : 207.71777777777777\n",
            "Epoch 65 ------> Error => Train : 209.29572549019608, Val : 210.01044444444443\n",
            "Epoch 66 ------> Error => Train : 208.74947058823528, Val : 208.89044444444446\n",
            "Epoch 67 ------> Error => Train : 208.38143137254903, Val : 209.36044444444445\n",
            "Epoch 68 ------> Error => Train : 208.54376470588232, Val : 208.8361111111111\n",
            "Epoch 69 ------> Error => Train : 208.27913725490197, Val : 208.75155555555557\n",
            "Epoch 70 ------> Error => Train : 208.2675294117647, Val : 209.571\n",
            "Epoch 71 ------> Error => Train : 208.43486274509803, Val : 208.27633333333333\n",
            "Epoch 72 ------> Error => Train : 208.02260784313725, Val : 207.03699999999998\n",
            "Epoch 73 ------> Error => Train : 208.08529411764707, Val : 207.4103333333333\n",
            "Epoch 74 ------> Error => Train : 207.8537843137255, Val : 207.27444444444444\n",
            "Epoch 75 ------> Error => Train : 207.81923529411765, Val : 207.82644444444443\n",
            "Epoch 76 ------> Error => Train : 207.44156862745098, Val : 207.63655555555556\n",
            "Epoch 77 ------> Error => Train : 207.57901960784312, Val : 207.8297777777778\n",
            "Epoch 78 ------> Error => Train : 207.53513725490194, Val : 207.1518888888889\n",
            "Epoch 79 ------> Error => Train : 207.44894117647058, Val : 208.25799999999998\n",
            "Epoch 80 ------> Error => Train : 207.74398039215686, Val : 207.38666666666666\n",
            "Epoch 81 ------> Error => Train : 207.88031372549017, Val : 208.60655555555556\n",
            "Epoch 82 ------> Error => Train : 207.9350980392157, Val : 206.88566666666668\n",
            "Epoch 83 ------> Error => Train : 207.68449019607846, Val : 209.68666666666667\n",
            "Epoch 84 ------> Error => Train : 207.81274509803922, Val : 207.96122222222223\n",
            "Epoch 85 ------> Error => Train : 207.0396274509804, Val : 207.50488888888887\n",
            "Epoch 86 ------> Error => Train : 207.89770588235294, Val : 208.90666666666667\n",
            "Epoch 87 ------> Error => Train : 208.3713137254902, Val : 207.75244444444445\n",
            "Epoch 88 ------> Error => Train : 208.76313725490195, Val : 207.349\n",
            "Epoch 89 ------> Error => Train : 208.6478823529412, Val : 208.834\n",
            "Epoch 90 ------> Error => Train : 210.07929411764707, Val : 209.34677777777776\n",
            "Epoch 91 ------> Error => Train : 208.54819607843137, Val : 208.428\n",
            "Epoch 92 ------> Error => Train : 209.15876470588233, Val : 209.01422222222223\n",
            "Epoch 93 ------> Error => Train : 209.31470588235294, Val : 208.6997777777778\n",
            "Epoch 94 ------> Error => Train : 209.05292156862745, Val : 209.37466666666666\n",
            "Epoch 95 ------> Error => Train : 209.3933725490196, Val : 208.70822222222222\n",
            "Epoch 96 ------> Error => Train : 209.103, Val : 208.4811111111111\n",
            "Epoch 97 ------> Error => Train : 209.2246274509804, Val : 208.27488888888888\n",
            "Epoch 98 ------> Error => Train : 208.65017647058824, Val : 209.05155555555555\n",
            "Epoch 99 ------> Error => Train : 209.189, Val : 208.04144444444444\n",
            "Epoch 100 ------> Error => Train : 208.86756862745096, Val : 209.83355555555556\n",
            "Epoch 101 ------> Error => Train : 209.28554901960786, Val : 208.48888888888888\n",
            "Epoch 102 ------> Error => Train : 208.9438235294118, Val : 209.877\n",
            "Epoch 103 ------> Error => Train : 208.47123529411766, Val : 209.01500000000001\n",
            "Epoch 104 ------> Error => Train : 209.00790196078432, Val : 208.10066666666665\n",
            "Epoch 105 ------> Error => Train : 209.0580588235294, Val : 209.04533333333333\n",
            "Epoch 106 ------> Error => Train : 208.14101960784313, Val : 208.56600000000003\n",
            "Epoch 107 ------> Error => Train : 208.65949019607842, Val : 208.2351111111111\n",
            "Epoch 108 ------> Error => Train : 209.0710980392157, Val : 210.7587777777778\n",
            "Epoch 109 ------> Error => Train : 209.36688235294116, Val : 208.6338888888889\n",
            "Epoch 110 ------> Error => Train : 209.33925490196077, Val : 208.14666666666668\n",
            "Epoch 111 ------> Error => Train : 209.34819607843136, Val : 209.59433333333334\n",
            "Epoch 112 ------> Error => Train : 210.2832745098039, Val : 209.29966666666667\n",
            "Epoch 113 ------> Error => Train : 210.7216274509804, Val : 210.31655555555557\n",
            "Epoch 114 ------> Error => Train : 210.63664705882354, Val : 212.56733333333335\n",
            "Epoch 115 ------> Error => Train : 211.0888431372549, Val : 211.4802222222222\n",
            "Epoch 116 ------> Error => Train : 210.71264705882353, Val : 211.4187777777778\n",
            "Epoch 117 ------> Error => Train : 211.1661568627451, Val : 211.81388888888887\n",
            "Epoch 118 ------> Error => Train : 211.06086274509806, Val : 211.6086666666667\n",
            "Epoch 119 ------> Error => Train : 210.7779019607843, Val : 211.702\n",
            "Epoch 120 ------> Error => Train : 211.42223529411763, Val : 211.6231111111111\n",
            "Epoch 121 ------> Error => Train : 211.12339215686274, Val : 210.78744444444447\n",
            "Epoch 122 ------> Error => Train : 211.11686274509805, Val : 211.40533333333332\n",
            "Epoch 123 ------> Error => Train : 211.12723529411764, Val : 211.159\n",
            "Epoch 124 ------> Error => Train : 211.05309803921568, Val : 211.1981111111111\n",
            "Epoch 125 ------> Error => Train : 210.7684117647059, Val : 211.40133333333333\n",
            "Epoch 126 ------> Error => Train : 210.183, Val : 209.2148888888889\n",
            "Epoch 127 ------> Error => Train : 209.86835294117645, Val : 209.77977777777778\n",
            "Epoch 128 ------> Error => Train : 210.62970588235294, Val : 209.57455555555555\n",
            "Epoch 129 ------> Error => Train : 210.61192156862745, Val : 210.44333333333333\n",
            "Epoch 130 ------> Error => Train : 210.1860588235294, Val : 209.60111111111112\n",
            "Epoch 131 ------> Error => Train : 209.97, Val : 210.37400000000002\n",
            "Epoch 132 ------> Error => Train : 210.31107843137255, Val : 209.34333333333333\n",
            "Epoch 133 ------> Error => Train : 209.5084705882353, Val : 209.59333333333336\n",
            "Epoch 134 ------> Error => Train : 210.19801960784312, Val : 210.13066666666666\n",
            "Epoch 135 ------> Error => Train : 210.09923529411765, Val : 210.81133333333335\n",
            "Epoch 136 ------> Error => Train : 210.43501960784315, Val : 210.19466666666668\n",
            "Epoch 137 ------> Error => Train : 210.19449019607845, Val : 210.22977777777777\n",
            "Epoch 138 ------> Error => Train : 210.14198039215685, Val : 209.6408888888889\n",
            "Epoch 139 ------> Error => Train : 209.87121568627452, Val : 210.15022222222223\n",
            "Epoch 140 ------> Error => Train : 209.2147843137255, Val : 209.18988888888887\n",
            "Epoch 141 ------> Error => Train : 208.66354901960784, Val : 209.49388888888888\n",
            "Epoch 142 ------> Error => Train : 208.7591568627451, Val : 209.15500000000003\n",
            "Epoch 143 ------> Error => Train : 208.86713725490193, Val : 209.68055555555554\n",
            "Epoch 144 ------> Error => Train : 208.20849019607843, Val : 208.05944444444444\n",
            "Epoch 145 ------> Error => Train : 208.6715882352941, Val : 208.8396666666667\n",
            "Epoch 146 ------> Error => Train : 209.17358823529412, Val : 207.46233333333333\n",
            "Epoch 147 ------> Error => Train : 208.95725490196077, Val : 209.16455555555555\n",
            "Epoch 148 ------> Error => Train : 208.7460588235294, Val : 208.4766666666667\n",
            "Epoch 149 ------> Error => Train : 209.46509803921566, Val : 208.39933333333335\n",
            "Epoch 150 ------> Error => Train : 209.08470588235295, Val : 208.9092222222222\n",
            "Epoch 151 ------> Error => Train : 209.11529411764707, Val : 209.00644444444444\n",
            "Epoch 152 ------> Error => Train : 208.810431372549, Val : 207.55833333333334\n",
            "Epoch 153 ------> Error => Train : 209.326, Val : 209.66666666666669\n",
            "Epoch 154 ------> Error => Train : 209.60033333333334, Val : 209.09555555555553\n",
            "Epoch 155 ------> Error => Train : 209.04619607843136, Val : 209.86044444444445\n",
            "Epoch 156 ------> Error => Train : 208.75376470588236, Val : 208.75400000000002\n",
            "Epoch 157 ------> Error => Train : 209.19788235294118, Val : 208.99666666666667\n",
            "Epoch 158 ------> Error => Train : 208.7606274509804, Val : 208.03300000000002\n",
            "Epoch 159 ------> Error => Train : 209.0754117647059, Val : 210.503\n",
            "Epoch 160 ------> Error => Train : 208.52250980392157, Val : 208.88133333333334\n",
            "Epoch 161 ------> Error => Train : 208.04213725490195, Val : 208.49633333333333\n",
            "Epoch 162 ------> Error => Train : 208.29362745098038, Val : 208.07333333333332\n",
            "Epoch 163 ------> Error => Train : 208.37268627450982, Val : 208.02966666666666\n",
            "Epoch 164 ------> Error => Train : 207.8145294117647, Val : 207.17322222222222\n",
            "Epoch 165 ------> Error => Train : 207.99072549019607, Val : 208.99411111111112\n",
            "Epoch 166 ------> Error => Train : 208.64388235294115, Val : 206.82022222222224\n",
            "Epoch 167 ------> Error => Train : 207.93486274509803, Val : 208.07166666666666\n",
            "Epoch 168 ------> Error => Train : 208.3252156862745, Val : 209.29033333333334\n",
            "Epoch 169 ------> Error => Train : 208.22764705882352, Val : 207.04577777777777\n",
            "Epoch 170 ------> Error => Train : 208.33017647058824, Val : 206.75155555555557\n",
            "Epoch 171 ------> Error => Train : 207.91274509803924, Val : 208.33066666666667\n",
            "Epoch 172 ------> Error => Train : 207.99866666666665, Val : 207.66266666666667\n",
            "Epoch 173 ------> Error => Train : 207.6741176470588, Val : 207.12911111111111\n",
            "Epoch 174 ------> Error => Train : 207.45941176470586, Val : 206.5113333333333\n",
            "Epoch 175 ------> Error => Train : 207.43676470588235, Val : 209.03833333333333\n",
            "Epoch 176 ------> Error => Train : 207.69684313725492, Val : 207.0271111111111\n",
            "Epoch 177 ------> Error => Train : 206.896431372549, Val : 205.54444444444445\n",
            "Epoch 178 ------> Error => Train : 207.74180392156862, Val : 206.87422222222222\n",
            "Epoch 179 ------> Error => Train : 206.98692156862745, Val : 207.2931111111111\n",
            "Epoch 180 ------> Error => Train : 207.65088235294118, Val : 207.53377777777777\n",
            "Epoch 181 ------> Error => Train : 207.36160784313728, Val : 206.9858888888889\n",
            "Epoch 182 ------> Error => Train : 207.0068431372549, Val : 207.47566666666665\n",
            "Epoch 183 ------> Error => Train : 207.10733333333332, Val : 207.66644444444444\n",
            "Epoch 184 ------> Error => Train : 207.65333333333334, Val : 207.53688888888888\n",
            "Epoch 185 ------> Error => Train : 207.6425882352941, Val : 206.62566666666666\n",
            "Epoch 186 ------> Error => Train : 207.6945882352941, Val : 207.7391111111111\n",
            "Epoch 187 ------> Error => Train : 207.5440588235294, Val : 207.33433333333332\n",
            "Epoch 188 ------> Error => Train : 206.87596078431375, Val : 207.14077777777777\n",
            "Epoch 189 ------> Error => Train : 206.98262745098037, Val : 206.53577777777778\n",
            "Epoch 190 ------> Error => Train : 207.63737254901957, Val : 208.11255555555556\n",
            "Epoch 191 ------> Error => Train : 207.61682352941176, Val : 206.53011111111113\n",
            "Epoch 192 ------> Error => Train : 207.00447058823528, Val : 206.44733333333335\n",
            "Epoch 193 ------> Error => Train : 207.1179411764706, Val : 205.22677777777778\n",
            "Epoch 194 ------> Error => Train : 206.73954901960786, Val : 207.83788888888887\n",
            "Epoch 195 ------> Error => Train : 207.6818431372549, Val : 206.69088888888888\n",
            "Epoch 196 ------> Error => Train : 207.51639215686274, Val : 205.7838888888889\n",
            "Epoch 197 ------> Error => Train : 207.31388235294116, Val : 206.39300000000003\n",
            "Epoch 198 ------> Error => Train : 206.6293137254902, Val : 205.26466666666667\n",
            "Epoch 199 ------> Error => Train : 207.1199411764706, Val : 207.15033333333335\n",
            "Epoch 200 ------> Error => Train : 207.18535294117646, Val : 208.02833333333334\n",
            "Epoch 201 ------> Error => Train : 206.4587843137255, Val : 205.25944444444445\n",
            "Epoch 202 ------> Error => Train : 206.48919607843135, Val : 207.9741111111111\n",
            "Epoch 203 ------> Error => Train : 207.5184705882353, Val : 208.11477777777776\n",
            "Epoch 204 ------> Error => Train : 207.3009411764706, Val : 207.33977777777778\n",
            "Epoch 205 ------> Error => Train : 207.49111764705884, Val : 207.08555555555557\n",
            "Epoch 206 ------> Error => Train : 207.3416862745098, Val : 206.67855555555556\n",
            "Epoch 207 ------> Error => Train : 206.83564705882353, Val : 206.09300000000002\n",
            "Epoch 208 ------> Error => Train : 206.76323529411766, Val : 207.3181111111111\n",
            "Epoch 209 ------> Error => Train : 207.42060784313725, Val : 206.67000000000002\n",
            "Epoch 210 ------> Error => Train : 206.3353725490196, Val : 206.02622222222223\n",
            "Epoch 211 ------> Error => Train : 207.02292156862745, Val : 207.00666666666666\n",
            "Epoch 212 ------> Error => Train : 207.25974509803922, Val : 205.6867777777778\n",
            "Epoch 213 ------> Error => Train : 207.59592156862743, Val : 206.59633333333335\n",
            "Epoch 214 ------> Error => Train : 207.36952941176472, Val : 207.29655555555556\n",
            "Epoch 215 ------> Error => Train : 207.19960784313724, Val : 208.32722222222222\n",
            "Epoch 216 ------> Error => Train : 207.39462745098038, Val : 206.48911111111113\n",
            "Epoch 217 ------> Error => Train : 206.6082156862745, Val : 206.60866666666666\n",
            "Epoch 218 ------> Error => Train : 206.46076470588235, Val : 207.11411111111113\n",
            "Epoch 219 ------> Error => Train : 206.74488235294115, Val : 208.063\n",
            "Epoch 220 ------> Error => Train : 206.82256862745098, Val : 205.54544444444446\n",
            "Epoch 221 ------> Error => Train : 207.43866666666668, Val : 208.08133333333333\n",
            "Epoch 222 ------> Error => Train : 206.61229411764705, Val : 207.61222222222221\n",
            "Epoch 223 ------> Error => Train : 207.48135294117645, Val : 206.3138888888889\n",
            "Epoch 224 ------> Error => Train : 207.1368823529412, Val : 207.52422222222222\n",
            "Epoch 225 ------> Error => Train : 207.14950980392155, Val : 206.31255555555558\n",
            "Epoch 226 ------> Error => Train : 207.07660784313725, Val : 207.74144444444445\n",
            "Epoch 227 ------> Error => Train : 207.2068431372549, Val : 206.0308888888889\n",
            "Epoch 228 ------> Error => Train : 206.52898039215688, Val : 208.42700000000002\n",
            "Epoch 229 ------> Error => Train : 207.2009019607843, Val : 206.02366666666666\n",
            "Epoch 230 ------> Error => Train : 206.96364705882354, Val : 206.59777777777776\n",
            "Epoch 231 ------> Error => Train : 207.32382352941175, Val : 207.07366666666667\n",
            "Epoch 232 ------> Error => Train : 207.29145098039214, Val : 207.9878888888889\n",
            "Epoch 233 ------> Error => Train : 207.03645098039215, Val : 204.692\n",
            "Epoch 234 ------> Error => Train : 206.88901960784315, Val : 207.14922222222222\n",
            "Epoch 235 ------> Error => Train : 207.00692156862746, Val : 206.38677777777778\n",
            "Epoch 236 ------> Error => Train : 206.99780392156862, Val : 205.9081111111111\n",
            "Epoch 237 ------> Error => Train : 207.00186274509804, Val : 206.1797777777778\n",
            "Epoch 238 ------> Error => Train : 207.37682352941175, Val : 207.25444444444446\n",
            "Epoch 239 ------> Error => Train : 207.69050980392157, Val : 208.30533333333335\n",
            "Epoch 240 ------> Error => Train : 206.9714117647059, Val : 207.1518888888889\n",
            "Epoch 241 ------> Error => Train : 206.8382745098039, Val : 205.7167777777778\n",
            "Epoch 242 ------> Error => Train : 206.51154901960786, Val : 206.98611111111111\n",
            "Epoch 243 ------> Error => Train : 207.10186274509803, Val : 207.1712222222222\n",
            "Epoch 244 ------> Error => Train : 207.25949019607845, Val : 207.4788888888889\n",
            "Epoch 245 ------> Error => Train : 206.72864705882353, Val : 206.09644444444444\n",
            "Epoch 246 ------> Error => Train : 206.89413725490195, Val : 206.17466666666667\n",
            "Epoch 247 ------> Error => Train : 207.09164705882353, Val : 206.28122222222223\n",
            "Epoch 248 ------> Error => Train : 206.81066666666666, Val : 206.02022222222223\n",
            "Epoch 249 ------> Error => Train : 207.20049019607842, Val : 207.40944444444443\n",
            "Epoch 250 ------> Error => Train : 206.93525490196077, Val : 206.5988888888889\n",
            "Epoch 251 ------> Error => Train : 207.24894117647062, Val : 207.86533333333335\n",
            "Epoch 252 ------> Error => Train : 207.16764705882355, Val : 207.24233333333336\n",
            "Epoch 253 ------> Error => Train : 206.86649019607842, Val : 206.30399999999997\n",
            "Epoch 254 ------> Error => Train : 206.55680392156864, Val : 207.76644444444446\n",
            "Epoch 255 ------> Error => Train : 206.79207843137254, Val : 205.98122222222224\n",
            "Epoch 256 ------> Error => Train : 207.04960784313727, Val : 206.23822222222222\n",
            "Epoch 257 ------> Error => Train : 206.90307843137253, Val : 206.03833333333333\n",
            "Epoch 258 ------> Error => Train : 207.14929411764706, Val : 205.68155555555558\n",
            "Epoch 259 ------> Error => Train : 206.4679411764706, Val : 207.77811111111112\n",
            "Epoch 260 ------> Error => Train : 206.0685098039216, Val : 205.49822222222224\n",
            "Epoch 261 ------> Error => Train : 207.2268431372549, Val : 207.23688888888887\n",
            "Epoch 262 ------> Error => Train : 207.19231372549018, Val : 206.70166666666668\n",
            "Epoch 263 ------> Error => Train : 206.92952941176472, Val : 206.91655555555556\n",
            "Epoch 264 ------> Error => Train : 206.83935294117646, Val : 208.16255555555557\n",
            "Epoch 265 ------> Error => Train : 206.96127450980393, Val : 205.98388888888888\n",
            "Epoch 266 ------> Error => Train : 206.34660784313724, Val : 206.04911111111113\n",
            "Epoch 267 ------> Error => Train : 207.46460784313726, Val : 207.45555555555555\n",
            "Epoch 268 ------> Error => Train : 206.6217450980392, Val : 206.43166666666667\n",
            "Epoch 269 ------> Error => Train : 206.95549019607842, Val : 206.73555555555555\n",
            "Epoch 270 ------> Error => Train : 207.2012549019608, Val : 205.83255555555556\n",
            "Epoch 271 ------> Error => Train : 207.11990196078432, Val : 208.51433333333333\n",
            "Epoch 272 ------> Error => Train : 206.87409803921568, Val : 205.75411111111111\n",
            "Epoch 273 ------> Error => Train : 207.19211764705884, Val : 206.53588888888888\n",
            "Epoch 274 ------> Error => Train : 207.47980392156865, Val : 207.61311111111112\n",
            "Epoch 275 ------> Error => Train : 207.10533333333336, Val : 206.3396666666667\n",
            "Epoch 276 ------> Error => Train : 206.78860784313724, Val : 207.57066666666665\n",
            "Epoch 277 ------> Error => Train : 206.73933333333332, Val : 206.25633333333332\n",
            "Epoch 278 ------> Error => Train : 207.52303921568625, Val : 206.46244444444446\n",
            "Epoch 279 ------> Error => Train : 207.21131372549019, Val : 205.59755555555557\n",
            "Epoch 280 ------> Error => Train : 206.41113725490197, Val : 206.27455555555554\n",
            "Epoch 281 ------> Error => Train : 207.3112549019608, Val : 206.14133333333334\n",
            "Epoch 282 ------> Error => Train : 207.7747254901961, Val : 206.6361111111111\n",
            "Epoch 283 ------> Error => Train : 207.02366666666666, Val : 207.2348888888889\n",
            "Epoch 284 ------> Error => Train : 207.27529411764706, Val : 203.92466666666667\n",
            "Epoch 285 ------> Error => Train : 207.19937254901959, Val : 207.06944444444446\n",
            "Epoch 286 ------> Error => Train : 207.19411764705885, Val : 206.9142222222222\n",
            "Epoch 287 ------> Error => Train : 207.0749411764706, Val : 205.98222222222222\n",
            "Epoch 288 ------> Error => Train : 206.08241176470588, Val : 207.12355555555555\n",
            "Epoch 289 ------> Error => Train : 207.42647058823528, Val : 207.30066666666664\n",
            "Epoch 290 ------> Error => Train : 207.0053725490196, Val : 206.2602222222222\n",
            "Epoch 291 ------> Error => Train : 207.01103921568625, Val : 207.56044444444444\n",
            "Epoch 292 ------> Error => Train : 206.9354117647059, Val : 206.98077777777777\n",
            "Epoch 293 ------> Error => Train : 206.19749019607843, Val : 207.46955555555556\n",
            "Epoch 294 ------> Error => Train : 207.44866666666667, Val : 207.524\n",
            "Epoch 295 ------> Error => Train : 206.13733333333334, Val : 206.3142222222222\n",
            "Epoch 296 ------> Error => Train : 206.8916862745098, Val : 207.02377777777778\n",
            "Epoch 297 ------> Error => Train : 207.06472549019605, Val : 208.11044444444445\n",
            "Epoch 298 ------> Error => Train : 207.03449019607842, Val : 205.97555555555556\n",
            "Epoch 299 ------> Error => Train : 207.2200392156863, Val : 206.34566666666666\n",
            "Epoch 300 ------> Error => Train : 206.7397450980392, Val : 205.816\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "kGyGWJ2QZALq",
        "outputId": "ff42ac92-0cb9-4a2e-c37a-f535f7f5441e"
      },
      "source": [
        "fig = plt.figure()\n",
        "plt.plot(train_loss, c='r', label=\"Train\")\n",
        "plt.plot(val_loss, c='g', label=\"Val\")\n",
        "plt.legend()\n",
        "plt.title(\"Reconstruction Error\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Error\")"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Error')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Q4thCEBENvT"
      },
      "source": [
        "# Compare reconstructed images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "weeyiOr0ERBc",
        "outputId": "85fbcec4-ce84-4f3e-ef28-b50b080d05c4"
      },
      "source": [
        "print(\"\\n\\nSampled images 1....\")\n",
        "fig2 = plt.figure()\n",
        "for i in range(9):\n",
        "  plt.subplot(3,3,i+1)\n",
        "  plt.tight_layout()\n",
        "\n",
        "  # 1 step sampling\n",
        "  img = rbm_1.reconstruct_image(test[i].T.reshape((784,1)))\n",
        "\n",
        "  plt.imshow(img.reshape((28,28)), cmap='gray', interpolation='none')\n",
        "  plt.title(\"Digit: {}\".format(test_y[i]))\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Sampled images 1....\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:35: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 9 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "SaUk3bLIETII",
        "outputId": "6fc8aa04-9403-4c58-f171-748b34b10e79"
      },
      "source": [
        "print(\"\\n\\nSampled images 2....\")\n",
        "fig2 = plt.figure()\n",
        "for i in range(9):\n",
        "  plt.subplot(3,3,i+1)\n",
        "  plt.tight_layout()\n",
        "\n",
        "  # 1 step sampling\n",
        "  img = rbm_3.reconstruct_image(test[i].T.reshape((784,1)))\n",
        "\n",
        "  plt.imshow(img.reshape((28,28)), cmap='gray', interpolation='none')\n",
        "  plt.title(\"Digit: {}\".format(test_y[i]))\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Sampled images 2....\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:38: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 9 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MDz0IP8VEZ_-"
      },
      "source": [
        "# Reconstruction error"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jRQXdseJEb_Y",
        "outputId": "7fd893c7-37ef-48fd-e580-d48c24c25b59"
      },
      "source": [
        "err_1 = rbm_1.reconstruction_error(test.T)\n",
        "err_3 = rbm_3.reconstruction_error(test.T)\n",
        "\n",
        "print(\"Reconstruction error using original RBM : \", err_1)\n",
        "print(\"Reconstruction error using modified RBM : \", err_3)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:35: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:38: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Reconstruction error using original RBM :  73.9257\n",
            "Reconstruction error using modified RBM :  207.06529999999998\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ccrMKLpKZEr8"
      },
      "source": [
        "# Re-Train old RBM with prior"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5sMg39FzZKab"
      },
      "source": [
        "class RBM_ret():\n",
        "    def __init__(self, num_hidden, num_visible, lr, n, batch_size, epochs, W_prior, b_v_prior, b_h_prior, W_old, b_v_old, b_h_old):\n",
        "        self.num_hidden = num_hidden\n",
        "        self.num_visible = num_visible\n",
        "        self.lr = lr\n",
        "        self.n = n\n",
        "        self.batch_size = batch_size\n",
        "        self.epochs = epochs\n",
        "        self.W_prior = W_prior\n",
        "        self.b_v_prior = b_v_prior\n",
        "        self.b_h_prior = b_h_prior\n",
        "\n",
        "        self.W = W_old # weights\n",
        "\n",
        "        self.b_h = b_h_old # bias latent\n",
        "        self.b_v = b_v_old # bias visible\n",
        "\n",
        "        self.dW = []\n",
        "        self.db_h = []\n",
        "        self.db_v = []\n",
        "\n",
        "    def sigmoid(self, x):  \n",
        "        #Sigmoid activation \n",
        "        #Implemented interms  of tanh for increased stability\n",
        "        return .5 * (1 + np.tanh(.5 * x))\n",
        "\n",
        "    \n",
        "    def bernoulli_array(self, prob_array, dim):\n",
        "        # Simulating Bernoulli from uniform\n",
        "        sample = np.zeros(dim)\n",
        "\n",
        "        # Draw x~Uni[0,1]\n",
        "        uni_sample = np.random.uniform(0, 1, dim)\n",
        "\n",
        "        # return 1 if x < p else return 0\n",
        "        diff = uni_sample - prob_array\n",
        "        coords = np.argwhere(diff<0)\n",
        "        sample[[*coords.T]] = 1  \n",
        "\n",
        "        return sample\n",
        "\n",
        "    def gibbs_sampling(self, h_0):\n",
        "\n",
        "        h = h_0.copy()\n",
        "\n",
        "        for i in range(self.n):\n",
        "\n",
        "            # (v x h) @ (h x b) + (v x 1) = (v x b)\n",
        "            p_v_h = self.sigmoid(self.W.T @ h + self.b_v)\n",
        "            v = self.bernoulli_array(p_v_h, (p_v_h.shape[0], p_v_h.shape[1]))\n",
        "\n",
        "            # (h x v) @ (v x b) + (h x 1) = (h x b)\n",
        "            p_h_v = self.sigmoid(self.W @ v + self.b_h)\n",
        "            h = self.bernoulli_array(p_h_v, (p_h_v.shape[0], p_h_v.shape[1]))\n",
        "\n",
        "        return v, h, p_h_v\n",
        "\n",
        "    def hidden_to_visible(self, h):\n",
        "\n",
        "        h = h.T.copy()\n",
        "\n",
        "        # (v x h) @ (h x b) + (v x 1) = (v x b)\n",
        "        p_v_h = self.sigmoid(self.W.T @ h + self.b_v)\n",
        "        v = self.bernoulli_array(p_v_h, (p_v_h.shape[0], p_v_h.shape[1]))\n",
        "\n",
        "        return v.T\n",
        "\n",
        "    def visible_to_hidden(self, v):\n",
        "\n",
        "        v = v.T.copy()\n",
        "\n",
        "        # (h x v) @ (v x b) + (h x 1) = (h x b)\n",
        "        p_h_v = self.sigmoid(self.W @ v + self.b_h)\n",
        "        h = self.bernoulli_array(p_h_v, (p_h_v.shape[0], p_h_v.shape[1]))\n",
        "\n",
        "        return h.T\n",
        "\n",
        "    def gradient_descent(self, v_0, p_h_v_0, v_n, p_h_v_n):\n",
        "\n",
        "        # Compute the gradients\n",
        "        # (h x b) @ (b x v) - (h x b) @ (b x v) = (h x v)\n",
        "        self.dW = (p_h_v_0 @ v_0 - p_h_v_n @ v_n)/self.batch_size\n",
        "        self.db_h = np.mean(p_h_v_0 - p_h_v_n, axis=1)[:, np.newaxis]\n",
        "        self.db_v = np.mean(v_0 - v_n, axis=0)[:, np.newaxis]\n",
        "        \n",
        "        # Weight update\n",
        "        self.W   = self.W   + self.lr * self.dW\n",
        "        self.b_h = self.b_h + self.lr * self.db_h\n",
        "        self.b_v = self.b_v + self.lr * self.db_v\n",
        "\n",
        "\n",
        "    def reconstruction_error(self, v):\n",
        "        # Sample hidden state\n",
        "        p_h_v = self.sigmoid(self.W @ v + self.b_h)\n",
        "        h = self.bernoulli_array(p_h_v, (p_h_v.shape[0], p_h_v.shape[1]))\n",
        "\n",
        "        # For prior RBM\n",
        "        p_l_h = self.sigmoid(self.W_prior @ h + self.b_h_prior)\n",
        "        l = self.bernoulli_array(p_l_h, (p_l_h.shape[0], p_l_h.shape[1]))\n",
        "\n",
        "        p_h_l = self.sigmoid(self.W_prior.T @ l + self.b_v_prior)\n",
        "        h_cap = self.bernoulli_array(p_h_l, (p_h_l.shape[0], p_h_l.shape[1]))\n",
        "\n",
        "        # Sample viible state\n",
        "        p_v_h = self.sigmoid(self.W.T @ h_cap + self.b_v)\n",
        "        v_sampled = self.bernoulli_array(p_v_h, (p_v_h.shape[0], p_v_h.shape[1]))    \n",
        "\n",
        "        return np.sum(np.mean((v-v_sampled)**2, axis=1), axis=0)\n",
        "\n",
        "\n",
        "    def reconstruct_image(self, v):\n",
        "        # Sample hidden state\n",
        "        p_h_v = self.sigmoid(self.W @ v + self.b_h)\n",
        "        h = self.bernoulli_array(p_h_v, (p_h_v.shape[0], p_h_v.shape[1]))\n",
        "\n",
        "        # For prior RBM\n",
        "        p_l_h = self.sigmoid(self.W_prior @ h + self.b_h_prior)\n",
        "        l = self.bernoulli_array(p_l_h, (p_l_h.shape[0], p_l_h.shape[1]))\n",
        "\n",
        "        p_h_l = self.sigmoid(self.W_prior.T @ l + self.b_v_prior)\n",
        "        h_cap = self.bernoulli_array(p_h_l, (p_h_l.shape[0], p_h_l.shape[1]))\n",
        "\n",
        "        # Sample viible state\n",
        "        p_v_h = self.sigmoid(self.W.T @ h_cap + self.b_v)\n",
        "        v_sampled = self.bernoulli_array(p_v_h, (p_v_h.shape[0], p_v_h.shape[1]))    \n",
        "\n",
        "        return v_sampled\n",
        "\n",
        "\n",
        "    def Train(self, train, val):\n",
        "\n",
        "        num_batches = int(train.shape[0]/self.batch_size)\n",
        "        train_loss = []\n",
        "        val_loss = []\n",
        "\n",
        "        for epoch in range(self.epochs):\n",
        "\n",
        "            # Shuffling the data\n",
        "            train = np.random.permutation(train)\n",
        "\n",
        "            # Splitting data into batches\n",
        "            batches = np.array_split(train, num_batches)\n",
        "\n",
        "            for i in range(num_batches):\n",
        "\n",
        "                # visible units from data\n",
        "                v_0 = batches[i].T\n",
        "\n",
        "                # (h x v) @ (v x b) + (h x 1) = (h x b)\n",
        "                p_h_v_0 = self.sigmoid(self.W @ v_0 + self.b_h)\n",
        "                h_0 = self.bernoulli_array(p_h_v_0, (p_h_v_0.shape[0], p_h_v_0.shape[1]))\n",
        "\n",
        "                # For prior RBM\n",
        "                p_l_h_0 = self.sigmoid(self.W_prior @ h_0 + self.b_h_prior)\n",
        "                l_0 = self.bernoulli_array(p_l_h_0, (p_l_h_0.shape[0], p_l_h_0.shape[1]))\n",
        "\n",
        "                p_h_l_0 = self.sigmoid(self.W_prior.T @ l_0 + self.b_v_prior)\n",
        "                h_0_cap = self.bernoulli_array(p_h_l_0, (p_h_l_0.shape[0], p_h_l_0.shape[1]))\n",
        "\n",
        "                # Run the markov chain\n",
        "                v_n, h_n, p_h_v_n = self.gibbs_sampling(h_0_cap)\n",
        "\n",
        "                # Compute gradients\n",
        "                self.gradient_descent(v_0.T, p_h_v_0, v_n.T, p_h_v_n)\n",
        "\n",
        "            # Compute reconstruction errror\n",
        "            error_train = self.reconstruction_error(train.T)\n",
        "            error_val = self.reconstruction_error(val.T)\n",
        "\n",
        "            print(f\"Epoch {epoch+1} ------> Error => Train : {error_train}, Val : {error_val}\")\n",
        " \n",
        "            train_loss.append(error_train)\n",
        "            val_loss.append(error_val)\n",
        "\n",
        "        return train_loss, val_loss"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j7wPJE2JZai0"
      },
      "source": [
        "# RBM config\n",
        "num_hidden = 256 # number of hidden units\n",
        "lr = 0.001 # learning rate for gradient descent\n",
        "n = 1 # number of Gibbs sampling steps\n",
        "batch_size = 100 # mini batch size for gradient update\n",
        "epochs = 300 # number of epochs"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aUqKEOeXZko9",
        "outputId": "83e57c07-93bf-4820-903a-dd5c9a47c46f"
      },
      "source": [
        "rbm_4 = RBM_ret(num_hidden, val.shape[1], lr, n, batch_size, epochs, rbm_2.W, rbm_2.b_v, rbm_2.b_h, rbm_1.W, rbm_1.b_v, rbm_1.b_h)\n",
        "train_loss, val_loss = rbm_4.Train(train, val)"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:38: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 ------> Error => Train : 96.52523529411765, Val : 96.30199999999999\n",
            "Epoch 2 ------> Error => Train : 96.98264705882353, Val : 96.72277777777778\n",
            "Epoch 3 ------> Error => Train : 97.20229411764706, Val : 97.13677777777778\n",
            "Epoch 4 ------> Error => Train : 97.39856862745097, Val : 97.14500000000001\n",
            "Epoch 5 ------> Error => Train : 97.34294117647059, Val : 97.16055555555556\n",
            "Epoch 6 ------> Error => Train : 97.47003921568628, Val : 97.05288888888889\n",
            "Epoch 7 ------> Error => Train : 97.48356862745098, Val : 97.28800000000001\n",
            "Epoch 8 ------> Error => Train : 97.62427450980394, Val : 97.41366666666667\n",
            "Epoch 9 ------> Error => Train : 97.54786274509804, Val : 97.29533333333333\n",
            "Epoch 10 ------> Error => Train : 97.38482352941176, Val : 97.31977777777777\n",
            "Epoch 11 ------> Error => Train : 97.43280392156862, Val : 97.2731111111111\n",
            "Epoch 12 ------> Error => Train : 97.46198039215686, Val : 97.12177777777777\n",
            "Epoch 13 ------> Error => Train : 97.36788235294118, Val : 96.92855555555556\n",
            "Epoch 14 ------> Error => Train : 97.37029411764706, Val : 97.22622222222222\n",
            "Epoch 15 ------> Error => Train : 97.4367843137255, Val : 97.23266666666666\n",
            "Epoch 16 ------> Error => Train : 97.40074509803921, Val : 97.255\n",
            "Epoch 17 ------> Error => Train : 97.34876470588236, Val : 97.09422222222221\n",
            "Epoch 18 ------> Error => Train : 97.32727450980391, Val : 97.14666666666666\n",
            "Epoch 19 ------> Error => Train : 97.26392156862745, Val : 97.115\n",
            "Epoch 20 ------> Error => Train : 97.17735294117648, Val : 96.97577777777778\n",
            "Epoch 21 ------> Error => Train : 97.19907843137256, Val : 96.94744444444444\n",
            "Epoch 22 ------> Error => Train : 97.13445098039216, Val : 97.10922222222223\n",
            "Epoch 23 ------> Error => Train : 97.126, Val : 97.08133333333333\n",
            "Epoch 24 ------> Error => Train : 97.0955294117647, Val : 96.759\n",
            "Epoch 25 ------> Error => Train : 97.12827450980393, Val : 96.85744444444444\n",
            "Epoch 26 ------> Error => Train : 97.13803921568629, Val : 96.86166666666665\n",
            "Epoch 27 ------> Error => Train : 97.04894117647059, Val : 96.813\n",
            "Epoch 28 ------> Error => Train : 97.01443137254901, Val : 96.982\n",
            "Epoch 29 ------> Error => Train : 97.01227450980392, Val : 96.62566666666666\n",
            "Epoch 30 ------> Error => Train : 96.97472549019608, Val : 96.54333333333334\n",
            "Epoch 31 ------> Error => Train : 96.888, Val : 96.6391111111111\n",
            "Epoch 32 ------> Error => Train : 96.92601960784313, Val : 96.60022222222221\n",
            "Epoch 33 ------> Error => Train : 96.84717647058824, Val : 96.586\n",
            "Epoch 34 ------> Error => Train : 96.8314705882353, Val : 96.70722222222223\n",
            "Epoch 35 ------> Error => Train : 96.71109803921568, Val : 96.48544444444445\n",
            "Epoch 36 ------> Error => Train : 96.70901960784315, Val : 96.50822222222223\n",
            "Epoch 37 ------> Error => Train : 96.65017647058824, Val : 96.77233333333334\n",
            "Epoch 38 ------> Error => Train : 96.59580392156863, Val : 96.6541111111111\n",
            "Epoch 39 ------> Error => Train : 96.64035294117647, Val : 96.32688888888889\n",
            "Epoch 40 ------> Error => Train : 96.7387450980392, Val : 96.346\n",
            "Epoch 41 ------> Error => Train : 96.57186274509803, Val : 96.56377777777777\n",
            "Epoch 42 ------> Error => Train : 96.64723529411765, Val : 96.36000000000001\n",
            "Epoch 43 ------> Error => Train : 96.58239215686274, Val : 96.42744444444445\n",
            "Epoch 44 ------> Error => Train : 96.48033333333333, Val : 96.33855555555556\n",
            "Epoch 45 ------> Error => Train : 96.48335294117648, Val : 96.16166666666666\n",
            "Epoch 46 ------> Error => Train : 96.43329411764705, Val : 96.425\n",
            "Epoch 47 ------> Error => Train : 96.33382352941176, Val : 96.169\n",
            "Epoch 48 ------> Error => Train : 96.47601960784314, Val : 96.13411111111111\n",
            "Epoch 49 ------> Error => Train : 96.42864705882353, Val : 96.20711111111112\n",
            "Epoch 50 ------> Error => Train : 96.24264705882352, Val : 96.35133333333333\n",
            "Epoch 51 ------> Error => Train : 96.3228431372549, Val : 96.2058888888889\n",
            "Epoch 52 ------> Error => Train : 96.29456862745099, Val : 96.38977777777778\n",
            "Epoch 53 ------> Error => Train : 96.24872549019608, Val : 95.95288888888888\n",
            "Epoch 54 ------> Error => Train : 96.17733333333334, Val : 96.22222222222223\n",
            "Epoch 55 ------> Error => Train : 96.19250980392157, Val : 96.12444444444445\n",
            "Epoch 56 ------> Error => Train : 96.20250980392157, Val : 95.984\n",
            "Epoch 57 ------> Error => Train : 96.02211764705883, Val : 95.81511111111112\n",
            "Epoch 58 ------> Error => Train : 96.14807843137255, Val : 95.75755555555557\n",
            "Epoch 59 ------> Error => Train : 96.0677843137255, Val : 95.77033333333333\n",
            "Epoch 60 ------> Error => Train : 96.01599999999999, Val : 95.96266666666666\n",
            "Epoch 61 ------> Error => Train : 95.89776470588234, Val : 95.90477777777778\n",
            "Epoch 62 ------> Error => Train : 96.10901960784314, Val : 95.96766666666667\n",
            "Epoch 63 ------> Error => Train : 96.06737254901961, Val : 96.0231111111111\n",
            "Epoch 64 ------> Error => Train : 95.83250980392157, Val : 95.93766666666666\n",
            "Epoch 65 ------> Error => Train : 95.83131372549019, Val : 95.63444444444444\n",
            "Epoch 66 ------> Error => Train : 95.83649019607844, Val : 95.72544444444443\n",
            "Epoch 67 ------> Error => Train : 95.84011764705883, Val : 95.82688888888889\n",
            "Epoch 68 ------> Error => Train : 95.84639215686275, Val : 95.6591111111111\n",
            "Epoch 69 ------> Error => Train : 95.81590196078432, Val : 95.60755555555556\n",
            "Epoch 70 ------> Error => Train : 95.84203921568628, Val : 95.91844444444445\n",
            "Epoch 71 ------> Error => Train : 95.7778431372549, Val : 95.68577777777779\n",
            "Epoch 72 ------> Error => Train : 95.79045098039217, Val : 95.7238888888889\n",
            "Epoch 73 ------> Error => Train : 95.63345098039215, Val : 95.61622222222222\n",
            "Epoch 74 ------> Error => Train : 95.71880392156862, Val : 95.62622222222222\n",
            "Epoch 75 ------> Error => Train : 95.6085294117647, Val : 95.49533333333333\n",
            "Epoch 76 ------> Error => Train : 95.5443137254902, Val : 95.48777777777777\n",
            "Epoch 77 ------> Error => Train : 95.65476470588236, Val : 95.50666666666667\n",
            "Epoch 78 ------> Error => Train : 95.6030980392157, Val : 95.47677777777777\n",
            "Epoch 79 ------> Error => Train : 95.49592156862745, Val : 95.30422222222222\n",
            "Epoch 80 ------> Error => Train : 95.61254901960785, Val : 95.44122222222222\n",
            "Epoch 81 ------> Error => Train : 95.47170588235295, Val : 95.209\n",
            "Epoch 82 ------> Error => Train : 95.54749019607844, Val : 95.38166666666666\n",
            "Epoch 83 ------> Error => Train : 95.375, Val : 95.24177777777777\n",
            "Epoch 84 ------> Error => Train : 95.43807843137255, Val : 95.3728888888889\n",
            "Epoch 85 ------> Error => Train : 95.4958431372549, Val : 95.18866666666666\n",
            "Epoch 86 ------> Error => Train : 95.41680392156863, Val : 95.20922222222222\n",
            "Epoch 87 ------> Error => Train : 95.38496078431373, Val : 95.02333333333334\n",
            "Epoch 88 ------> Error => Train : 95.33858823529411, Val : 95.17266666666666\n",
            "Epoch 89 ------> Error => Train : 95.32541176470588, Val : 95.10577777777777\n",
            "Epoch 90 ------> Error => Train : 95.22588235294117, Val : 94.76788888888889\n",
            "Epoch 91 ------> Error => Train : 95.37374509803922, Val : 95.23188888888889\n",
            "Epoch 92 ------> Error => Train : 95.30741176470588, Val : 95.23444444444445\n",
            "Epoch 93 ------> Error => Train : 95.28223529411764, Val : 94.9618888888889\n",
            "Epoch 94 ------> Error => Train : 95.29919607843138, Val : 95.27866666666667\n",
            "Epoch 95 ------> Error => Train : 95.31174509803921, Val : 95.242\n",
            "Epoch 96 ------> Error => Train : 95.23778431372548, Val : 95.10822222222221\n",
            "Epoch 97 ------> Error => Train : 95.12680392156862, Val : 94.81666666666666\n",
            "Epoch 98 ------> Error => Train : 95.05760784313725, Val : 94.83555555555556\n",
            "Epoch 99 ------> Error => Train : 95.15343137254902, Val : 95.04433333333333\n",
            "Epoch 100 ------> Error => Train : 95.0573725490196, Val : 94.94922222222222\n",
            "Epoch 101 ------> Error => Train : 95.00323529411766, Val : 94.85122222222222\n",
            "Epoch 102 ------> Error => Train : 95.00417647058823, Val : 95.02655555555556\n",
            "Epoch 103 ------> Error => Train : 95.10998039215687, Val : 94.97755555555554\n",
            "Epoch 104 ------> Error => Train : 95.10278431372548, Val : 94.91666666666667\n",
            "Epoch 105 ------> Error => Train : 95.07060784313725, Val : 94.78933333333333\n",
            "Epoch 106 ------> Error => Train : 95.12680392156862, Val : 94.96944444444443\n",
            "Epoch 107 ------> Error => Train : 94.95105882352941, Val : 95.00488888888889\n",
            "Epoch 108 ------> Error => Train : 95.06023529411765, Val : 94.87544444444444\n",
            "Epoch 109 ------> Error => Train : 94.89068627450982, Val : 94.54744444444445\n",
            "Epoch 110 ------> Error => Train : 94.92723529411764, Val : 94.76055555555556\n",
            "Epoch 111 ------> Error => Train : 94.92801960784314, Val : 94.99911111111112\n",
            "Epoch 112 ------> Error => Train : 94.83570588235294, Val : 94.51144444444444\n",
            "Epoch 113 ------> Error => Train : 94.88643137254903, Val : 94.76033333333334\n",
            "Epoch 114 ------> Error => Train : 94.75921568627452, Val : 94.66866666666667\n",
            "Epoch 115 ------> Error => Train : 94.7943137254902, Val : 94.55988888888889\n",
            "Epoch 116 ------> Error => Train : 94.77764705882353, Val : 94.64611111111111\n",
            "Epoch 117 ------> Error => Train : 94.74880392156862, Val : 94.61677777777777\n",
            "Epoch 118 ------> Error => Train : 94.84201960784313, Val : 94.58722222222222\n",
            "Epoch 119 ------> Error => Train : 94.81192156862744, Val : 94.75222222222223\n",
            "Epoch 120 ------> Error => Train : 94.64678431372549, Val : 94.57277777777779\n",
            "Epoch 121 ------> Error => Train : 94.61343137254902, Val : 94.48688888888888\n",
            "Epoch 122 ------> Error => Train : 94.67350980392158, Val : 94.63111111111111\n",
            "Epoch 123 ------> Error => Train : 94.68511764705883, Val : 94.79888888888888\n",
            "Epoch 124 ------> Error => Train : 94.6193137254902, Val : 94.27211111111112\n",
            "Epoch 125 ------> Error => Train : 94.58654901960784, Val : 94.33544444444445\n",
            "Epoch 126 ------> Error => Train : 94.49247058823529, Val : 94.48977777777777\n",
            "Epoch 127 ------> Error => Train : 94.68382352941177, Val : 94.52377777777778\n",
            "Epoch 128 ------> Error => Train : 94.61519607843138, Val : 94.46411111111111\n",
            "Epoch 129 ------> Error => Train : 94.61776470588235, Val : 94.48766666666667\n",
            "Epoch 130 ------> Error => Train : 94.59235294117647, Val : 94.47488888888888\n",
            "Epoch 131 ------> Error => Train : 94.58339215686274, Val : 94.37422222222223\n",
            "Epoch 132 ------> Error => Train : 94.5279019607843, Val : 94.32666666666665\n",
            "Epoch 133 ------> Error => Train : 94.52037254901961, Val : 94.5818888888889\n",
            "Epoch 134 ------> Error => Train : 94.49796078431373, Val : 94.25088888888888\n",
            "Epoch 135 ------> Error => Train : 94.40364705882354, Val : 94.43311111111112\n",
            "Epoch 136 ------> Error => Train : 94.42009803921569, Val : 94.23555555555555\n",
            "Epoch 137 ------> Error => Train : 94.42735294117648, Val : 94.25177777777779\n",
            "Epoch 138 ------> Error => Train : 94.45898039215686, Val : 94.33733333333333\n",
            "Epoch 139 ------> Error => Train : 94.501, Val : 94.37155555555556\n",
            "Epoch 140 ------> Error => Train : 94.39880392156863, Val : 94.29544444444444\n",
            "Epoch 141 ------> Error => Train : 94.31725490196078, Val : 94.31022222222222\n",
            "Epoch 142 ------> Error => Train : 94.44060784313726, Val : 94.17622222222222\n",
            "Epoch 143 ------> Error => Train : 94.33019607843138, Val : 94.40444444444444\n",
            "Epoch 144 ------> Error => Train : 94.35119607843137, Val : 94.14533333333333\n",
            "Epoch 145 ------> Error => Train : 94.31680392156862, Val : 94.30799999999999\n",
            "Epoch 146 ------> Error => Train : 94.2421568627451, Val : 94.0361111111111\n",
            "Epoch 147 ------> Error => Train : 94.33750980392156, Val : 94.08588888888889\n",
            "Epoch 148 ------> Error => Train : 94.20239215686274, Val : 94.21733333333333\n",
            "Epoch 149 ------> Error => Train : 94.29556862745099, Val : 94.27044444444445\n",
            "Epoch 150 ------> Error => Train : 94.32345098039215, Val : 94.08211111111112\n",
            "Epoch 151 ------> Error => Train : 94.26313725490195, Val : 94.12255555555555\n",
            "Epoch 152 ------> Error => Train : 94.16288235294118, Val : 94.005\n",
            "Epoch 153 ------> Error => Train : 94.21227450980392, Val : 94.25266666666667\n",
            "Epoch 154 ------> Error => Train : 94.2243137254902, Val : 93.99533333333333\n",
            "Epoch 155 ------> Error => Train : 94.16160784313726, Val : 94.3578888888889\n",
            "Epoch 156 ------> Error => Train : 94.10849019607844, Val : 94.09277777777777\n",
            "Epoch 157 ------> Error => Train : 94.24423529411764, Val : 94.14966666666666\n",
            "Epoch 158 ------> Error => Train : 94.17558823529411, Val : 93.97411111111111\n",
            "Epoch 159 ------> Error => Train : 94.18111764705881, Val : 94.08211111111112\n",
            "Epoch 160 ------> Error => Train : 94.11172549019608, Val : 93.94288888888889\n",
            "Epoch 161 ------> Error => Train : 94.12625490196079, Val : 93.84533333333334\n",
            "Epoch 162 ------> Error => Train : 94.116, Val : 93.94644444444444\n",
            "Epoch 163 ------> Error => Train : 94.13264705882354, Val : 94.00366666666666\n",
            "Epoch 164 ------> Error => Train : 94.06313725490196, Val : 93.9328888888889\n",
            "Epoch 165 ------> Error => Train : 94.08870588235294, Val : 94.02588888888889\n",
            "Epoch 166 ------> Error => Train : 94.1087843137255, Val : 94.09644444444444\n",
            "Epoch 167 ------> Error => Train : 94.10188235294117, Val : 94.109\n",
            "Epoch 168 ------> Error => Train : 94.04735294117647, Val : 93.95066666666668\n",
            "Epoch 169 ------> Error => Train : 93.93, Val : 93.76599999999999\n",
            "Epoch 170 ------> Error => Train : 94.00190196078431, Val : 93.82277777777779\n",
            "Epoch 171 ------> Error => Train : 94.08954901960784, Val : 93.92077777777777\n",
            "Epoch 172 ------> Error => Train : 94.00749019607844, Val : 93.95455555555554\n",
            "Epoch 173 ------> Error => Train : 93.90223529411765, Val : 93.84355555555555\n",
            "Epoch 174 ------> Error => Train : 93.95394117647058, Val : 93.94544444444443\n",
            "Epoch 175 ------> Error => Train : 93.95927450980392, Val : 93.77166666666666\n",
            "Epoch 176 ------> Error => Train : 93.94147058823529, Val : 93.58133333333333\n",
            "Epoch 177 ------> Error => Train : 93.99211764705882, Val : 94.08477777777779\n",
            "Epoch 178 ------> Error => Train : 93.95815686274508, Val : 94.00755555555557\n",
            "Epoch 179 ------> Error => Train : 93.92733333333334, Val : 93.71155555555555\n",
            "Epoch 180 ------> Error => Train : 93.96754901960784, Val : 93.84511111111112\n",
            "Epoch 181 ------> Error => Train : 93.96760784313724, Val : 93.70288888888888\n",
            "Epoch 182 ------> Error => Train : 93.88843137254902, Val : 93.997\n",
            "Epoch 183 ------> Error => Train : 93.83245098039215, Val : 93.84211111111111\n",
            "Epoch 184 ------> Error => Train : 93.90333333333334, Val : 93.78044444444444\n",
            "Epoch 185 ------> Error => Train : 93.89874509803921, Val : 93.654\n",
            "Epoch 186 ------> Error => Train : 93.81907843137255, Val : 93.804\n",
            "Epoch 187 ------> Error => Train : 93.78992156862745, Val : 93.75766666666667\n",
            "Epoch 188 ------> Error => Train : 93.75888235294117, Val : 93.78466666666667\n",
            "Epoch 189 ------> Error => Train : 93.73327450980392, Val : 93.54366666666667\n",
            "Epoch 190 ------> Error => Train : 93.76511764705882, Val : 93.73444444444445\n",
            "Epoch 191 ------> Error => Train : 93.85807843137255, Val : 93.42811111111112\n",
            "Epoch 192 ------> Error => Train : 93.75156862745098, Val : 93.55911111111112\n",
            "Epoch 193 ------> Error => Train : 93.65098039215687, Val : 93.46444444444444\n",
            "Epoch 194 ------> Error => Train : 93.61529411764707, Val : 93.46866666666666\n",
            "Epoch 195 ------> Error => Train : 93.6597843137255, Val : 93.34188888888889\n",
            "Epoch 196 ------> Error => Train : 93.72454901960785, Val : 93.56433333333334\n",
            "Epoch 197 ------> Error => Train : 93.72901960784313, Val : 93.59077777777777\n",
            "Epoch 198 ------> Error => Train : 93.76556862745097, Val : 93.71088888888889\n",
            "Epoch 199 ------> Error => Train : 93.7037450980392, Val : 93.49622222222223\n",
            "Epoch 200 ------> Error => Train : 93.6370588235294, Val : 93.32811111111111\n",
            "Epoch 201 ------> Error => Train : 93.68419607843137, Val : 93.67733333333334\n",
            "Epoch 202 ------> Error => Train : 93.67696078431374, Val : 93.56788888888889\n",
            "Epoch 203 ------> Error => Train : 93.6292156862745, Val : 93.67988888888888\n",
            "Epoch 204 ------> Error => Train : 93.67839215686274, Val : 93.33166666666666\n",
            "Epoch 205 ------> Error => Train : 93.6061568627451, Val : 93.465\n",
            "Epoch 206 ------> Error => Train : 93.66105882352942, Val : 93.68922222222221\n",
            "Epoch 207 ------> Error => Train : 93.74227450980392, Val : 93.61488888888888\n",
            "Epoch 208 ------> Error => Train : 93.61382352941177, Val : 93.43055555555556\n",
            "Epoch 209 ------> Error => Train : 93.57337254901961, Val : 93.39244444444445\n",
            "Epoch 210 ------> Error => Train : 93.65623529411765, Val : 93.53655555555555\n",
            "Epoch 211 ------> Error => Train : 93.64394117647058, Val : 93.66877777777779\n",
            "Epoch 212 ------> Error => Train : 93.70319607843138, Val : 93.56755555555556\n",
            "Epoch 213 ------> Error => Train : 93.57386274509804, Val : 93.42188888888889\n",
            "Epoch 214 ------> Error => Train : 93.50392156862745, Val : 93.4421111111111\n",
            "Epoch 215 ------> Error => Train : 93.5344705882353, Val : 93.358\n",
            "Epoch 216 ------> Error => Train : 93.61113725490196, Val : 93.57944444444445\n",
            "Epoch 217 ------> Error => Train : 93.5815294117647, Val : 93.38444444444444\n",
            "Epoch 218 ------> Error => Train : 93.50839215686274, Val : 93.39188888888889\n",
            "Epoch 219 ------> Error => Train : 93.57052941176471, Val : 93.494\n",
            "Epoch 220 ------> Error => Train : 93.4461568627451, Val : 93.45611111111111\n",
            "Epoch 221 ------> Error => Train : 93.50641176470589, Val : 93.36733333333333\n",
            "Epoch 222 ------> Error => Train : 93.45949019607843, Val : 93.42977777777779\n",
            "Epoch 223 ------> Error => Train : 93.5121568627451, Val : 93.40066666666667\n",
            "Epoch 224 ------> Error => Train : 93.50886274509804, Val : 93.62955555555556\n",
            "Epoch 225 ------> Error => Train : 93.38286274509804, Val : 93.25588888888889\n",
            "Epoch 226 ------> Error => Train : 93.52488235294118, Val : 93.38777777777779\n",
            "Epoch 227 ------> Error => Train : 93.52594117647058, Val : 93.25588888888889\n",
            "Epoch 228 ------> Error => Train : 93.37466666666667, Val : 93.28766666666667\n",
            "Epoch 229 ------> Error => Train : 93.43629411764705, Val : 93.14377777777777\n",
            "Epoch 230 ------> Error => Train : 93.48498039215687, Val : 93.05688888888888\n",
            "Epoch 231 ------> Error => Train : 93.60011764705882, Val : 93.45744444444445\n",
            "Epoch 232 ------> Error => Train : 93.44739215686275, Val : 93.1681111111111\n",
            "Epoch 233 ------> Error => Train : 93.49300000000001, Val : 93.3531111111111\n",
            "Epoch 234 ------> Error => Train : 93.44707843137255, Val : 93.23144444444445\n",
            "Epoch 235 ------> Error => Train : 93.42443137254901, Val : 93.45555555555555\n",
            "Epoch 236 ------> Error => Train : 93.4670588235294, Val : 93.22144444444444\n",
            "Epoch 237 ------> Error => Train : 93.35643137254903, Val : 93.24877777777778\n",
            "Epoch 238 ------> Error => Train : 93.39574509803921, Val : 93.19955555555555\n",
            "Epoch 239 ------> Error => Train : 93.35358823529413, Val : 93.30522222222223\n",
            "Epoch 240 ------> Error => Train : 93.40105882352941, Val : 93.24522222222222\n",
            "Epoch 241 ------> Error => Train : 93.30813725490196, Val : 93.40366666666667\n",
            "Epoch 242 ------> Error => Train : 93.34639215686275, Val : 93.19444444444443\n",
            "Epoch 243 ------> Error => Train : 93.34813725490196, Val : 93.42699999999999\n",
            "Epoch 244 ------> Error => Train : 93.32101960784314, Val : 93.25344444444444\n",
            "Epoch 245 ------> Error => Train : 93.35813725490196, Val : 92.98755555555556\n",
            "Epoch 246 ------> Error => Train : 93.38868627450981, Val : 93.02133333333333\n",
            "Epoch 247 ------> Error => Train : 93.49539215686274, Val : 93.35544444444446\n",
            "Epoch 248 ------> Error => Train : 93.38572549019608, Val : 93.20277777777778\n",
            "Epoch 249 ------> Error => Train : 93.38754901960785, Val : 93.29544444444444\n",
            "Epoch 250 ------> Error => Train : 93.25849019607844, Val : 93.36155555555555\n",
            "Epoch 251 ------> Error => Train : 93.3117843137255, Val : 93.20644444444444\n",
            "Epoch 252 ------> Error => Train : 93.20670588235294, Val : 93.15311111111112\n",
            "Epoch 253 ------> Error => Train : 93.3523137254902, Val : 93.03222222222222\n",
            "Epoch 254 ------> Error => Train : 93.28370588235295, Val : 93.09311111111111\n",
            "Epoch 255 ------> Error => Train : 93.20564705882353, Val : 92.91444444444444\n",
            "Epoch 256 ------> Error => Train : 93.2313725490196, Val : 93.13422222222222\n",
            "Epoch 257 ------> Error => Train : 93.19127450980392, Val : 93.12\n",
            "Epoch 258 ------> Error => Train : 93.32672549019608, Val : 93.235\n",
            "Epoch 259 ------> Error => Train : 93.1779411764706, Val : 93.27888888888889\n",
            "Epoch 260 ------> Error => Train : 93.18064705882352, Val : 93.01488888888889\n",
            "Epoch 261 ------> Error => Train : 93.28164705882352, Val : 93.26233333333334\n",
            "Epoch 262 ------> Error => Train : 93.30043137254903, Val : 93.14277777777778\n",
            "Epoch 263 ------> Error => Train : 93.18090196078431, Val : 93.06011111111111\n",
            "Epoch 264 ------> Error => Train : 93.1476862745098, Val : 93.43711111111111\n",
            "Epoch 265 ------> Error => Train : 93.16678431372549, Val : 92.86355555555555\n",
            "Epoch 266 ------> Error => Train : 93.19354901960784, Val : 92.94044444444444\n",
            "Epoch 267 ------> Error => Train : 93.25519607843137, Val : 93.16277777777778\n",
            "Epoch 268 ------> Error => Train : 93.29792156862744, Val : 93.29966666666667\n",
            "Epoch 269 ------> Error => Train : 93.1034705882353, Val : 92.81588888888888\n",
            "Epoch 270 ------> Error => Train : 93.26049019607842, Val : 93.23866666666666\n",
            "Epoch 271 ------> Error => Train : 93.10154901960783, Val : 93.092\n",
            "Epoch 272 ------> Error => Train : 93.16398039215686, Val : 92.97255555555556\n",
            "Epoch 273 ------> Error => Train : 93.2546862745098, Val : 93.16677777777778\n",
            "Epoch 274 ------> Error => Train : 93.13107843137254, Val : 93.00844444444445\n",
            "Epoch 275 ------> Error => Train : 93.12909803921568, Val : 93.08488888888888\n",
            "Epoch 276 ------> Error => Train : 93.11841176470588, Val : 92.834\n",
            "Epoch 277 ------> Error => Train : 93.03460784313725, Val : 92.92555555555556\n",
            "Epoch 278 ------> Error => Train : 93.15876470588235, Val : 93.24211111111111\n",
            "Epoch 279 ------> Error => Train : 93.1016862745098, Val : 92.98511111111111\n",
            "Epoch 280 ------> Error => Train : 92.9685294117647, Val : 92.89922222222222\n",
            "Epoch 281 ------> Error => Train : 93.04176470588234, Val : 93.12244444444444\n",
            "Epoch 282 ------> Error => Train : 93.13976470588236, Val : 93.10044444444443\n",
            "Epoch 283 ------> Error => Train : 93.03711764705882, Val : 92.83044444444445\n",
            "Epoch 284 ------> Error => Train : 93.02531372549021, Val : 93.08333333333334\n",
            "Epoch 285 ------> Error => Train : 93.08364705882352, Val : 92.84855555555555\n",
            "Epoch 286 ------> Error => Train : 93.09778431372548, Val : 93.01022222222223\n",
            "Epoch 287 ------> Error => Train : 92.94056862745097, Val : 92.73555555555555\n",
            "Epoch 288 ------> Error => Train : 93.00754901960784, Val : 92.97422222222222\n",
            "Epoch 289 ------> Error => Train : 93.03145098039215, Val : 92.77666666666667\n",
            "Epoch 290 ------> Error => Train : 92.97225490196078, Val : 93.13166666666667\n",
            "Epoch 291 ------> Error => Train : 93.02590196078431, Val : 92.812\n",
            "Epoch 292 ------> Error => Train : 92.94992156862746, Val : 92.84544444444444\n",
            "Epoch 293 ------> Error => Train : 93.05103921568627, Val : 93.01044444444445\n",
            "Epoch 294 ------> Error => Train : 93.08013725490197, Val : 92.9568888888889\n",
            "Epoch 295 ------> Error => Train : 92.95543137254901, Val : 93.02477777777779\n",
            "Epoch 296 ------> Error => Train : 92.97156862745098, Val : 92.80188888888888\n",
            "Epoch 297 ------> Error => Train : 92.8936274509804, Val : 92.79522222222222\n",
            "Epoch 298 ------> Error => Train : 92.99333333333334, Val : 92.726\n",
            "Epoch 299 ------> Error => Train : 92.96756862745099, Val : 92.94133333333335\n",
            "Epoch 300 ------> Error => Train : 92.80549019607844, Val : 92.90966666666667\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "ytinWSmJZ4LL",
        "outputId": "a32951d2-3e51-40f5-b93b-e83660b504e7"
      },
      "source": [
        "fig = plt.figure()\n",
        "plt.plot(train_loss, c='r', label=\"Train\")\n",
        "plt.plot(val_loss, c='g', label=\"Val\")\n",
        "plt.legend()\n",
        "plt.title(\"Reconstruction Error\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Error\")"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Error')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEWCAYAAABhffzLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdd3iVRdrA4d+k956QQkIg9F5CEVCaoNLEVUCsyIJ11/KJuth3UZdddde2rqLYV0DFDiiiFEGk10DoARLSe29nvj/m5CQBlFBO6nNfV668521nJspz5sw784zSWiOEEKLlcGjoAgghhKhfEviFEKKFkcAvhBAtjAR+IYRoYSTwCyFECyOBXwghWhgJ/ELUE6XUjUqpFQ1dDiEk8IuLSimVoJQqVkoVKKVSlFLvKaW8GrpcZ6KU0kqp9na6d7T1/k5V+7TW/9Naj7HDew1XSlmsf/OaP5dc7PcSzYMEfmEPE7TWXkBvoA8wp4HLc15qBu0m4KTW2uuUnw2nnqQMh1P2nVM9m9jfRZyBBH5hN1rrFOB7zAcAAEqpQUqpX5RSOUqpnUqp4TWOBSil3lVKnVRKZSulvqxxbJZS6pBSKksp9bVSKrzGMa2UulMpddB63/8opZT1WHul1BqlVK5SKkMptdi6f6318p3W1vFUa8s5USn1iFIqBXhXKTVdKbWuZr1qflNQSrkrpV5USh2zvsc6pZQ7UHX/nKrW96n3UkoNVkpttl63WSk1uMax1UqpuUqp9UqpfKXUCqVU0Pn8d7De61ml1HqgCGhnrcM9SqmDwME6/o1rnS+aMK21/MjPRfsBEoDLrdutgd3Ay9bXEUAmMBbT6BhtfR1sPb4UWAz4A87AMOv+kUAG0BdwBV4F1tZ4Tw18C/gBUUA6cKX12ELgMev7uQFDT7mufY3Xw4EK4B/W93EHpgPrTqmj7TrgP8Bqa90cgcHWa6Ot5znVuM52LyAAyAZuBpyAadbXgdbjq4HDQEdrOVYD837jbz4cSPyd/yargeNAN+t7OVvL9oO1HO51/Bvbzm/o/8/k58J+pMUv7OFLpVQ+cAJIA56y7r8JWKa1Xqa1tmitfwC2AGOVUmHAVcCdWutsrXW51nqN9bobgXe01tu01qWYrqNLlFLRNd5zntY6R2t9HFhF9beMcqANEK61LtFa12q9n4EFeEprXaq1Lv69E61dJjOA+7TWSVrrSq31L9Yyns044KDW+kOtdYXWeiEQD0yocc67WusD1nJ8UqNOZxJu/bZT88ezxvH3tNZx1vcqt+77u9Y6y3r/uvyNa54vmjAJ/MIeJmmtvTEt0c5AVRdFG2ByzeAEDAXCgEggS2udfYb7hQPHql5orQsw3xQiapyTUmO7CKh6oPwwoIBNSqk4pdSMs5Q9XWtdUoc6Yq2XG6Zlfq5q1cnqGHWr05mc1Fr7nfJTWOP4iTNcU3NfXf7GZ7qHaIIk8Au7sbbY3wNesO46AXx4SnDy1FrPsx4LUEr5neFWJzEfGgBYW7KBQFIdypCitZ6ltQ4H7gBeP8tInlPT1RYCHjXeO7TGsQygBIipw31OVatOVlHUoU7n6UzlqbmvLn9jSeXbTEjgF/b2EjBaKdUL+AiYoJS6QinlqJRysz5Qba21TgaWYwKzv1LKWSl1mfUeC4HblFK9lVKuwHPARq11wtneXCk1WSnV2voyGxO8LNbXqUC7s9xiJ9DN+t5uwNNVB7TWFuAd4F9KqXBrnS6xljHd+j6/df9lQEel1A1KKSel1FSgK+ZZRUM477+xaHok8Au70lqnAx8AT2qtTwBXA49iAuMJ4CGq/z+8GdMnH495NnC/9R4rgSeAJUAypoV9fR2L0B/YqJQqAL7G9McfsR57Gnjf2u005TfKfwD4G7ASM5rl1GcEszEPsDcDWZgHww5a6yLgWWC99f6DTrlvJjAeeBDTpfIwMF5rnVHHep0qXJ0+jv/aul58gX9j0cQoreXbmxBCtCTS4hdCiBZGAr8QQrQwEviFEKKFkcAvhBAtTJNIthQUFKSjo6MbuhhCCNGkbN26NUNrHXzq/iYR+KOjo9myZUtDF0MIIZoUpdSps8MB6eoRQogWRwK/EEK0MBL4hRCihWkSffxCCHGuysvLSUxMpKSkrslWmy43Nzdat26Ns7Nznc6XwC+EaJYSExPx9vYmOjoa64JszZLWmszMTBITE2nbtm2drpGuHiFEs1RSUkJgYGCzDvoASikCAwPP6ZuNBH4hRLPV3IN+lXOtZ8sN/CkpsHBhQ5dCCCHqXcsN/K+9BjfcAHv2NHRJhBDNUGZmJr1796Z3796EhoYSERFhe11WVva7127ZsoV7773XbmVruQ93d+0yv5csge7dG7YsQohmJzAwkB07dgDw9NNP4+XlxezZs23HKyoqcHI6cwiOjY0lNjbWbmVruS3+qsD/6acNWw4hRIsxffp07rzzTgYOHMjDDz/Mpk2buOSSS+jTpw+DBw9m//79AKxevZrx48cD5kNjxowZDB8+nHbt2vHKK69ccDlaZos/NxeOHYPwcIiLg+RkCAtr6FIJIezl/vvB2vq+aHr3hpdeOufLEhMT+eWXX3B0dCQvL4+ff/4ZJycnVq5cyaOPPsqSJUtOuyY+Pp5Vq1aRn59Pp06duOuuu+o8Zv9MWmbg373b/J48GV5+GeLjJfALIerF5MmTcXR0BCA3N5dbb72VgwcPopSivLz8jNeMGzcOV1dXXF1dCQkJITU1ldatW593GVpe4C8qgrfeMttTppjAv38/jBjRsOUSQtjPebTM7cXT09O2/cQTTzBixAi++OILEhISGD58+BmvcXV1tW07OjpSUVFxQWVoeX38L74IH3wAd9wBgwaBh4dp8X/wAXTuDNnZDV1CIUQLkZubS0REBADvvfdevb1vywv8v/wCPXrAG2+AgwN06gTvvgu33mpa/itXwsaN0KWL+UAQQgg7efjhh5kzZw59+vS54Fb8uVBa63p7s/MVGxurL3ghlvR0OHgQJk2CceNY8tB4HvvpMXb80hO3hZ9CaKiZ1DVrFhQUmMld/frBhg1wAQ9RhBANY9++fXTp0qWhi1FvzlRfpdRWrfVp40JbTov/9tthyBDzAdCvH98c+Ib9mfvZ7ldsjj/1FFx9NXz7LXzxhflWsHUrfPhhw5ZbCCEuspYT+JOTq7f79WPLSfMNYtO43vDoozBzJlxxhTmvpATee8+0+J97Dn7jSbsQQjRFLSfwV/WfubhQ2KU9+zL2AbCh+CApc/4MTk4wYwZ88w1s2wZ9+5pvAYcPw4QJ5sNACCGagZYT+BMSTG6eDRvYkXcAi7bg5uTG4rjFRP07it2pu8HVFcaPhz59zDUTJsDrr8P338P//tegxRdCiIulZQT+wkLIzDQ5efr2ZVvyNgDuG3gfAI4Ojsz5cc6Zr73zTujaFebPr6/SCiGEXbWMwH/smPndpg0AR3OO4uHswbMjn+XIvUd4/NLHWXpwKSdyT9guSchJ4Pn1z1OhK82D4U2bqmf8CiFEE9YiA39SfhIR3hE4OjjS1r8tw6KHAbA7bTcFZQU8s/YZ2r7clodXPszPx36G668313/9dUOUXgjRBI0YMYLvv/++1r6XXnqJu+6664znDx8+nAsetl5HLTLwJ+Yl0tqnOs9F1+CuAOxN38sX+77giVVPEOoVCsD+zP3QqhXExprAv349NIG5D0KIhjVt2jQWLVpUa9+iRYuYNm1aA5WoWssJ/E5OtkRsSXlJRPhE2A4HuAcQ6hVKXHocKQUpAMTfE4+nsyfxGdbZu2PHmu6eoUNlbL8Q4qyuu+46li5dalt0JSEhgZMnT7Jw4UJiY2Pp1q0bTz31VIOUrWUkaTt2jJI2Ebzy64sczjpMUn4Srb1rZ7brFtyNuLQ4gj2CcXV0xcfVh85BndmXsY+T+ScJnzrVPOAtKTFJ3m65pYEqI4Q4V/d/dz87Ui5uWubeob156crfTv4WEBDAgAEDWL58OVdffTWLFi1iypQpPProowQEBFBZWcmoUaPYtWsXPXv2vKhlO5sW0eL/vHgbIdMSeWTlI8zfNp8KS0WtFj+YwL83fS+phamEeIaglKJzUGdWHF5BxL8i+E/BKjO5a84cWLcO/v53k9ph7lwz0aue+uaEEE1Hze6eqm6eTz75hL59+9KnTx/i4uLYu3dvvZerRbT4f3RORDsoXrnyFe79zqxjWbOPH0w/f2F5IduStxHiGQJAx8COtuP3f38/Y2LGEHrzFO49/CJ/efFROr3+OiQmmhPef988BxBCNDq/1zK3p6uvvpoHHniAbdu2UVRUREBAAC+88AKbN2/G39+f6dOnU9IAk0Obf4u/rIycykJaKW/uGXCPbXeEd+0Wf0xADABxaXG2wN/Ovx0Ad8feTYWlgp+P/8za/DjeC0+j858hIyvRjPMfNw6WL6+nCgkhmgovLy9GjBjBjBkzmDZtGnl5eXh6euLr60tqairLGyhu2DXwK6XuU0rtUUrFKaXut+5brJTaYf1JUEpd5PXQTpGYSK4b+Ln44KCqq3tqi78qyGs0wZ7BAEzrPo3vb/qel696GXcnd3al7jKjfKx+/PgZePVVuOoqk9rh0CG7VkUI0fRMmzaNnTt3Mm3aNHr16kWfPn3o3LkzN9xwA0OGDGmQMtmtq0cp1R2YBQwAyoDvlFLfaq2n1jjnRSDXXmUA4NgxctzA1yMAgLkj5vLEqidsrfoqkT6ROCgHLNpCiIc55ujgyJiYMQD0aNWDXam7KCovsl2TEeZnRguNHWt2vPCCyfMvhBBWkyZNomb6+99acGX16tX1UyDs2+LvAmzUWhdprSuANcAfqg4qpRQwBVhoxzLAsWPkuoKfj2nFP37Z4+inNI4OjrVOc3Z0JtInEuC0DwWAniE92Zm6k30Z+xjUehAAGUUZ5mDbtvDQQ/Dmm2YB5rVr7VghIYS4MPYM/HuAS5VSgUopD2AsEFnj+KVAqtb64JkuVkrdrpTaopTakp6efv6lqGrx+4We9dSq7p4zBf5eob3IKs5i3fF1dA/ujr+bf3XgB/Tcubz8xBhSSzJNMricnPMvsxBC2JHdAr/Weh/wD2AF8B2wA6iscco0fqe1r7Wer7WO1VrHBgcHn39BUlLIdVf4eQae9dS2fm0BbH38NQ2MGGjb7hTUiSCPIDKKqwN/fN4R7ndcweK5UyEpCf7zn/MvsxDiomgKKwxeDOdaT7s+3NVaL9Ba99NaXwZkAwcAlFJOmG6fxfZ8f4DKvBzyXTS+rr5nPff3Wvz9I/ozs89MAHqE9DCBv0aL/0DmAQCygr3MsM6lS01e/4KCi1ENIcQ5cnNzIzMzs9kHf601mZmZuLm51fkau47jV0qFaK3TlFJRmEA/yHrociBea51oz/cHyCvMAsDX7eyBf3DkYPzd/G0fAKeaP2E+s/rNIjY8lv9s/g8n8qqzedoCf3GWedg7d675AHjkETPZSwhRr1q3bk1iYiIX1FXcRLi5udG6deuzn2hl7wlcS5RSgUA5cI/Wuqrj+3rs/VDXKqc4GwA/N7+znjui7QiyHsn6zeNKKQZEDAAgyCOI7SnbbcdqBf5xN8Hf/mYOfPaZWb5RqfOtghDiPDg7O9O2bduGLkajZNfAr7W+9Df2T7fn+9aUW2pGi9alq+dcBHkEkVKQwuM/PU5cehzrj68HrIE/Nhbuuw+Ki01+n7g4swiMEEI0As0+ZUNOWT5Qtxb/uQjyCKLCUsGzPz+LQqEx/YhZxVng4AAvvQQpKbBggUnotmSJGfYphBANrNmnbMitMA9X69LHfy6CPIJs2w8MesC2nVVco6soNNR09cTHm8ldQgjRCDT/Fr/FzLS1R4sfwMnBibkj55JXmsex3GO29XxtJk2CQYNMLn+grLIMR+V42gQyIYSoL827xV9aSq6TmTpwsfv43Z3cAejZqicezh68NfEtBkYMJLskG4u21D65f3/YuRNKS3F9xpWbv7j5opZFCCHORfMO/Hl55FiHtl7srp7Y8Fi6h3TnjXHVuXkC3AOwaAu5JaekHxowAMrLKdlmWv0L91gHND35JHz55UUtlxBCnE2zD/y5ruCpXHFyuLi9Wv7u/uy+azf9I/rb9gW4m0Rwtfr5ga9b5ZDkDanPPWrbV56VAc8+C2+/fVHLJYQQZ9O8A39uLjlu4OfkVS9vd6bAn12czaQfZ/HKTR1I3rvJtn/3Dx+BxQL79592HyGEsKfmHfjz8sh1A1/nhgv8W05uQaM5NrIvKXfeZNu/afs3ZuPoUbOOr+WU5wJCCGEnzT7w57iB30V+sPtbAj1MIrj0onRmfT2L9cfXs/nkZgBO5J0gZVD1JK5dSdvNeP/KSujYEe6+u17KKIQQzT7w57qC70Ueyvlbgj1MVs+v9n/F29vf5obPb+Cnoz8BcCL3BMkVOSgNHTIhvTQb/vhHc+GJE2bN3uzseimnEKJla/aBP8eNOqVkvhgCPQLpHtKdz/Z+Bphg/+PRHwE4mX+SpPwkgt2DCC2AzGBPmDev+uKSEvj443oppxCiZWv2gT/XDXy9gs5+7kVydaerAege0p1vb/iWIZFDmNhpIpW6km3J2wj1DSew50AyOkRAQACvXe7Dd9f0gB49zCxfIYSws2Yd+HVerll20TOg3t5zYqeJAFze9nLGdhjLuhnruKPfHQBsT9lOmFcYQe16kFFpcgg9NRxeHxsEl18Ov/4KpaX1VlYhRMvUrAN/SV42ZU7118cP0D+8P/NGzePegffa9lWt5QsQ6hVqW8SloKyArIo8EsozYNgw092zadOZbiuEEBdNsw78udOuAS5+np7fo5TikaGP0Na/OhNnpG914O8d2ptAj0DKLeXsS98HQEJOAnroUJOz/1//Mit3gUnrXFRUb2UXQrQMzTrw53RqA1z8PD3nytfVlyGRQ7h/4P3cO/BeW4K3qoRu+WX55Hg4wMCBJoXDpEmmy2f0aAgOljH+QoiLqlln56zKmXOx8/ScK6UU62ass72uCvw1V/DanrKdgcu+wvOH1ViunwoL3sZhvVnchcWLYdq0ei2zEKL5at4t/hKz0mN9dvXUxaktfoBRH4xixo9/hsmTmXK7PzN+eaT6gldfre8iCiGasWYd+O217OKFCnQ38wq2p2zHy6U6ncTSA0sps5SzPRR2eBeanR07wgGznu+yg8t4d/u79V5eIUTz0qwDf2Nv8VdYKugeUp3GobC8kHXH15HiWMxJb+vOSZMoz86kLCudcR+PY8bXMxqgxEKI5kT6+BtAzfJE+Ubh4+qDt4s3X+//mk/iPqHIUkKRJ5RHhOI8YAAzJ0LKookNWGIhRHPSrAN/TkkOjsoRT2fPhi5KLQ7KAXcnd4orirl3wL0MiRoCwOAFg/lq/1e281Ivv4TWMTGsbQOpyRub+X8tIUR9adahJLc0F183X5RSDV2U0+y4cwc+rj6EeoXa9nUM7MiGxA2218nPzsHXLYQEfwBt219SUYKbk1s9llYI0Zw068A/vfd0hkcPb+hinFHHwI6n7Wsf0L7W6+SCZCosFaedl7viG9zGTrZb2YQQzVuzfrgbGx7LdV2va+hi1FmHgA61XifnJ7M7bfdp5+U+P7e+iiSEaIaadeBvaqpa/M4OzigUJ/NPsidtD17KjSjlbzvvGf/dTJg/AsrLJambEOKcSeBvRKoCf5h3GMGewSQXJLMhcQM9W/flkq5jbOd92Au+TV5tcvrHxjZUcYUQTZQE/kbE182XYI9gwrzCCPMKY93xdWw5uYVrOl/DWxPeYtWtq2qdvzq8HPbsgcLCBiqxEKIpksDfyFzZ/kqGRg1lbIex7Msw2TundJuCt6s30X7Rtc796Y7RZuPJJ+Gqq0BrhBDibJr1qJ6m6INrPgCgtKKUH478gJ+bH1G+UQD4uPrUOndVxSGz8dprUFYGO3ZAnz6Qm2vSPPTvX69lF0I0DdLib6RcnVxZd9s6vp32rW1fzcDv7+ZPfEECRc6YoA8mpTPAE0/AgAGyqIsQ4owk8Ddirk6uuDq52l47OTjZZiGPiRmDRhPXvkY6is8/N909iYnm9d13S/ePEOI0dg38Sqn7lFJ7lFJxSqn7a+z/s1Iq3rr/n/YsQ3NTlednTIwZ5bOrq3U94dtuMw96V62C7Gyzb+tWyMhoiGIKIRoxuwV+pVR3YBYwAOgFjFdKtVdKjQCuBnpprbsBL9irDM1RVXfPJa0vwdPZk12tncHR0SzZGBYGc+fCsWN83c2JUbdA+YmEhi2wEKLRsWeLvwuwUWtdpLWuANYAfwDuAuZprUsBtNZpdixDs1O1tkC4dzg9WvVgV4wXvPIK+PnBXXfB6tVYjh/jL2Nd+KkdrN+/soFLLIRobOwZ+PcAlyqlApVSHsBYIBLoaN2/USm1Ril1xqEnSqnblVJblFJb0tPT7VjMpsXXzRc3Jzd8XH3oEdKD3cXHTF8+kNy/Cyti4Lt2FvZ5mkXav038qSGLK4RohOwW+LXW+4B/ACuA74AdQCVmCGkAMAh4CPhEnSF9ptZ6vtY6VmsdGxwcbK9iNjlBHkG09mmNUopOgZ3ILM4ksygTgBmpb3LFzfDoKAh3DmDEUfi2cPtZ7iiEaGns+nBXa71Aa91Pa30ZkA0cABKBz7WxCbAAQfYsR3Myd8RcFl67EIBOQZ0AOJh1EICs8jwAdobCH9tP4co0b/arTLKLs2vdI60wjUd+eITyyvJ6LLkQorGw96ieEOvvKEz//sfAl8AI6/6OgAsgQ0/qqJ1/O2LDTX6eqtTOBzLNmrzF5cUAOFhg5pA/E+FivimlFdZ+jPLtgW/55y//ZEfKjvoqthCiEbH3OP4lSqm9wDfAPVrrHOAdoJ1Sag+wCLhVaxlsfj7a+rXFUTlyIPMAWmuOZB/hlsjxrHW9g6iIrgT7mEVe0otqPyNJLzSvk/KT6r3MQoiGZ9eUDVrrS8+wrwy4yZ7v21I4OzrTzr8d+zP3k1GUQWF5If26jWbIjHsBCA6IBCB9xy+wPA62bIGSEjKuNJ/3idnHGqzsQoiGI7l6mriOgR05kHmAI9lHAPMtoEpIZCcogPS/PcJPWfDn8Q5sXOhIekE59IakLT/BJfc1VNGFEA1EUjY0cX3D+hKXFseaY2sA8wygStDtDwCQNusGFj1zPXsDLex55XHSgz0ASNy9HhYsAIul/gsuhGgwEvibuJl9ZwLw3M/PAdRK3ezq7YePqw/pUUGsztwKwIF+0aT37wZAYlkmzJwJ69fXb6GFEA1KAn8TF+UbxbVdryW3NJcp3abg6eJZ63iwRzA7U3fahnzuz9hve9ib2MbPnLR3b72WWQjRsCTwNwNvjn+TLbO2sOjaRacdC/EMsXUDuTi6cCDrABlFZvTsIYccrrrFkawtP8PTT0NxcX0WWwjRQCTwNwN+bn70C+/HGSZAE+xpxvL7u/kzqu0odqbspKCsAD8309r/rl0l32/8H/z1r7B0ab2WWwjRMCTwN3NB7mZS9OiY0XQN7mrr8rmszWW2c9ZHVm1IX78QLYEE/mYurcjM2h3TbgxdgrrY9k/vNZ3j9x/nchXDuijrzl9+gUOHICgI1q1rgNIKIeqDBP5mrluwGcEzsu1Iru16rW1/iGcIkb6RDA0byM5Q6DrbneQDW83yjZmZZvlGMJO+ZLinEM2KBP5m7q/D/0r8PfG09W+Ln5sfEztNBCDUy6RzmDDWjPXf51XMyqhKk9sfYPVqePtts2D7Z581RNGFEHYigb+Zc3VytWXxBPh08qf8eMuPxATEANA3IpbyJ8pxc3Jje1tXOHECLr/cnPy3v5nfW7bUd7GFEHYkgb+FcXF0YWTbkbX2OTk40bNVT7Z3t657MG4cdO9uPgTABP777oNjkttHiOZAAr8AoE9oH3Z45KG7d8MybiwMHVp9cNUq0wX07LMNV0AhxEUjgV8AJudPTnkef5o3DN/P+rGol6M50KpV7RMtFnjuOUhIqPcyCiEuDgn8AjCjfoI8gnh9y+u4OroyPeNt9l/eBx59tPqkI0dg+XJ47DF44YWGK6wQ4oKoprAGSmxsrN4iDxjtrsJSQWJeIuWV5XR8rSPzx88n0jmQUQ+8gnN6FuTkmL7/5cshPNw8A3CQtoMQjZVSaqvWOvbU/fKvVtg4OTgR7RdNO/92uDq6sjhuMVd9cS2fv3wXTJ5sAv1330G3bnDyJGza1NBFFkKch7MGfqWUg1JqcH0URjQOjg6OxATE8NPRnwBIyEmADh3MQQcHWLwYPD1h9mwoK2u4ggohzstZA7/W2gL8px7KIhqRDgEd0JhuwD3pe2h7/EHWtIGn7ujI8dbeZnLX+vXmQW+VZ56BDRsaqMRCiLqqa1fPj0qpa9WZ0j+KZqljYEfb9rKDy0goPsnzUyL4W8g+Pt79MVx/ven+eeEFSE6G3FyT5mHOnAYstRCiLuoa+O8APgXKlFJ5Sql8pVSeHcslGliHgA627aziLAC+80oB4HDWYXPgueegvBx69TLfAADWrIHD1uPZ2VBaWm9lFkLUTZ0Cv9baW2vtoLV21lr7WF/72LtwouF0CDSB39XR1bavUlcCcDjbGtjbtzfdPRYLPP549cWPPw733AMBAWbGrxCiUanzqB6l1ESl1AvWn/H2LJRoeEMih/DkZU9yR787TjtmC/wAsbEwejSUlJgHvk8/DYsWcfuJ13mzH/DRR9LqF6KRqVPgV0rNA+4D9lp/7lNK/d2eBRMNy9nRmb+O+Cs9WvUAwNvFGwAH5cCJ3BOUVtQI5iNGmN/dulH2+Bz0xx/zVj+4cwLs9CqE77+v7+ILIX5HXVv8Y4HRWut3tNbvAFcC4+xXLNFYRHhHAHBt12vxcPZgYqeJaLQZ4lnFGvgHjTqK6zOuPBtR/Y3gxeEu8Pnn9VlkIcRZnMsELr8a274XuyCicWrj1waAS6MuJXV2Kg8NfgiAzv/pzFfxX5mT2ren8q472OiaDsAPR36wXb892k2WdBSikalr4H8O2K6Uek8p9T6wFZBUjS1Al6AufHLdJ9zQ4wa8XLzoFFid23/lkZW8ueVNjuYkkP+vebb9e9L2ANCrVS/2uRdQnHAI0tLqvexCiDOr08xdwAIMAj4HlgCXaK0X27lsohFQSjG528F58wkAACAASURBVGTcnNwACPQI5PC9h+kQ0IHNJzdz59I7efSnR8krrR7dWzX8c3S70VRiIS4EM7Fr7lx4552GqIYQooa6ztx9WGudrLX+2vqTUg9lE41UO/92dA3uysakjQB8se8LjuceB8Dfzd923uXtzEpe21s7wo8/mnH///xn7ZtVJQn83//gjTfsX3ghRJ27elYqpWYrpSKVUgFVP3YtmWjUYvxjbNullaUs2L4AqB7/D9A/oj8+rj7s7B0G8+ebIZ/790NiojnhppsgMNCM+7/pJrjrrnqtgxAtVV0D/1TgHmAtpn9/KyB5kluwdv7tANPCd3dyZ8tJ879DVaoHJwcn/N38aePbhsSY4Npj+X/8ESoqzCLu2dm1V/YqKam3OgjRUtW1j/8vWuu2p/y0q8O19yml9iil4pRS91v3Pa2USlJK7bD+jL0I9RD1rGqx9u4h3Qn0CORo9lGgOtVDkEcQSilCPENI83MGd3fiLu/Fsbb+JrXzjh3mw+Cjj2B8jfmA110HEyfWe32EaEmcznaC1tqilHoIOKeHuUqp7sAsYABQBnynlPrWevjfWmtZwqkJq+rq6RbcjbzSPBLzTPdNzcAPEOIZwqacBPjoI6YcmU14thc/PL+Ej9vkobrDtOHD4cYbYeNGGDQIli4FDw+TBkIWeRHCLuzZx98F2Ki1LtJaVwBrgD9cUGlFoxHtF82g1oMY33E8gR6Btv1VXT1Vgb+VZyvSCtOwXDOJwyUn+dktlWKHSm50X8YN12G+DQB07Mi/B8FfhwFFRXDyJLtSd/Fl/Jf1XTUhmj179vHvAS5VSgUqpTwws38jrcf+pJTapZR6Rynlf6aLlVK3K6W2KKW2pKen17GYor44Ozqz4Y8bGNdxHIHu1YG/fUB7AII9ggHT4s8vy+d47nFKK0sptZTx8+O32M6ft86M/1+Vs4P/uxKeHoFZBeDAAeatm8ed395Zb3USoqWoa3bOU/v3z9rHr7XeB/wDWAF8B+wAKoH/AjFAbyAZePE3rp+vtY7VWscGBwfXvUai3lUFfi8XL3zdfPF19SXUKxQwgR9gc9Jm2/nvdal+0Pv2trfJL83nn79UD/M86g8cOEBiXmKt+QFCiIvjdwO/UurhGtuTTzn23OlX1Ka1XqC17qe1vgzIBg5orVO11pXW+QFvYZ4BiCasqqvHx9Vk6l524zL+MvQvQHXgrxr1E+AewGd7PwNg3qh55Jfl87/d/+NA5gE6OJgP+G1tXODVV0k6uI3iimIqLBX1Wh8hmruztfivr7F96tJKV57t5kqpEOvvKEz//sdKqbAap1yD6RISTVhVi78q8A+OHEy4dzhQo8V/0rT4b+pxE+WWcgBu7nUzvVr14p3t75CQk8CkQdNxcnBiWxjovXtJciwEoCA9qV7rI0Rzd7bAr35j+0yvz2SJUmov8A1wj9Y6B/inUmq3UmoXMAJ4oM6lFY3SqS3+mqoC/6akTfi4+vCHLub5vqezJ2FeYYyIHsHmk5uxaAvdgrvRPaQ72zp6k+UOpdYxZ3mTroL+/eunMkK0AGcbzql/Y/tMr0+/WOtLz7Dv5jqUSzQhp7b4a6oK/IXlhfQI6cGg1oNwd3KnfUB7lFL0C+9nO7d9QHu6BndlQ1E2ST9/AN+azN/5h/dBOpCSAqHm2QFlZZCaCpGRp76lEOIsztbi71W1xi7Q07pd9bpHPZRPNAG/1+L3dPG0bUf7RePq5Mrd/e9marepAPQLqx34gz2CySzNJsmn+gtlftXqj1u3Vt943jyIioLVqy9eRYRoIX438GutHWussetk3a567VxfhRSNW9WY/TMFfqhO7/DIkEcAeGHMC8y51Dwy6hjYEU9nTzydPQnxDCHQPZC80rxaC73kPzYblIK1a2GP9ZHQokXm9+TJpvUP5Jfms3iPJI0V4mxkaqS4YLauHpczB/6109eS8VAGQ6KGnHbM0cGRfuH96BzUGaWU7UNkV+ou2zl5lw0yC7v/85/Qo4eZ6btvH0RHQ0YGHDYrft34+Y1cv+R6DmcdPu19hBDVJPCLC+br5oufmx8RPhFnPB7hE1Frdu+p3pn4Dh/94SOg+tvDztSdtuOvbnqVYVelmIdKV1wBH38MwNF7buDVAZiMn8C64+sAky1UCPHbJPCLC+agHNh15y7uHXjveV0fExBD56DOQPXzgp2pO4n2iwZgzbE1rA3I5/CLj8Hy5TB7NnTvzpudCrh3LKTEmzkC2SXZgOnyEUL8Ngn84qKI9I20rdJ1Iapa/EXlRXQL7lbr2PdDw0xf//PPw65d7C8yi78cPra91nkFZQUXXA4hmjMJ/KJRqQr8YDJ9OjtUjyFYcWRF9YlKsT/DdPEcyjhAQcZJ26GCnFSzcegQjBkDkutJiFok8ItGpWbCtyjfqFojhVYdXUVhWSHxGfFUWCo4lHUIgENFSRz8xyO28wrWrDQb77wDP/xghn4KIWwk8ItGxdXJFS8XLwDa+LXB29UbgL5hfckvy2f8wvF0e70br216zZb64ZB7Mft/rB7Gmb/+J7NRbo6zYgWcrP5GIERLJ4FfNDpV3T1RvlF4u5jAP7mryRG4OmE1Fm3hge9Npg8/Nz8ORXqy16/cdn1B8jH44gs4alYFY88eiIiAF16oXtxdiBZMAr9odGoFfmuLf2DEQFr7tAbgycuetG1fEXMFB0Mc2T2+v20RmIK24TB9upnpO2qU6fK55hp46CHo1YuCo/uZ+fVMMosy679yQjQCEvhFoxPoHoiroyvBHsG2Fn+4dzhDo4YC8Me+f2TlzSt5c/ybDIkcQm5ZHqvLD9KzVU88nT0pGD0c8vIgIQE6d4bbboPFi+HNNyE+ng2v/YUF2xewOmF1g9VRiIZ01jV3hahvnYM6k1OSg1LK9nA33DucBy95kL6hfYnyjQKgU1An4jPiAcgpyaFHSA9+PvYz+f6e4O9PaV42m6JgqNYoZ2e4/Xb45ReSf14I4yCjMK3B6ihEQ5IWv2h0nh/9PD/dah7Q+rj64OXihberN7HhsTw05KFa53YK7GTLBdQjpAdeLl4UVBTCyJHcMw4uK/4PSw8urb7gL38h2c8RgMwP3qx+AAym/3/RIsjNtW8FhWhgEvhFo+Ps6IyHswcA9/S/h/+O++9vnquUYlwHk765e0h3vF29KSgrYPXwaBb0BYXiwRUP0vHVjjyz9hksnTpy8t4ZAGQe2AmffVZ9s48+gmnT4I037Fc5IRoBCfyiUesT1oebet70u+fMHjyb50c/T/uA9ni5eJFfms8vPfxsxw5kHiC3NJcnVj3B8oPLSS42XTwZ/i5mqCeYZG8PWb9NSKpn0cxJ4BdNXpRvFLMHz0YpZbp6ygrYmxlPlG8UTw17ijfGvcHeu/fi6ujKqoRVJBckA5AY6cvtxZ+Q/Mv3cN11kJMDw4bBunXm4XC7drW/EQjRTEjgF81KVeDfl7GPLkFd8HTx5I7YOwj0CGRQ60GsTlhNcr4J/Ku9MnirSxHL/nSlCfZvvQV33QUFBWYI6NGjLPjxBRLzEhu4VkJcXBL4RbPi7eJNXmke+9L30TW4a61jw6OHsz1lO4ezTb5+i3X10KMThpplHW++mcO921CpgH/9iwwPmBm6kQXbFtR3NYSwKwn8olnxcvEiKT+J4ori0wL/5e0ux6ItgEklXeVorygICmLpgaW0X3QJb17bBk6cINGaJujk5p/MM4A6eG/Heyw9sPTsJwrRgCTwi2alKs8PcFrgHxI5xJYELsK7etGYhJwE8krzmP7VdAAWdjf7E9uac5O3r4WJE83Qz6lTTToIMCkhCmqngH7u5+d4ZdMrF7NKQlx0EvhFs1IV+F0cXejVqletY0opPr7WrN41tsNY2/6j2UdZfnA5GUUZjIkZwzqOMWw6LB0TDUBKpD/POW1g1wM3wCefwMKFZuRP584wY0at98gqzrI9QxCisZLAL5qVCksFAFd3uhpPF8/Tjo+JGUPFExUMjx4OmHH+yQXJLNm3hED3QP415l8ArI2G+Q5mgZd9fuU8Ngo+OGgd4bN1K/k3TzHv9fnnkGge/lq0heySbFIKUuxbSSEukAR+0ayEeIYA8KcBf/rNcxwdHG1dPrHhsQB8uvdTrupwFd1CurHt9m20D2hvex5QtaJXqvVzpCDxCD4z03ngyQFgscDbb7M5aTM7UnZg0RYyijIoLyuBigp7VVOICyK5ekSzMrPvTEa1HUWHwA6/e16HQLO615RuU9h8cjMAU7pOAcykscuiLrMt9FIlxQuIiOCtyCQAFrkc5NXBg2H5cqb6f0Cwg0kop9GkTR1PhJM/fPrpRa6hEBdOAr9oVpwcnM4a9AGi/aLJm5MHQHxGPBM7TWRCpwm2471DewPg6uhKaWUpAKnd2qDv+B8vfWayhAZ7hcCIEVj+/hwnrtKkVGiwrhSZsms9EQllZphoaOjFrKIQF0y6ekSL5ebkhpuTG29PfJuJnSbWOtYnrE+t3wApDkUkdY/iuB+44sTRnKNYhl1GhpuFCqUprl4emGSnEtMNdNddZvlHIRoRCfxCnEGvVr3wc/PjypgrbfsyijLYfHILANf1mEpJRQkpPdtx0v/0L87bQyG9bQh8+SXccov094tGRQK/EGfg7epN0v8l8dCQh3B2cCbUKxSNZsXhFSgU13S+BoAt2XEcue+W065/ciQM/LM7LFhgunsWLIDt203aZ8n/IxqY0k1gDdLY2Fi9ZcuWhi6GaKF+TfyV+Ix4bvvqNtr4tsHNyY1vpn1Dx9fMUo81nwOcSv+lxPTx5+RU7/T0hNRUSr9byrtb38ap/0BmXjO3PqoiWhil1Fatdeyp+6XFL8RZDGo9iE6BnQA4lnuMPmF9aOPXxna8ZtD3dK49d+D7E6tZ9cwf4cEHzdKPc+ZAYSGMHcu9703lLtcfmLXrGSyZ1pQQn38OU6actij84azDPP7T41RaKu1US9GS2DXwK6XuU0rtUUrFKaXuP+XYg0oprZQKsmcZhLgYQr2qR+aMaTcGF0cXru50Nc4OzrXOC3APYM30Ndw38D4Arv3kWu51+B5eeMEs/fjMMxAdTeGGtXzct/raY6//3Wy89poZArpjR637Prn6SZ79+VmWH1pupxqKlsRugV8p1R2YBQwAegHjlVLtrccigTHAcXu9vxAXUyuvVrbtqoVhvrz+S76e9jVghocC+Lv7c1mby5jWfRoAheWFxGfEU1ph/Vbg4ACvvMLXT02lwKGcuSNMF0/8t++aNQDWrTPnff11rfcP9woHYNnBZXapn2hZ7Nni7wJs1FoXaa0rgDXAH6zH/g08DDT+BwxCAB7OHszqO4tlNyzD2bG6pT4gYgBgFoh3d3InwD0AoNZcggpLhW1R+CPZR9g1oA2fti8jwjuCO/rdAcA+x2zzALi8HPz84Kuvar1/1SziL+O/tG0DlFSU2KG2ormzZ+DfA1yqlApUSnkAY4FIpdTVQJLWeqcd31uIi27+hPlc1eGqWvsC3AMY1mYYgyIGEeUbZUsZEeAegL+bv+28Xam70Frzh8V/YMyHY/jp6E9c1f4qgj2DCXLxY18QMG8e+PrCAw+YEUDp6bbrCw7vAyC5IJkTuScAWHtsLX7z/Gyvhagru83c1VrvU0r9A1gBFAI7AFfgUUw3z+9SSt0O3A4QFRVlr2IKccFWT18NwPiO4/Fz87Pt79mqJxZtYVPSJnal7mJ1wmp2pla3d8bEmH8GXVp1Z1/IekhLg9tuI/XSvsS1hZHLl5vgX1RE/pF1EG2uS//uM9r834vs6VVG6aBStpzcQqRvZH1VVzQDdn24q7VeoLXup7W+DMgG4oC2wE6lVALQGtimlDptTrvWer7WOlZrHRscHGzPYgpxUfQL70dMQIzt9cJrF/Lp5E/pFtKNHak7eGPrGwR5BOHn5odCMbLtSAA6B3chvpUjAKXXX0fo2gmMuhVe/e9ttDsxm/KnnyS/NN9237QnZ4OjI2klmQDsTd9bj7UUzYFdc/UopUK01mlKqShM//4grfXLNY4nALFa67otbyREExLmHQbA4NaDeXfHu7g6uTKx00SifKLYn7mfQA+TIbR9QHsyXSrI7dqO/7pVj+Z5+jILWR5w7PvF5P/yF1p7l5OYl0iajyN8+BlpL48B8tibFgfLl0NMDHTs2BBVFU2MvcfxL1FK7QW+Ae7RWuec7QIhmpuRbUdSWF5IVnEWw9sM568j/sqi6xbZjsf4m28Jh1cs5ttDy+gc1BmFIsvDHD8c7Ut+qL/tvLR5T8DAgaTFmC/K+/athbFjoVMn2Ly5fisnmiR7d/VcqrXuqrXupbX+8QzHo6W1L5q7YdHDUCjb9qmquod2pu1mY9JGJnWaRI+Q7rbjh7MPk1+aT5h3GO5O7qRZTLdPWiuz2ti+0iQq20SCs7NZIaymykp44w0zaUwIK5m5K4SdBbgH0CesD9F+0bbx/jVVteTf3/k+FZYKRrYdyeDIIYBJM30o6xD5Zfl4u3gT4hnCkn1LiHklhoOlJ1EaSpzh8K0TYdQosx5wzVm/K1eaDKHvv18fVRVNhAR+IerBWxPe4n9/+N8Zj3m7ehPsEcyaY2twdnBmSNQQZg+ezYKJC+gc1JnD2YcpKCvAy8WLEM8QEnISOJJ9hJSCFK4KHIjS8HFvR/SkSawvO4yumQa6anvt2nqopWgqZCEWIepB37C+v3s82DOY9KJ0JnebjIezBzEBMcQExPD1/q85kHmAgrICvF28CfasPcJtUM9xWBL9eevoZ/Qe/jzX/BH+8spEAgru4e7xf8NzxQpz4tq15puAUvaqomhCpMUvRCOQW5ILwAODHqi1v31Aew5kHgDMN4OqCWJVQjxDmNlnJifzT/J2/McAzOtfysO7/8UPS1+B3buhQwdIToZDtZeSpLAQbrtNHgi3QBL4hWgEFl67kGdGPGNb/L1KjH8Mldpk5PR28a6VrgHMN4WhUWYpyO8OfVfrWOK8R3ljiCvF//6n2VGzuyctDf78Z3jvPXjyyd8v3N13w4cfnnulRKMlgV+IRuDSNpfy2GWPnba/fUB727a3qzcn808C0DHQjNcP8QyhlVcrIrwjqNSVjG43moonKnDEgc96O3PX6FKWta2A4GBYs8bcKCkJOnRAv/su/x3tz4kN38GxY2cu2IkT8N//wrvv1t6fkgKZmRdecdEgJPAL0YjVCvwu3jw38jliw2N5dOijOCgH2viadQH6hfcDoFtwNxwdHAn1DuPXSPPPO7UwDS67rLrF/67JBHrky3e4e0g27/YG3nmHlA9ep+yzxexL3kXugV1QUMALi+7lh3bAtm3Vo4UqK+HSS2HGjPr6M4iLTB7uCtGIRfpG4uTgRIWlAi8XL/pH9GfzrM1orRkWPcyWo6dfWD++3v813UK6ARDhE0FSfhIA6YXpMGwYLFkCCQkmC+jIkWxq5wY74HjXCCwv/Zuw/8tn7AFYFgdXHHVkuesMHgr/Em4B/XQuHDkCpaXM/uoewoIP8eCGXHlg3ERJi1+IRszJwYm2fm0B09VTRSlVa07AZW0uA6B/eH8AIrwjbMfSi6yBH+Cmm0zwv/NONp80D3WPtQsgp9xMCltmzfjwa1glWZ9/bLvHEX9gyxb08GG8lbea1/tjEsglJdWpHnmleSTkJNSx1sLeJPAL0chVzez1dvH+zXOGRw8n8YFEeoX2AmoH/rTCNOjRAyZPhvXrYcAAuPZaNiVtAuC4awlZwwfUul+nQndOOFXP9v2khwO88QYJ5RnkucGRADjui+kCAnPfqqGjZ/D06qcZ9t7ps5YB862hrOw3rxUXnwR+IRq59v6mn79mi/9MInyqg324d7htO70o3XTHvPmmafHPn09OWR7bkk3QPp53goz5L9e6l3PP3pxoV70q6sbeQbB6NbvCqkPGmmhsff8ZM28g7dor4bvaI4uqHMg8QGJe4mmjkgAzsig8HIqKfrd+4uKRwC9EIzcgYgB+bn621b3qouaHQHphOp/GfUqJtzt8+CGWnj2YsHACFZYKpnWfRklFiW2uQJXM0mxO/ONRAGLDYznc1g9cXNg5IBKFwsfVhzW9fOHXX2H7dv7Y+zhTJysz9HPuXLjzzlr3qwr6NdNL2yxfbkYIxcefw19FXAgJ/EI0cjf1vInEBxJxc3Kr8zVVXT0+rj7Epccx5bMpvLX1LQCOZh9l3fF1/H3U35nSbQoA25O3296rT2gfsoqzOFGShpODE5e0voQjRUno5cvZObQj7QPac0nrS9jaxhV+/BH++1/igyEu2gOOHoW//tXkBqqosJXnRJ5ZJSy7OMvMIaiZNO7XX83vvbKuQH2RwC9EI6eUwtPF85yuGRw5mAcveZCbe95s27fy6EoAjuceB6B3aG+ifM3qdjtSzToAL13xEle2v9IE/rwTRHhH0CGgA4XlhaQO6MrOoiP0Cu1Fj5Ae7HPOocJSgX77bU74O5CuCyjwcjHDPUtKYNUq2L+foo3ryCrOAiBr/kvQqpWZTWyxmIfDJ6xLR0rgrzcS+IVohtyd3XlhzAt0CKhe9H3V0VVUWCpsre9I30hb4N+evB2Fws/Nj0D3QCosFexN30ukb2R12uiUnRzOPkyvVr3oHtKdUksZh4d2IzMmjGIH03efMHUMb1wVzJ+vAj1xAgwcSNI9t9jKkL31F7ORnAzHj8PGjea1i4vp658+/dxTSGdmwtChEBd37n+oFkoCvxDNWM2kbvll+Qx5ZwjLDi4DoLVPawLdA/Fx9SG3NBc/Nz8cHRxtzxJ2pu4k0ifSljb6y/gvAbOWcHfregG7//kgJ5ZVLypzdPZM7hqYzmsD4aOOpZCbS2LmUdvx7PjtEB1tXsTFwUcfURjgzbZJA82HwfvvU/nvf3Hg16XmQ6Ck5OyVXLnSjCr67LPz/TO1OBL4hWjG/N38AegU2InY8Fg2JW1icdxiAt0D8XD2QCllS/9QFfCrloS0aAvt/NsR7ReNQvFF/BcA9GrVi67BXQG4/vtZPLOjekTQxpPVCd8eGwXFU//Azt7VS2pnO1fC1KnmxQcfwBdfsODeoQzqsp58FyAqisVfPUvX5eNJXvI+rFt3xnqVVpRWv/j5Z/N7/frz/CsZKw6vYE/angu6R1MhgV+IZizIwwzJvLHHjWyetZluwWZmb9WMXzAfClAd8GuOHuoT2gdXJ1diAmJILUzF28WbKN8o3J3dcVSOVOpKPt/3OQAOyoH3d5oFX2aFT+CEL1w68hgP9E6x3S/LHTOZLCzMrBbm50dy/86UKwspzz8Fa9YQ39qNSgfrpLFffqmuTGUlGUUZ7Evfh9ffvdiVusvsr/pw+PVX83zhPM36Zhbz1s077+ubEgn8QjRj/SP6s3HmRlsCuKqcPpE+1YG/qsUf6B5Y6zeYB8AAfxv+NwCKK4pR1hQNy29czuSuk23ndgjoQGJeIp7Onjw6+RUAtiZvtR13tig2R8CnXscgyDpHYPp0cizFAKRNGg3R0ZyYeiUAid0i4eWX4Yor4O232dDJg5DnQ1i4ZyEVlgozAS07G3btgs6dIT8fHnrovJPHZRRlkFead17XNjUS+IVo5gZEDMBBmX/q/cJOD/xVLf5Tu3oA2vqbdBHXd7+eR4Y8wofXVKdnHh0zmjfGv2F7PcS6XOScoXOI9oumR0gPAL678TtW3boKf+XBkq5w/ap7KAq1vsedd5JTmgNAamEqhWWFJJabwJ3UMRSyssyM4Fmz2Bhchkaz/NByAA5k7IeZM0Epjj37MNrLE/3vf/PxOw/Y1jegtLT2UpS/oayyjKLyIgrLW8baxBL4hWhBbIHf97db/FXPBQDbB4ZSinmXz+P67tfXul+AewBBHkF0DOzI2xPfpuzxMtu3izlD5zBn6ByuaH8Fw6OHExBk3tOiLeye939mfeBOncguzgbg1U2vEvZimK2fPbFq5vDIkQDsa+UIwI7ELQAcXLkYPv+c3f/4P6J3z+C1Fc+wbKA/NxZ9yNy1c803gNBQk5TuLKrKUFgmgV8I0czEhscyuetkxnUYZ9vXIbADzg7OhHmHAeDs6AzAiOgRdbrn8fuPs/POnSilbNcCTOsxjedGPWd7XXMuwnZLEkyaBEBOiWnxrz22lvyyfFIKzDOBpHAvSEhAr1hB4vrlxPcwD4krrFHrYOEJGDuWpKvNB8On8Z+zcIA7ABlxm81D35wcs55AFYsFYmLg1Vdr1SG7xBr4W0iLX9IyC9GCuDq58snkT2rt83LxYsMfN9AhsHrMf9rstLPmBqri7uxep/OSC5Jt25/v+5wA9wCmdJtiC/yn5vFJzE+CNm1YdmApE36YgHaq3WVzKNgRy+NvUZi9AYCDWQfZHJABwNFda+FV68Swbdtgzx7o3t2klj5yhII1P+Dxp3tw2LQZbrmF7NtGA1BQVmCu0ZoRc8Lo4N6a+U9tqVP9mhJp8Qsh6BfeDx9XH9vrYM/gc0oRURdVq4f5uPrww5EfmPrZVPJK82yBvyZPZ0+S8kzK5xWHV6CpHfSdHJwoVZWccC8no8gE+5SCFEpUBR0zYG8wJn2Euzs4OsLH1hTTO3eS7gHePb7h6Z+e5Me7riAh7QDZK78Bqrt69Fdfsdo9lbfYCvv3w8GD5vqSknOfYNYISeAXQtSLUW1HAXBrr1tt++LS4s4Y+AdEDOBY7jFi58fyzYFvbPurHkoPiDBppA9lHSKzuHoUj5ezJ3/cDhmekO4B9OwJw4ebRWhOnoStW3nK2oO1bNcSrr0il8fGuZGdbT6UCssLQWsSnnnQds8N91/Lxvuto5duvhnGj///9u48usryTuD495c9cJOQBLISAgkBlB0TtoJWkM1TCy6jIDpqKxyptVA7U9LjgG2terR1oDo6HVGmjmLBXY9MUQSVOg5SUJZgZBEyBA0klyUsCWF75o/nvTc3ywWCudzc3N/nnJy893nf3Pt78oSH933WBrF+sucTnvv8uYv7pQSJVvxKFg2mzAAAEI9JREFUqUviralvUTa7jEfHPsp7t70HwPpv11N3pn4y1sD0gURFRDG863DADgfdfXg3M4fMZMaQGdw95G4AhmUPA+xTxIGa+or/6h5jGPhHO5O4tAt2H4Ibb4Tt2yEnh5o/PMpzQ+y1UZVuquNgXW8Xh6LsgnI1p2o4u3oVm47v8r7nyOFbGT50k73bX77cThSrq4/5mb8/wy9X/rKVf1uBpW38SqlLwhXjwhXjAuCavGvoGN2Rv+2xs26jI6I5dfYUD495mF6pvYiJjKHmVA0Haw/y4uYXubnvzYzNG8trX9plGQqzCgHbvON7xz8+fzz9CkYBsKZHBFcWFsLkyTB7NsTHs6HTEU5FQtQZ2Bxpm4h2nnXzdf1AJmqffIJN3eOBWhLq4GisTT/zyjIia+2cA7ZsgUIbQ1VNFYdOHOLE6ROt3jwWKHrHr5S65CIkgn5p/bwVv2dT+YLUAgpSC8jtlMvCiQtZOHEhT4x/gu93/z5gRxpN7z+dST0n0SG6A/uO7cNd42ZwxmDemfoOM4bMIDsxmwn5E3hqYjK1t0+zQzpLSmDXLtaOsR3YU7ZBbf0AJN7rHek9PrZqBZtG5gFwxmc74V3P/55VefBmH2B9fYev+8h+AO9opFCgFb9SKij6p/X3VpbT+k3jlr63kJec1+CalPgU7h9xP5ERtmJO7ZDKSze8RHJ8MhmuDCqOVXCg9gCpHVK5rvd1xEbZ2/PiUcVUnjjAsu12OQl69WKbcbPiarvoXP+JdzT4nNKU+qUejs+80/u6Jqb+mpLKrfxmcid+MSkC1qwB5+7fve9rAL7dv9NeuHMnvPqq33yfNWftdphBpBW/UiooPB20YGcBL71pKVERF976nOHKsE09NQcaLDMBcFXuVaTEp/DJHruOT93pOvo83YfVu1czNHsoGQNGeq/1rD7qcXzu/ZRXlzf5vJI02JUaQVniWWpf/QtkZGAWLKBK7H8AFcuX8kbpG9zwH2OouutmO4egGW+UvkHuwlzvHgXBoBW/UiooJhVM8h53iuvU4p/PdGV6m3o8i9F5iAhFWUWs+2Ydv/34t6zavcp7blbhLDJddrKaK8bFrf1vbfCz5UfKOX7qOJd1vqxB+vos+Pb0IYzA/zw9l7LhfTg+by51kXaoacXHy3lh4wu86Spnwm1Qt+ZD9lbugHnzYOpUO3kMOxLpxOkT7D2yt/7NL/EQUa34lVJB0TWxq/fYd5mIC5XhymDvkb0cPnG4yR0/QFFWEVsqt/DgRw9yy2t2KegPbv+A0bmjyXDZWcBZCVn8sPcPG/zcV267969n6WmPlZfHeucTjKt4jB4j11EVfcp7vuLYPo64bWX+RSY8vvYJ+j3Tn9OP/A6WLYOyMgDvnb5n/gHz54PLZSeXXSIBrfhFZLaIlIjIVhGZ46Q9JCKbRWSjiLwvIlmBjEEp1XZ5xvZfzB1/hiuDoyePYjANFpbzKMou8h57ZuR6dhzzLE+RlZDVZOG65ir+YdnDqD3rsweAw51WvwxFRQKU76vftH7NoY1USx37L3PWRSotBWM4UG37Ndw1bjs09KGH7Hk/ew8EQsAqfhHpB8wAhgIDgR+ISE/g98aYAcaYQcC7wPxAxaCUatvevfVdSmaVeDtlW8Jz1w40e8c/LHsYkRLZIM3zlJHWMQ2wm9KLCNXF1Sy/dTlQX/F79i4AGJc3znucEFO/lEXZWDukM1Ii+TYB9kYco89hO1zoi0TbfLPzwZ/xVWfsENDbb+fgW3YWsftffs7pxc/xeXYEm9JhxI65DeYkBFIg7/gvAz4zxtQYY04DHwM3GGN8F7zuCJx/zVSlVLsUFxVH37S+57+wGb4V/8ickU3Op7vS2TBzAzOHzASgS4cu3nWFYiJjuCr3KkZ1s2P+E2MTSY63zU2l7lKiIqIarF00Nm8sghAbGcv4/PHe9C1TRgDQu3NvNmdGUBcFRQl2tdMDHew1xUdeZ/A9UDvvV7BkCQej7YihqkPfsnjTn7lixlkGzYK1Ufv4tPxT297/0EOwf/9F/V4uRCAr/hJgtIikikgH4FogB0BEHhaRcmA6fu74RWSmiKwXkfVVVVUBDFMpFYo8na8LJizw7hvQ2MCM+m0ifZeiBvjozo+4p/Ae72vP5DJ3jZushKwGzU+5Sbn06dyH3E65LLpuES9d/xIAmw+WAnansoqOtvO2aFDDJR3W7l3LiSh4qw9M+UkK+zPtE4O7I2xv9KBS9cdHYNEi2+7fr59dWjoAAlbxG2NKgceA94EVwEbgjHPuAWNMDrAE+Kmfn3/WGFNojCns0qVLc5copcJYfko+tQ/UMmf4nHNe55kc5rv5THM6Rte31+ck5jRo0kmKS2LelfMo/l4xyfHJDM4cDNgN6aMjopnSZ4r32sLChp3FHn8eBG+nHWR7rO1vcA/qRVmjro3yL9fC/PmcjISn8twc/evb54z5YgW0c9cY87wx5gpjzJXAIWB7o0uWADcGMgalVPt1IUskeCp+T8euP757CfRO7d1gtdLE2ESm9Z/GXYPvAmynMEDZ4TJSO6Q2aP7JS8lvts9hQ7adBuwZGeTukc62y7owKX8iH9++mvSoTpRnu+DoUT66qZCfXQsjSn/RZLnq1hDoUT1pzvduwA3AyyJS4HPJZOCrQMaglApvPZJ7kJuU613Y7UJM6TOF2KhYoiOiccW4mkwsS4pNIj7K9hcMSB/QZElr3/4HjwPxDbsz9586zI6oI/RN68eVeVeTk9aT8p62dWNPke0n2Eolr2x9pcl7fVeBXqTtdRFJBU4B9xpjDovI8yLSGzgL/B9wzznfQSmlvoOYyBjK5pS16GfG5dtRPAmxCd4K3peIcMbYTtoJ+RMAWHPnGjZUbCBCIshwZbC1aisFKQXsOLijyc9HSARbKrcAtmMYbPPSV50OQWEhe3p2IeILWPp5PjfOv7lFsV+IgFb8xpjRzaRp045Sqk3KdGXSLambtwkpMTaRDtEdmr325JmTAN5mntG5oxmda6s8zx1/UXYROw7u8K4+6tG9U3d2HbITtjyb3eck5rBy10rMuh3sefsuss+6+IePKgGfleJaic7cVUopR/nPy/nkR/UTqRJiEkiKTWr2Ws8m9b7j/T26JnYlOiKaOcPmUPy94gZDQ6G+ozkuKo5BGYNsWlIOx04eo7qumj3Ve+gWm2ZH9VRUNHn/70orfqWUckRGRDZozy/MKvSu/d/Ypz/6lLLZZYg0vSOfM3wOK25bQVF2EY9e86j3CcDz9OCZP/DyDS979zb2dD7f+9/38mXVl3RLzrVvtm1b62TOh27EopRSfiyevNjvudQOqc0uFQG2qce3g9dzPKLrCFbtXsXMK2Zy39D7SHele6+5Ju8apvefzpItSwDo1vtmeGQc5Oa2RlYa0IpfKaUCLL2jreCLRxUzLm8cOYk5TZ4UUuJTePH6F3nv6/dw17jJSe8N190bkHi0qUcppQIsPzmfuKg4hncdztxRc5ttHgI7WugHvezM36S45vsWWoPe8SulVIDdPeRuJvSc4F0W4lwWTFhAclxyg9nArU2MaftrpBUWFpr1PntcKqWUOj8R2WCMadI7rU09SikVZrTiV0qpMKMVv1JKhRmt+JVSKsxoxa+UUmFGK36llAozWvErpVSY0YpfKaXCTEhM4BKRKuymLRejM+BuxXCCSfPSNmle2ibNC+QaY5psWh4SFf93ISLrm5u5Foo0L22T5qVt0rz4p009SikVZrTiV0qpMBMOFf+zwQ6gFWle2ibNS9ukefGj3bfxK6WUaigc7viVUkr50IpfKaXCTLuu+EVkoohsE5GdIlIc7HhaSkTKRGSLiGwUkfVOWoqIrBSRHc735GDH2RwRWSwilSJS4pPWbOxiPemU02YRGRK8yBvyk49fi8g3TrlsFJFrfc79ysnHNhGZEJyomyciOSLyoYh8KSJbRWS2kx6K5eIvLyFXNiISJyLrRGSTk5ffOOk9ROQzJ+ZlIhLjpMc6r3c657u3+EONMe3yC4gEvgbygBhgE3B5sONqYR7KgM6N0h4Hip3jYuCxYMfpJ/YrgSFAyfliB64F/goIMBz4LNjxnycfvwb+qZlrL3f+zmKBHs7fX2Sw8+ATXyYwxDlOALY7MYdiufjLS8iVjfP7dTnH0cBnzu/7FWCqk/4nYJZz/BPgT87xVGBZSz+zPd/xDwV2GmN2GWNOAkuByUGOqTVMBl5wjl8AArcx53dgjFkDHGyU7C/2ycB/GWst0ElEMi9NpOfmJx/+TAaWGmPqjDG7gZ3Yv8M2wRhTYYz53Dk+CpQC2YRmufjLiz9ttmyc3+8x52W082WAMcBrTnrjcvGU12vAWPG3e7sf7bnizwbKfV7v5dx/GG2RAd4XkQ0iMtNJSzfGVDjH+4D04IR2UfzFHopl9VOn+WOxT3NbyOTDaR4YjL27DOlyaZQXCMGyEZFIEdkIVAIrsU8kh40xp51LfOP15sU5Xw2ktuTz2nPF3x6MMsYMASYB94rIlb4njX3WC8nxuKEcO/DvQD4wCKgAnghuOC0jIi7gdWCOMeaI77lQK5dm8hKSZWOMOWOMGQR0xT6J9Ank57Xniv8bIMfndVcnLWQYY75xvlcCb2L/IPZ7Hred75XBi7DF/MUeUmVljNnv/EM9CyyivsmgzedDRKKxFeUSY8wbTnJIlktzeQnlsgEwxhwGPgRGYJvWopxTvvF68+KcTwIOtORz2nPF/3egwOkZj8F2grwT5JgumIh0FJEEzzEwHijB5uEO57I7gLeDE+FF8Rf7O8A/OqNIhgPVPk0PbU6jdu7rseUCNh9TnVEXPYACYN2ljs8fpx34eaDUGPOvPqdCrlz85SUUy0ZEuohIJ+c4HhiH7bP4ELjJuaxxuXjK6yZgtfOkduGC3aMdyC/sqITt2PayB4IdTwtjz8OOQtgEbPXEj23LWwXsAD4AUoIdq5/4/4J91D6FbZ/8sb/YsaMannbKaQtQGOz4z5OPF504Nzv/CDN9rn/Aycc2YFKw42+Ul1HYZpzNwEbn69oQLRd/eQm5sgEGAF84MZcA8530POx/TjuBV4FYJz3Oeb3TOZ/X0s/UJRuUUirMtOemHqWUUs3Qil8ppcKMVvxKKRVmtOJXSqkwoxW/UkqFGa34lQJE5IzPio4bpRVXcxWR7r6reyoVbFHnv0SpsFBr7JR5pdo9veNX6hzE7onwuNh9EdaJSE8nvbuIrHYWA1slIt2c9HQRedNZW32TiIx03ipSRBY5662/78zQVCootOJXyopv1NRzi8+5amNMf+DfgIVO2lPAC8aYAcAS4Ekn/UngY2PMQOw6/lud9ALgaWNMX+AwcGOA86OUXzpzVylARI4ZY1zNpJcBY4wxu5xFwfYZY1JFxI1dDuCUk15hjOksIlVAV2NMnc97dAdWGmMKnNdzgWhjzO8CnzOlmtI7fqXOz/g5bok6n+MzaP+aCiKt+JU6v1t8vv+vc/wpdsVXgOnA35zjVcAs8G6ukXSpglTqQuldh1JWvLMDkscKY4xnSGeyiGzG3rVPc9LuA/5TRP4ZqALuctJnA8+KyI+xd/azsKt7KtVmaBu/UufgtPEXGmPcwY5FqdaiTT1KKRVm9I5fKaXCjN7xK6VUmNGKXymlwoxW/EopFWa04ldKqTCjFb9SSoWZ/wfMGtz4lh0wygAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "fGYCkQ8gZ9ZH",
        "outputId": "7622bed4-1143-4fc4-aa3a-7a375a698832"
      },
      "source": [
        "print(\"\\n\\nSampled images 3....\")\n",
        "fig2 = plt.figure()\n",
        "for i in range(9):\n",
        "  plt.subplot(3,3,i+1)\n",
        "  plt.tight_layout()\n",
        "\n",
        "  # 1 step sampling\n",
        "  img = rbm_3.reconstruct_image(test[i].T.reshape((784,1)))\n",
        "\n",
        "  plt.imshow(img.reshape((28,28)), cmap='gray', interpolation='none')\n",
        "  plt.title(\"Digit: {}\".format(test_y[i]))\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Sampled images 3....\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:38: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 9 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "3ZPQEKrQZ_XO",
        "outputId": "0cba4514-5f29-4927-fca7-3f25a693103d"
      },
      "source": [
        "print(\"\\n\\nSampled images 4....\")\n",
        "fig2 = plt.figure()\n",
        "for i in range(9):\n",
        "  plt.subplot(3,3,i+1)\n",
        "  plt.tight_layout()\n",
        "\n",
        "  # 1 step sampling\n",
        "  img = rbm_4.reconstruct_image(test[i].T.reshape((784,1)))\n",
        "\n",
        "  plt.imshow(img.reshape((28,28)), cmap='gray', interpolation='none')\n",
        "  plt.title(\"Digit: {}\".format(test_y[i]))\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Sampled images 4....\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:38: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 9 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GNhUf7Sxaxfl",
        "outputId": "c36b63fe-7829-4d7f-c6d5-e44048bc9678"
      },
      "source": [
        "err_1 = rbm_1.reconstruction_error(test.T)\n",
        "err_3 = rbm_3.reconstruction_error(test.T)\n",
        "err_4 = rbm_4.reconstruction_error(test.T)\n",
        "\n",
        "print(\"Reconstruction error using original RBM : \", err_1)\n",
        "print(\"Reconstruction error using modified RBM : \", err_3)\n",
        "print(\"Reconstruction error using modified RBM : \", err_4)"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:35: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:38: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Reconstruction error using original RBM :  73.9085\n",
            "Reconstruction error using modified RBM :  206.2768\n",
            "Reconstruction error using modified RBM :  93.2079\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H-mxrDiKncP7"
      },
      "source": [
        "# Train stack of RBMs after the individual ones are trained"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ampx4EHTs2uO"
      },
      "source": [
        "class RBM_ret_full():\n",
        "    def __init__(self, num_hidden, num_visible, lr, n, batch_size, epochs, W_prior, b_v_prior, b_h_prior, W_old, b_v_old, b_h_old):\n",
        "        self.num_hidden = num_hidden\n",
        "        self.num_visible = num_visible\n",
        "        self.lr = lr\n",
        "        self.n = n\n",
        "        self.batch_size = batch_size\n",
        "        self.epochs = epochs\n",
        "        self.W_prior = W_prior\n",
        "        self.b_v_prior = b_v_prior\n",
        "        self.b_h_prior = b_h_prior\n",
        "\n",
        "        self.W = W_old # weights\n",
        "\n",
        "        self.b_h = b_h_old # bias latent\n",
        "        self.b_v = b_v_old # bias visible\n",
        "\n",
        "        self.dW = []\n",
        "        self.db_h = []\n",
        "        self.db_v = []\n",
        "\n",
        "        self.dW_prior = []\n",
        "        self.db_h_prior = []\n",
        "        self.db_v_prior = []\n",
        "\n",
        "    def sigmoid(self, x):  \n",
        "        #Sigmoid activation \n",
        "        #Implemented interms  of tanh for increased stability\n",
        "        return .5 * (1 + np.tanh(.5 * x))\n",
        "\n",
        "    \n",
        "    def bernoulli_array(self, prob_array, dim):\n",
        "        # Simulating Bernoulli from uniform\n",
        "        sample = np.zeros(dim)\n",
        "\n",
        "        # Draw x~Uni[0,1]\n",
        "        uni_sample = np.random.uniform(0, 1, dim)\n",
        "\n",
        "        # return 1 if x < p else return 0\n",
        "        diff = uni_sample - prob_array\n",
        "        coords = np.argwhere(diff<0)\n",
        "        sample[[*coords.T]] = 1  \n",
        "\n",
        "        return sample\n",
        "\n",
        "    def gibbs_sampling(self, l_0):\n",
        "\n",
        "        l = l_0.copy()\n",
        "\n",
        "        for i in range(self.n):\n",
        "\n",
        "\n",
        "            # (h x l) @ (l x b) + (l x 1) = (l x b)\n",
        "            p_h_l = self.sigmoid(self.W_prior.T @ l + self.b_v_prior)\n",
        "            h = self.bernoulli_array(p_h_l, (p_h_l.shape[0], p_h_l.shape[1]))\n",
        "\n",
        "            # (v x h) @ (h x b) + (v x 1) = (v x b)\n",
        "            p_v_h = self.sigmoid(self.W.T @ h + self.b_v)\n",
        "            v = self.bernoulli_array(p_v_h, (p_v_h.shape[0], p_v_h.shape[1]))\n",
        "\n",
        "            # (h x v) @ (v x b) + (h x 1) = (h x b)\n",
        "            p_h_v = self.sigmoid(self.W @ v + self.b_h)\n",
        "            h = self.bernoulli_array(p_h_v, (p_h_v.shape[0], p_h_v.shape[1]))\n",
        "\n",
        "            # (h x l) @ (l x b) + (l x 1) = (l x b)\n",
        "            p_l_h = self.sigmoid(self.W_prior @ h + self.b_h_prior)\n",
        "            l = self.bernoulli_array(p_l_h, (p_l_h.shape[0], p_l_h.shape[1]))\n",
        "\n",
        "        return v, h, l, p_h_v, p_l_h\n",
        "\n",
        "    def hidden_to_visible(self, h):\n",
        "\n",
        "        h = h.T.copy()\n",
        "\n",
        "        # (v x h) @ (h x b) + (v x 1) = (v x b)\n",
        "        p_v_h = self.sigmoid(self.W.T @ h + self.b_v)\n",
        "        v = self.bernoulli_array(p_v_h, (p_v_h.shape[0], p_v_h.shape[1]))\n",
        "\n",
        "        return v.T\n",
        "\n",
        "    def visible_to_hidden(self, v):\n",
        "\n",
        "        v = v.T.copy()\n",
        "\n",
        "        # (h x v) @ (v x b) + (h x 1) = (h x b)\n",
        "        p_h_v = self.sigmoid(self.W @ v + self.b_h)\n",
        "        h = self.bernoulli_array(p_h_v, (p_h_v.shape[0], p_h_v.shape[1]))\n",
        "\n",
        "        return h.T\n",
        "\n",
        "    def gradient_descent(self, v_0, p_h_v_0, v_n, p_h_v_n):\n",
        "\n",
        "        # Compute the gradients\n",
        "        # (h x b) @ (b x v) - (h x b) @ (b x v) = (h x v)\n",
        "        self.dW = (p_h_v_0 @ v_0 - p_h_v_n @ v_n)/self.batch_size\n",
        "        self.db_h = np.mean(p_h_v_0 - p_h_v_n, axis=1)[:, np.newaxis]\n",
        "        self.db_v = np.mean(v_0 - v_n, axis=0)[:, np.newaxis]\n",
        "        \n",
        "        # Weight update\n",
        "        self.W   = self.W   + self.lr * self.dW\n",
        "        self.b_h = self.b_h + self.lr * self.db_h\n",
        "        self.b_v = self.b_v + self.lr * self.db_v\n",
        "\n",
        "\n",
        "    def gradient_descent_prior(self, h_0, p_l_h_0, h_n, p_l_h_n):\n",
        "\n",
        "        # Compute the gradients\n",
        "        # (l x b) @ (b x h) - (l x b) @ (b x h) = (l x h)\n",
        "        self.dW_prior = (p_l_h_0 @ h_0 - p_l_h_n @ h_n)/self.batch_size\n",
        "        self.db_h_prior = np.mean(p_l_h_0 - p_l_h_n, axis=1)[:, np.newaxis]\n",
        "        self.db_v_prior = np.mean(h_0 - h_n, axis=0)[:, np.newaxis]\n",
        "        \n",
        "        # Weight update\n",
        "        self.W_prior   = self.W_prior   + self.lr * self.dW_prior\n",
        "        self.b_h_prior = self.b_h_prior + self.lr * self.db_h_prior\n",
        "        self.b_v_prior = self.b_v_prior + self.lr * self.db_v_prior\n",
        "\n",
        "\n",
        "    def reconstruction_error(self, v):\n",
        "        # Sample hidden state\n",
        "        p_h_v = self.sigmoid(self.W @ v + self.b_h)\n",
        "        h = self.bernoulli_array(p_h_v, (p_h_v.shape[0], p_h_v.shape[1]))\n",
        "\n",
        "        # For prior RBM\n",
        "        p_l_h = self.sigmoid(self.W_prior @ h + self.b_h_prior)\n",
        "        l = self.bernoulli_array(p_l_h, (p_l_h.shape[0], p_l_h.shape[1]))\n",
        "\n",
        "        p_h_l = self.sigmoid(self.W_prior.T @ l + self.b_v_prior)\n",
        "        h_cap = self.bernoulli_array(p_h_l, (p_h_l.shape[0], p_h_l.shape[1]))\n",
        "\n",
        "        # Sample viible state\n",
        "        p_v_h = self.sigmoid(self.W.T @ h_cap + self.b_v)\n",
        "        v_sampled = self.bernoulli_array(p_v_h, (p_v_h.shape[0], p_v_h.shape[1]))    \n",
        "\n",
        "        return np.sum(np.mean((v-v_sampled)**2, axis=1), axis=0)\n",
        "\n",
        "\n",
        "    def reconstruct_image(self, v):\n",
        "        # Sample hidden state\n",
        "        p_h_v = self.sigmoid(self.W @ v + self.b_h)\n",
        "        h = self.bernoulli_array(p_h_v, (p_h_v.shape[0], p_h_v.shape[1]))\n",
        "\n",
        "        # For prior RBM\n",
        "        p_l_h = self.sigmoid(self.W_prior @ h + self.b_h_prior)\n",
        "        l = self.bernoulli_array(p_l_h, (p_l_h.shape[0], p_l_h.shape[1]))\n",
        "\n",
        "        p_h_l = self.sigmoid(self.W_prior.T @ l + self.b_v_prior)\n",
        "        h_cap = self.bernoulli_array(p_h_l, (p_h_l.shape[0], p_h_l.shape[1]))\n",
        "\n",
        "        # Sample viible state\n",
        "        p_v_h = self.sigmoid(self.W.T @ h_cap + self.b_v)\n",
        "        v_sampled = self.bernoulli_array(p_v_h, (p_v_h.shape[0], p_v_h.shape[1]))    \n",
        "\n",
        "        return v_sampled\n",
        "\n",
        "\n",
        "    def Train(self, train, val):\n",
        "\n",
        "        num_batches = int(train.shape[0]/self.batch_size)\n",
        "        train_loss = []\n",
        "        val_loss = []\n",
        "\n",
        "        for epoch in range(self.epochs):\n",
        "\n",
        "            # Shuffling the data\n",
        "            train = np.random.permutation(train)\n",
        "\n",
        "            # Splitting data into batches\n",
        "            batches = np.array_split(train, num_batches)\n",
        "\n",
        "            for i in range(num_batches):\n",
        "\n",
        "                # visible units from data\n",
        "                v_0 = batches[i].T\n",
        "\n",
        "                # (h x v) @ (v x b) + (h x 1) = (h x b)\n",
        "                p_h_v_0 = self.sigmoid(self.W @ v_0 + self.b_h)\n",
        "                h_0 = self.bernoulli_array(p_h_v_0, (p_h_v_0.shape[0], p_h_v_0.shape[1]))\n",
        "\n",
        "                # For prior RBM\n",
        "                p_l_h_0 = self.sigmoid(self.W_prior @ h_0 + self.b_h_prior)\n",
        "                l_0 = self.bernoulli_array(p_l_h_0, (p_l_h_0.shape[0], p_l_h_0.shape[1]))\n",
        "\n",
        "                # Run the markov chain\n",
        "                v_n, h_n, l_n, p_h_v_n, p_l_h_n = self.gibbs_sampling(l_0)\n",
        "\n",
        "                # Compute gradients\n",
        "                self.gradient_descent(v_0.T, p_h_v_0, v_n.T, p_h_v_n)\n",
        "                self.gradient_descent_prior(h_0.T, p_l_h_0, h_n.T, p_l_h_n)\n",
        "\n",
        "            # Compute reconstruction errror\n",
        "            error_train = self.reconstruction_error(train.T)\n",
        "            error_val = self.reconstruction_error(val.T)\n",
        "\n",
        "            print(f\"Epoch {epoch+1} ------> Error => Train : {error_train}, Val : {error_val}\")\n",
        " \n",
        "            train_loss.append(error_train)\n",
        "            val_loss.append(error_val)\n",
        "\n",
        "        return train_loss, val_loss"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GtrQ7AxmvxD2"
      },
      "source": [
        "# RBM config\n",
        "num_hidden = 256 # number of hidden units\n",
        "lr = 0.001 # learning rate for gradient descent\n",
        "n = 1 # number of Gibbs sampling steps\n",
        "batch_size = 100 # mini batch size for gradient update\n",
        "epochs = 300 # number of epochs"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fwk6buCpv4U5",
        "outputId": "f13c2689-2635-4299-da9a-392e931f6cc7"
      },
      "source": [
        "rbm_5 = RBM_ret_full(num_hidden, val.shape[1], lr, n, batch_size, epochs, rbm_2.W, rbm_2.b_v, rbm_2.b_h, rbm_1.W, rbm_1.b_v, rbm_1.b_h)\n",
        "train_loss, val_loss = rbm_4.Train(train, val)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:38: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 ------> Error => Train : 92.86860784313726, Val : 92.843\n",
            "Epoch 2 ------> Error => Train : 92.9355294117647, Val : 93.0261111111111\n",
            "Epoch 3 ------> Error => Train : 92.91621568627451, Val : 92.92988888888888\n",
            "Epoch 4 ------> Error => Train : 93.02133333333333, Val : 93.02833333333334\n",
            "Epoch 5 ------> Error => Train : 93.0098431372549, Val : 92.98366666666666\n",
            "Epoch 6 ------> Error => Train : 92.97598039215686, Val : 92.80555555555557\n",
            "Epoch 7 ------> Error => Train : 92.72574509803921, Val : 92.77022222222223\n",
            "Epoch 8 ------> Error => Train : 92.92915686274509, Val : 92.90144444444445\n",
            "Epoch 9 ------> Error => Train : 92.94376470588236, Val : 92.88333333333333\n",
            "Epoch 10 ------> Error => Train : 92.89250980392157, Val : 92.85766666666667\n",
            "Epoch 11 ------> Error => Train : 92.85739215686274, Val : 92.84155555555556\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S74XR2iAv-9c"
      },
      "source": [
        "fig = plt.figure()\n",
        "plt.plot(train_loss, c='r', label=\"Train\")\n",
        "plt.plot(val_loss, c='g', label=\"Val\")\n",
        "plt.legend()\n",
        "plt.title(\"Reconstruction Error\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Error\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ymfXfJNPwC1W"
      },
      "source": [
        "print(\"\\n\\nSampled images 3....\")\n",
        "fig2 = plt.figure()\n",
        "for i in range(9):\n",
        "  plt.subplot(3,3,i+1)\n",
        "  plt.tight_layout()\n",
        "\n",
        "  # 1 step sampling\n",
        "  img = rbm_3.reconstruct_image(test[i].T.reshape((784,1)))\n",
        "\n",
        "  plt.imshow(img.reshape((28,28)), cmap='gray', interpolation='none')\n",
        "  plt.title(\"Digit: {}\".format(test_y[i]))\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O9XKYZEKwDW7"
      },
      "source": [
        "print(\"\\n\\nSampled images 4....\")\n",
        "fig2 = plt.figure()\n",
        "for i in range(9):\n",
        "  plt.subplot(3,3,i+1)\n",
        "  plt.tight_layout()\n",
        "\n",
        "  # 1 step sampling\n",
        "  img = rbm_4.reconstruct_image(test[i].T.reshape((784,1)))\n",
        "\n",
        "  plt.imshow(img.reshape((28,28)), cmap='gray', interpolation='none')\n",
        "  plt.title(\"Digit: {}\".format(test_y[i]))\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L8mEnVb9wJEx"
      },
      "source": [
        "err_1 = rbm_1.reconstruction_error(test.T)\n",
        "err_3 = rbm_3.reconstruction_error(test.T)\n",
        "err_4 = rbm_4.reconstruction_error(test.T)\n",
        "err_5 = rbm_5.reconstruction_error(test.T)\n",
        "\n",
        "print(\"Reconstruction error using original RBM : \", err_1)\n",
        "print(\"Reconstruction error using modified RBM : \", err_3)\n",
        "print(\"Reconstruction error using retrained RBM : \", err_4)\n",
        "print(\"Reconstruction error using retrained full RBM : \", err_5)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}