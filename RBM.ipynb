{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RBM.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOhpuCK70U+FzGiOYBcnMvs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GangaMegha/Generative-Models/blob/main/RBM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FcyDht9LwHXP"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Import MNIST data\n",
        "from keras.datasets import mnist"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bpN1fuKVG8DQ"
      },
      "source": [
        "# RBM class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DgSFBOGKG_OC"
      },
      "source": [
        "class RBM():\n",
        "    def __init__(self, num_hidden, num_visible, lr, n, batch_size, epochs):\n",
        "        self.num_hidden = num_hidden\n",
        "        self.num_visible = num_visible\n",
        "        self.lr = lr\n",
        "        self.n = n\n",
        "        self.batch_size = batch_size\n",
        "        self.epochs = epochs\n",
        "\n",
        "        self.W = np.random.randn(num_hidden, num_visible)/np.sqrt(0.5*(num_visible + num_hidden)) # weights\n",
        "\n",
        "        self.b_h = np.zeros((num_hidden, 1)) # bias latent\n",
        "        self.b_v = np.zeros((num_visible, 1)) # bias visible\n",
        "\n",
        "        self.dW = []\n",
        "        self.db_h = []\n",
        "        self.db_v = []\n",
        "\n",
        "    def sigmoid(self, x):  \n",
        "        #Sigmoid activation \n",
        "        #Implemented interms  of tanh for increased stability\n",
        "        return .5 * (1 + np.tanh(.5 * x))\n",
        "\n",
        "    \n",
        "    def bernoulli_array(self, prob_array, dim):\n",
        "        # Simulating Bernoulli from uniform\n",
        "        sample = np.zeros(dim)\n",
        "\n",
        "        # Draw x~Uni[0,1]\n",
        "        uni_sample = np.random.uniform(0, 1, dim)\n",
        "\n",
        "        # return 1 if x < p else return 0\n",
        "        diff = uni_sample - prob_array\n",
        "        coords = np.argwhere(diff<0)\n",
        "        sample[[*coords.T]] = 1  \n",
        "\n",
        "        return sample\n",
        "\n",
        "    def gibbs_sampling(self, h_0):\n",
        "\n",
        "        h = h_0.copy()\n",
        "\n",
        "        for i in range(self.n):\n",
        "\n",
        "            # (v x h) @ (h x b) + (v x 1) = (v x b)\n",
        "            p_v_h = self.sigmoid(self.W.T @ h + self.b_v)\n",
        "            v = self.bernoulli_array(p_v_h, (p_v_h.shape[0], p_v_h.shape[1]))\n",
        "\n",
        "            # (h x v) @ (v x b) + (h x 1) = (h x b)\n",
        "            p_h_v = self.sigmoid(self.W @ v + self.b_h)\n",
        "            h = self.bernoulli_array(p_h_v, (p_h_v.shape[0], p_h_v.shape[1]))\n",
        "\n",
        "        return v, h, p_h_v\n",
        "\n",
        "    def gradient_descent(self, v_0, p_h_v_0, v_n, p_h_v_n):\n",
        "\n",
        "        # Compute the gradients\n",
        "        # (h x b) @ (b x v) - (h x b) @ (b x v) = (h x v)\n",
        "        self.dW = (p_h_v_0 @ v_0 - p_h_v_n @ v_n)/self.batch_size\n",
        "        self.db_h = np.mean(p_h_v_0 - p_h_v_n, axis=1)[:, np.newaxis]\n",
        "        self.db_v = np.mean(v_0 - v_n, axis=0)[:, np.newaxis]\n",
        "        \n",
        "        # Weight update\n",
        "        self.W   = self.W   + self.lr * self.dW\n",
        "        self.b_h = self.b_h + self.lr * self.db_h\n",
        "        self.b_v = self.b_v + self.lr * self.db_v\n",
        "\n",
        "\n",
        "    def reconstruction_error(self, v):\n",
        "        # Sample hidden state\n",
        "        p_h_v = self.sigmoid(self.W @ v + self.b_h)\n",
        "        h = self.bernoulli_array(p_h_v, (p_h_v.shape[0], p_h_v.shape[1]))\n",
        "\n",
        "        # Sample viible state\n",
        "        p_v_h = self.sigmoid(self.W.T @ h + self.b_v)\n",
        "        v_sampled = self.bernoulli_array(p_v_h, (p_v_h.shape[0], p_v_h.shape[1]))    \n",
        "\n",
        "        return np.sum(np.mean((v-v_sampled)**2, axis=1), axis=0)\n",
        "\n",
        "\n",
        "    def reconstruct_image(self, v):\n",
        "        # Sample hidden state\n",
        "        p_h_v = self.sigmoid(self.W @ v + self.b_h)\n",
        "        h = self.bernoulli_array(p_h_v, (p_h_v.shape[0], p_h_v.shape[1]))\n",
        "\n",
        "        # Sample viible state\n",
        "        p_v_h = self.sigmoid(self.W.T @ h + self.b_v)\n",
        "        v_sampled = self.bernoulli_array(p_v_h, (p_v_h.shape[0], p_v_h.shape[1]))    \n",
        "\n",
        "        return v_sampled\n",
        "\n",
        "\n",
        "    def Train(self, train, val):\n",
        "\n",
        "        num_batches = int(train.shape[0]/batch_size)\n",
        "        train_loss = []\n",
        "        val_loss = []\n",
        "\n",
        "        for epoch in range(self.epochs):\n",
        "\n",
        "            # Shuffling the data\n",
        "            train = np.random.permutation(train)\n",
        "\n",
        "            # Splitting data into batches\n",
        "            batches = np.array_split(train, num_batches)\n",
        "\n",
        "            for i in range(num_batches):\n",
        "\n",
        "                # visible units from data\n",
        "                v_0 = batches[i].T\n",
        "\n",
        "                # (h x v) @ (v x b) + (h x 1) = (h x b)\n",
        "                p_h_v_0 = self.sigmoid(self.W @ v_0 + self.b_h)\n",
        "                h_0 = self.bernoulli_array(p_h_v_0, (p_h_v_0.shape[0], p_h_v_0.shape[1]))\n",
        "\n",
        "                # Run the markov chain\n",
        "                v_n, h_n, p_h_v_n = self.gibbs_sampling(h_0)\n",
        "\n",
        "                # Compute gradients\n",
        "                self.gradient_descent(v_0.T, p_h_v_0, v_n.T, p_h_v_n)\n",
        "\n",
        "            # Compute reconstruction errror\n",
        "            error_train = self.reconstruction_error(train.T)\n",
        "            error_val = self.reconstruction_error(val.T)\n",
        "\n",
        "            print(f\"Epoch {epoch+1} ------> Error => Train : {error_train}, Val : {error_val}\")\n",
        " \n",
        "            train_loss.append(error_train)\n",
        "            val_loss.append(error_val)\n",
        "\n",
        "        return train_loss, val_loss\n",
        "\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kJ6GU55s92Qa"
      },
      "source": [
        "# MNIST data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "DOp2JtgT9l0P",
        "outputId": "81fade58-4a95-4692-935a-0e782464befa"
      },
      "source": [
        "# Load MNIST data\n",
        "(train, train_y), (test, test_y) = mnist.load_data()\n",
        "\n",
        "# Converting to binary\n",
        "train[[*np.argwhere(train>0).T]] = 1\n",
        "test[[*np.argwhere(test>0).T]] = 1\n",
        "\n",
        "\n",
        "fig = plt.figure()\n",
        "for i in range(9):\n",
        "  plt.subplot(3,3,i+1)\n",
        "  plt.tight_layout()\n",
        "  plt.imshow(train[i], cmap='gray', interpolation='none')\n",
        "  plt.title(\"Digit: {}\".format(train_y[i]))\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
            "  \"\"\"\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVUAAAELCAYAAABpiBWpAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAQnElEQVR4nO3db6hk9X3H8ffXGFf8s/5Z7J9VoyXbwjYSQ4s+qRsMtaBUaYVi09o2NWxjhCDU4p8qln0gjRZiqIFgSo2mSLU+SEmWagktPsgiYh+FdYMQ3brs9q7aRdbsriLofvvgzIXLdPbee+b+zpzfmXm/4MDOzLlnfmfmu9/5nD9zJjITSVIZp/U9AEmaJzZVSSrIpipJBdlUJakgm6okFWRTlaSCZt5UI+LxiHiw9LwaLmtC44ZcE1HyPNWIeBP4ReAj4GPgp8A/Af+QmSc3uOxrgacz85IWf7MLeAD4cMXdn83M/RsZi9avwpoI4GFg5+iufwTuS0/YnpnaamLF354B/AQ4d5q/X9ZFUr0pM88FLqMp3nuBJzp4nvX6l8w8Z8VkQ529mmriK8DvA1cCnwVuAm7vaSyLrKaaWHY38L8bXUhnm/+Z+V5m/hD4Q+BLEXEFQEQ8FREPLc8XEfdExOGIWIqInRGREbFt5bwRcTbwArA1Io6Ppq1djV3dqKQmvgR8IzMPZeb/AN8A/rzwqmqdKqkJIuJXgD8Bvr7Rdep8n2pmvgIcAnaMPxYR1wN3AdcB24BrT7GME8ANwNKKxLkUEddExNE1hnBTRLwbEfsi4o6NrIvK6LkmPkOzibfsJ6P71KMK+sS3gPuBD6Zfi8asDlQtARdOuP8W4MnM3JeZ7wO72iw0M/dk5vmrzPIcsB24CPgL4G8i4o/aPIc601dNnAO8t+L2e8A5o32t6lcvNRERNwOfyMx/bbPcU5lVU70YeHfC/VuBgytuH5wwz9Qy86eZuZSZH2fmS8DfA39Q8jk0tV5qAjgObF5xezNw3ANVVZh5TYx2GfwdcGepZXbeVCPiKpoXa8+Ehw8DK4+yXbrKokoUfQImkp71XBP7aA5SLbtydJ961GNN/CpwOfDjiHgL+D7wyxHxVkRc3nJZQIdNNSI2R8SNwLM0pzjsnTDbc8BtEbE9Is4CVjvX7G1gS0Sc12IMvxcRF0TjappPox+0WA0VVENN0Jy6c1dEXDw6iPFXwFMt/l4FVVATr9I06c+Npp2jZXyOKRNxF011d0QcoxnQA8CjwG2TZszMF4DHgBeB14GXRw99OGHe14BngP0RcTQitkbEjog4vspYvjha7jGa/0yPZOb3plstbUBNNfEdYDewl+Y/1L+N7tNsVVETmflRZr61PNHsfjg5uv3xNCtW9OT/jYqI7TSFvikzP+p7POqfNaFxtddE79/9j4ibI2JTRFwAPALsrvGF0uxYExo3pJrovanSfJvlHeANmq+seS6prAmNG0xNVLX5L0lDV0NSlaS5YVOVpIJObzNzRCzEvoLM9AsC67QoNQEcycyL+h7EECx6TZhUpfU50PcAVJ2JNWFTlaSCbKqSVJBNVZIKsqlKUkE2VUkqyKYqSQW1Ok9Vqsl6v2LtL6VolkyqklRQdUl1Fhd4MbkMmxcB0katVkMb7Q8mVUkqaOZJ1ZShaU1bO5P+zq2V/oy/H/P2XphUJamgmSTVWtLpvH0izrta6kbzYxY1ZVKVpIJsqpJUUHWnVLXlJr2kEkr1EpOqJBU0k6S68hNg2h3Fy8vw4MX88z3WkJlUJamgme9TbZs4x/dzuA91fpVKqOM1Mmm5y/dZT7OzKFsgJlVJKqi3o//rSRMr7zdRzK+2CcZaUFuzTMkmVUkqaPDnqWqYFmX/mhaPSVWSCqomqa51VsCp7nf/2vzyvVVbNeyfN6lKUkHVJNVlbc9j9eyA+eN7qWVD3PduUpWkgqpLqstMrPNpiMlD3eqjJrrsEyZVSSqo2qS6zKtTqS1rpU4l/y+vN2n2UQsmVUkqqPqkusxrBcy/jb5nbVKJ9dGfeX/tTaqSVFD1SdX9Y1rLWjUy78lIdTGpSlJB1SXVjSZTU8niMKGqRiZVSSqo96Ta1e8SaXjcf655YFKVpIJmnlRLpxETqpZZC6qBSVWSCrKpSlJBnW7+d3HgwU08LbMWVCOTqiQVVDSpmky1lhKXf7MmVDOTqiQV1PvJ/+NMIYvB91nzyqQqSQUVTaqmD0k16aMnmVQlqSCbqiQVZFOVpIJsqpJUkE1Vkgpqe/T/CHCgi4FU5LK+BzAwi1ATYF20sdA1EV5tXZLKcfNfkgqyqUpSQTZVSSrIpipJBdlUJakgm6okFWRTlaSCbKqSVJBNVZIKsqlKUkE2VUkqyKYqSQXNvKlGxOMR8WDpeTVc1oTGDbomMrPYBLwJfAAcA44CLwFfBU4rsOxrgUMt/+YLwIvAe8CbJdfVabA1cT7wPeCd0bSr79do0aYKa+Ju4NXReP4buHsjY+giqd6UmefSXGvwYeBe4IkOnmc9TgDfpXnR1J+aauKbwFnA5cDVwJ9GxG09jWWR1VQTAfwZcAFwPfC1iPji1Evr4BPourH7rgZOAleMbj8FPLTi8XuAw8ASsBNIYNvKeYGzaT7ZTgLHR9PWFuO6DpNqL1NtNUFzAeWrVty+H/hx36/TIk211cSE8T0GfGva9et8n2pmvgIcAnaMPxYR1wN30TS9bTTRfdIyTgA3AEuZec5oWoqIayLiaGeDVycqqIkY+/cV7ddCJVVQE8vPFaMx7JtqRZjdgaol4MIJ998CPJmZ+zLzfWBXm4Vm5p7MPL/A+DR7fdXEvwP3RcS5EbEN+DLN7gD1r4Y+sYumLz7Z5jlWmlVTvRh4d8L9W4GDK24fnDCP5lNfNXEnzSbiz4AfAM/QJCT1r9c+ERFfo9m3+ruZ+eG0y+m8qUbEVTQv1p4JDx8GLllx+9JVFuWPac2JPmsiM9/NzFsz85cy8zM0/wdeabscldV3n4iILwP3Ab+dmRv6kO2sqUbE5oi4EXgWeDoz906Y7TngtojYHhFnAauda/Y2sCUizmsxhtMi4kzgk83NODMizmixGiqokpr4dERsiYhPRMQNwFdoDnKoB5XUxK3A3wK/k5n7Wwx/oi6a6u6IOEYT0R8AHgUmnrKSmS/QHGl7EXgdeHn00P+L3pn5Gs2m2v6IOBoRWyNiR0QcX2Usn6fZ1Hse+NTo3z+aaq20ETXVxG8Ce2nOSfw6cGtmTn1QQlOrqSYeArYA/xURx0fT49OuWFU/UR0R22lOwt2UmR/1PR71z5rQuNprovfv/kfEzRGxKSIuAB4Bdtf4Qml2rAmNG1JN9N5Ugdtpvi74BvAxcEe/w1EFrAmNG0xNVLX5L0lDV0NSlaS5YVOVpIJObzNzRCzEvoLMjLXnEixOTQBHMvOivgcxBIteEyZVaX0O9D0AVWdiTdhUJakgm6okFWRTlaSCbKqSVJBNVZIKsqlKUkE2VUkqqNXJ/zVaz7ULmt/ykjTv1nstky57gklVkgoabFL16lqSauwDJlVJKmiwSVWLo1Qacd/68JWqheXldFETJlVJKsimKkkFDW7zv8Yd0+qG77WGWAMmVUkqaDBJtYaTetWtIaYS1Wm5D/RRUyZVSSpoMEl1LSbUxTH+XptwtayGPmBSlaSCqk+qppD51/X+8hrSi7pR43trUpWkgqpNqh7tn29ttkCm3YdqbQzfEN9Dk6okFVRtUtV82shFxd2/rnE11oRJVZIKqi6pur9MG00f1sb8KZ1I/TkVSRqIapKqCVUbZW3Mj673lXqRakkaiGqSqhZDn1cPUt2mqYmN1tPKvyuVWk2qklRQ70nVfamLaZr303Q7n/pIqG3G0bZWTaqSVFDvSVXSYppFQu1jH75JVZIKqj6pui9VyzxzQNMeg5nl9SRMqpJUUG9J1bShtqwZraXtlq3fqJKkys08qZo2JJVW07EXk6okFWRTlaSCqjulqqYYL6kuQ+gPJlVJKqi6pCqdiif/z5chpM5pmFQlqSCbquZGZppi1TubqiQVNPN9qvO6H0X16PJH3aS1mFQlqSCbqgYnIkyhqpZNVZIK8jxVDZZpVTUyqUpSQW2T6hHgQBcDqchlfQ9gYBahJsC6aGOhayI8WVqSynHzX5IKsqlKUkE2VUkqyKYqSQXZVCWpIJuqJBVkU5WkgmyqklSQTVWSCrKpSlJBNlVJKsimKkkF2VQlqaCZN9WIeDwiHiw9r4bLmtC4QdfE8m+ll5iAN4EPgGPAUeAl4KvAaQWWfS1wqOXffAF4EXgPeLPkujoNtib+EtgP/BxYAr4JnN7367RIU4U1UbRPdJFUb8rMc2ku4PowcC/wRAfPsx4ngO8Cd/f0/GrUVBM/BH4jMzcDVwBXAnf2NJZFVlNNlO0THXwCXTd239XASeCK0e2ngIdWPH4PcJgmNewEEti2cl7gbJpPtpPA8dG0tcW4rsOk2stUa02MlrUF+A/g232/Tos01VoTpfpE5/tUM/MV4BCwY/yxiLgeuGu0MttoovukZZwAbgCWMvOc0bQUEddExNHOBq9O9F0TEfHHEfFzmp/9uBL4zkbWRxvXd02UNKsDVUvAhRPuvwV4MjP3Zeb7wK42C83MPZl5foHxafZ6q4nM/OdsNv9/DXgceLvNc6gzc9EnZtVULwbenXD/VuDgitsHJ8yj+dR7TWTmz4B9wLe7eg610ntNlNB5U42Iq2herD0THj4MXLLi9qWrLMpfKJwTldXE6cCnCyxHG1BZTWxIZ001IjZHxI3As8DTmbl3wmzPAbdFxPaIOAtY7Vyzt4EtEXFeizGcFhFnAp9sbsaZEXFGi9VQQZXUxM6I+IXRv38d+GvgP9e9Eiqqkpoo2ie6aKq7I+IYTUR/AHgUuG3SjJn5AvAYzTlirwMvjx76cMK8rwHPAPsj4mhEbI2IHRFxfJWxfJ7maODzwKdG//7RVGuljaipJn4L2BsRJ2jq4nng/ulWSxtQU00U7RMxOpWgChGxHXgV2JSZH/U9HvXPmtC42mui9+/+R8TNEbEpIi4AHgF21/hCaXasCY0bUk303lSB24F3gDeAj4E7+h2OKmBNaNxgaqKqzX9JGroakqokzQ2bqiQVdHqbmSNiIfYVZGb0PYahWJSaAI5k5kV9D2IIFr0mTKrS+hzoewCqzsSasKlKUkE2VUkqyKYqSQXZVCWpIJuqJBXU6pSqWVjrG14Rnu0kqV4mVUkqqJqk6jUINK7LmnCLZ9hOVRs1vK8mVUkqqJqkKs1ya2X5uWpINiqnhvfVpCpJBVXTVCPC1CBp8KppqpI0D2yqklRQNQeqPKVK0jwwqUpSQdUk1fWq4ZQJ9WOt99ytHdXApCpJBVWTVJdTiGljcc1y68MtHXXFpCpJBVWTVJeZWNWWtaKamFQlqaDqkqq0FpOpat6iNalKUkEmVVWj69ThEX/NgklVkgoyqap3XSVUk6n6YFKVpIJsqppbmVnl0WHNN5uqJBVkU1Xv/CkdzRObqiQVNNij/15Xdf5M+16631Tj+uwPJlVJKsimKkkF2VQlqaDB7lPVMK22/7Pt/i/3parGq1WZVCWpoGqT6no/gTwLYBhKJIma0oh0KiZVSSqo2qSqxVM6ibr1oj6YVCWpIJuqJBXk5r/mjpv96pNJVZIKMqlq8EymqolJVZIKqj6pmkLmQ4mvE1oLGgKTqiQVVH1S1XwxbaoLNdWVSVWSCrKpSlJBNlVJKsimKkkF2VQlqaC2R/+PAAe6GEhFLut7AAOzCDUB1kUbC10T4dXUJakcN/8lqSCbqiQVZFOVpIJsqpJUkE1VkgqyqUpSQTZVSSrIpipJBdlUJamg/wP64mVBiqf0RAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 9 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z0uFtm7E9dvU",
        "outputId": "6f41e3bb-3334-46d3-a5b1-631744705b3e"
      },
      "source": [
        "# Split data into Train, Val, Test and flatten the images\n",
        "frac = 0.15\n",
        "\n",
        "n = int(frac*(train.shape[0]))\n",
        "val = train[:n]\n",
        "train = train[n:]\n",
        "\n",
        "train = train.reshape(train.shape[0], -1)\n",
        "val = val.reshape(val.shape[0], -1)\n",
        "test = test.reshape(test.shape[0], -1)\n",
        "\n",
        "print('Train: ', train.shape)\n",
        "print('Val: ', val.shape)\n",
        "print('Test:  ', test.shape)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train:  (51000, 784)\n",
            "Val:  (9000, 784)\n",
            "Test:   (10000, 784)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-7sT-yDYPI2M"
      },
      "source": [
        "# Train and Inference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yCLe1EBNPT-W"
      },
      "source": [
        "# RBM config\n",
        "num_hidden = 256 # number of hidden units\n",
        "lr = 0.001 # learning rate for gradient descent\n",
        "n = 1 # number of Gibbs sampling steps\n",
        "batch_size = 100 # mini batch size for gradient update\n",
        "epochs = 500 # number of epochs"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C3sHXwRmmmkt",
        "outputId": "e950c642-052a-4b7a-f396-cbd8fa2016a2"
      },
      "source": [
        "rbm = RBM(num_hidden, val.shape[1], lr, n, batch_size, epochs)\n",
        "train_loss, val_loss = rbm.Train(train, val)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:35: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 ------> Error => Train : 162.8538431372549, Val : 162.109\n",
            "Epoch 2 ------> Error => Train : 147.51301960784315, Val : 146.71866666666665\n",
            "Epoch 3 ------> Error => Train : 134.03400000000002, Val : 133.18977777777778\n",
            "Epoch 4 ------> Error => Train : 123.66207843137255, Val : 122.907\n",
            "Epoch 5 ------> Error => Train : 116.35678431372548, Val : 115.49066666666667\n",
            "Epoch 6 ------> Error => Train : 110.7252549019608, Val : 109.97133333333333\n",
            "Epoch 7 ------> Error => Train : 106.63558823529411, Val : 105.93066666666667\n",
            "Epoch 8 ------> Error => Train : 103.33194117647056, Val : 102.5141111111111\n",
            "Epoch 9 ------> Error => Train : 100.35041176470588, Val : 99.6091111111111\n",
            "Epoch 10 ------> Error => Train : 97.93194117647059, Val : 97.29533333333333\n",
            "Epoch 11 ------> Error => Train : 95.77780392156863, Val : 95.19077777777778\n",
            "Epoch 12 ------> Error => Train : 93.84741176470588, Val : 93.16144444444444\n",
            "Epoch 13 ------> Error => Train : 92.14196078431374, Val : 91.61966666666667\n",
            "Epoch 14 ------> Error => Train : 90.40535294117647, Val : 89.95444444444443\n",
            "Epoch 15 ------> Error => Train : 89.08898039215686, Val : 88.35344444444445\n",
            "Epoch 16 ------> Error => Train : 87.62498039215686, Val : 87.01688888888889\n",
            "Epoch 17 ------> Error => Train : 86.3523137254902, Val : 85.76177777777778\n",
            "Epoch 18 ------> Error => Train : 85.1568431372549, Val : 84.588\n",
            "Epoch 19 ------> Error => Train : 84.0162156862745, Val : 83.42333333333333\n",
            "Epoch 20 ------> Error => Train : 82.91147058823529, Val : 82.21622222222223\n",
            "Epoch 21 ------> Error => Train : 81.98813725490196, Val : 81.3761111111111\n",
            "Epoch 22 ------> Error => Train : 81.07252941176469, Val : 80.36566666666667\n",
            "Epoch 23 ------> Error => Train : 80.1017450980392, Val : 79.47977777777777\n",
            "Epoch 24 ------> Error => Train : 79.23050980392156, Val : 78.88944444444444\n",
            "Epoch 25 ------> Error => Train : 78.48190196078431, Val : 77.77433333333333\n",
            "Epoch 26 ------> Error => Train : 77.61813725490197, Val : 77.00933333333333\n",
            "Epoch 27 ------> Error => Train : 76.88558823529411, Val : 76.46266666666666\n",
            "Epoch 28 ------> Error => Train : 76.1544705882353, Val : 75.64111111111112\n",
            "Epoch 29 ------> Error => Train : 75.37025490196078, Val : 74.72977777777777\n",
            "Epoch 30 ------> Error => Train : 74.74250980392156, Val : 74.2391111111111\n",
            "Epoch 31 ------> Error => Train : 74.17347058823529, Val : 73.64988888888888\n",
            "Epoch 32 ------> Error => Train : 73.57974509803921, Val : 73.01266666666666\n",
            "Epoch 33 ------> Error => Train : 72.9223725490196, Val : 72.46133333333333\n",
            "Epoch 34 ------> Error => Train : 72.36535294117647, Val : 71.81\n",
            "Epoch 35 ------> Error => Train : 71.83529411764707, Val : 71.31733333333332\n",
            "Epoch 36 ------> Error => Train : 71.22176470588235, Val : 70.56766666666667\n",
            "Epoch 37 ------> Error => Train : 70.74747058823529, Val : 70.17933333333333\n",
            "Epoch 38 ------> Error => Train : 70.24890196078431, Val : 69.68844444444444\n",
            "Epoch 39 ------> Error => Train : 69.74770588235295, Val : 69.2551111111111\n",
            "Epoch 40 ------> Error => Train : 69.31376470588235, Val : 68.85455555555555\n",
            "Epoch 41 ------> Error => Train : 68.88709803921569, Val : 68.44533333333334\n",
            "Epoch 42 ------> Error => Train : 68.518, Val : 67.92833333333334\n",
            "Epoch 43 ------> Error => Train : 68.04798039215686, Val : 67.48444444444445\n",
            "Epoch 44 ------> Error => Train : 67.57207843137255, Val : 67.02944444444445\n",
            "Epoch 45 ------> Error => Train : 67.25225490196078, Val : 66.821\n",
            "Epoch 46 ------> Error => Train : 66.83460784313726, Val : 66.06677777777777\n",
            "Epoch 47 ------> Error => Train : 66.41090196078432, Val : 65.96266666666668\n",
            "Epoch 48 ------> Error => Train : 66.13596078431372, Val : 65.57177777777778\n",
            "Epoch 49 ------> Error => Train : 65.72960784313725, Val : 65.30777777777777\n",
            "Epoch 50 ------> Error => Train : 65.38356862745098, Val : 64.81722222222223\n",
            "Epoch 51 ------> Error => Train : 65.03541176470588, Val : 64.5048888888889\n",
            "Epoch 52 ------> Error => Train : 64.74388235294117, Val : 64.14455555555557\n",
            "Epoch 53 ------> Error => Train : 64.39411764705882, Val : 63.82766666666667\n",
            "Epoch 54 ------> Error => Train : 64.10949019607844, Val : 63.66166666666666\n",
            "Epoch 55 ------> Error => Train : 63.825, Val : 63.38044444444445\n",
            "Epoch 56 ------> Error => Train : 63.532980392156865, Val : 62.94033333333333\n",
            "Epoch 57 ------> Error => Train : 63.25823529411765, Val : 62.669111111111114\n",
            "Epoch 58 ------> Error => Train : 62.972607843137254, Val : 62.50055555555556\n",
            "Epoch 59 ------> Error => Train : 62.70707843137255, Val : 62.13566666666666\n",
            "Epoch 60 ------> Error => Train : 62.325568627450984, Val : 61.897\n",
            "Epoch 61 ------> Error => Train : 62.14635294117647, Val : 61.687\n",
            "Epoch 62 ------> Error => Train : 61.84329411764706, Val : 61.47222222222223\n",
            "Epoch 63 ------> Error => Train : 61.62780392156863, Val : 61.09733333333334\n",
            "Epoch 64 ------> Error => Train : 61.39443137254902, Val : 60.79311111111111\n",
            "Epoch 65 ------> Error => Train : 61.05335294117647, Val : 60.638777777777776\n",
            "Epoch 66 ------> Error => Train : 60.79796078431373, Val : 60.32555555555555\n",
            "Epoch 67 ------> Error => Train : 60.613098039215686, Val : 59.998666666666665\n",
            "Epoch 68 ------> Error => Train : 60.36135294117646, Val : 59.95244444444444\n",
            "Epoch 69 ------> Error => Train : 60.14447058823529, Val : 59.68377777777778\n",
            "Epoch 70 ------> Error => Train : 59.92898039215686, Val : 59.394888888888886\n",
            "Epoch 71 ------> Error => Train : 59.71403921568627, Val : 59.416222222222224\n",
            "Epoch 72 ------> Error => Train : 59.48433333333333, Val : 59.162111111111116\n",
            "Epoch 73 ------> Error => Train : 59.31168627450981, Val : 58.85577777777778\n",
            "Epoch 74 ------> Error => Train : 59.12466666666667, Val : 58.61844444444445\n",
            "Epoch 75 ------> Error => Train : 58.8868431372549, Val : 58.467888888888886\n",
            "Epoch 76 ------> Error => Train : 58.697352941176476, Val : 58.2011111111111\n",
            "Epoch 77 ------> Error => Train : 58.45025490196078, Val : 58.010333333333335\n",
            "Epoch 78 ------> Error => Train : 58.26072549019608, Val : 57.74833333333333\n",
            "Epoch 79 ------> Error => Train : 58.089882352941174, Val : 57.66088888888889\n",
            "Epoch 80 ------> Error => Train : 57.926019607843145, Val : 57.42688888888888\n",
            "Epoch 81 ------> Error => Train : 57.721901960784315, Val : 57.30011111111112\n",
            "Epoch 82 ------> Error => Train : 57.53431372549019, Val : 57.18811111111111\n",
            "Epoch 83 ------> Error => Train : 57.408392156862746, Val : 56.985555555555564\n",
            "Epoch 84 ------> Error => Train : 57.17296078431373, Val : 56.82822222222222\n",
            "Epoch 85 ------> Error => Train : 57.00825490196079, Val : 56.54722222222222\n",
            "Epoch 86 ------> Error => Train : 56.79923529411765, Val : 56.434555555555555\n",
            "Epoch 87 ------> Error => Train : 56.716196078431366, Val : 56.324444444444445\n",
            "Epoch 88 ------> Error => Train : 56.46770588235294, Val : 56.19288888888889\n",
            "Epoch 89 ------> Error => Train : 56.34774509803922, Val : 55.95455555555556\n",
            "Epoch 90 ------> Error => Train : 56.23566666666667, Val : 55.81888888888889\n",
            "Epoch 91 ------> Error => Train : 56.02113725490196, Val : 55.522666666666666\n",
            "Epoch 92 ------> Error => Train : 55.8716862745098, Val : 55.587\n",
            "Epoch 93 ------> Error => Train : 55.68874509803922, Val : 55.33144444444444\n",
            "Epoch 94 ------> Error => Train : 55.54272549019608, Val : 55.07522222222222\n",
            "Epoch 95 ------> Error => Train : 55.41709803921569, Val : 55.00888888888889\n",
            "Epoch 96 ------> Error => Train : 55.203941176470586, Val : 54.869\n",
            "Epoch 97 ------> Error => Train : 55.12845098039216, Val : 54.68988888888889\n",
            "Epoch 98 ------> Error => Train : 54.955705882352945, Val : 54.67755555555556\n",
            "Epoch 99 ------> Error => Train : 54.83698039215686, Val : 54.56233333333333\n",
            "Epoch 100 ------> Error => Train : 54.725078431372545, Val : 54.292888888888896\n",
            "Epoch 101 ------> Error => Train : 54.58927450980392, Val : 54.232000000000006\n",
            "Epoch 102 ------> Error => Train : 54.35923529411765, Val : 54.007111111111115\n",
            "Epoch 103 ------> Error => Train : 54.250098039215686, Val : 53.86677777777778\n",
            "Epoch 104 ------> Error => Train : 54.13737254901961, Val : 53.796\n",
            "Epoch 105 ------> Error => Train : 54.04360784313725, Val : 53.60955555555555\n",
            "Epoch 106 ------> Error => Train : 53.880686274509806, Val : 53.593999999999994\n",
            "Epoch 107 ------> Error => Train : 53.7503137254902, Val : 53.36977777777778\n",
            "Epoch 108 ------> Error => Train : 53.64062745098039, Val : 53.251555555555555\n",
            "Epoch 109 ------> Error => Train : 53.49745098039216, Val : 53.13833333333333\n",
            "Epoch 110 ------> Error => Train : 53.33984313725491, Val : 52.96944444444445\n",
            "Epoch 111 ------> Error => Train : 53.26707843137255, Val : 52.93166666666667\n",
            "Epoch 112 ------> Error => Train : 53.17752941176471, Val : 52.711\n",
            "Epoch 113 ------> Error => Train : 53.04833333333333, Val : 52.732777777777784\n",
            "Epoch 114 ------> Error => Train : 52.910000000000004, Val : 52.56277777777777\n",
            "Epoch 115 ------> Error => Train : 52.800725490196086, Val : 52.36266666666667\n",
            "Epoch 116 ------> Error => Train : 52.67539215686274, Val : 52.433\n",
            "Epoch 117 ------> Error => Train : 52.55276470588235, Val : 52.275333333333336\n",
            "Epoch 118 ------> Error => Train : 52.43572549019608, Val : 52.20099999999999\n",
            "Epoch 119 ------> Error => Train : 52.25258823529412, Val : 51.89033333333333\n",
            "Epoch 120 ------> Error => Train : 52.21835294117647, Val : 51.967666666666666\n",
            "Epoch 121 ------> Error => Train : 52.07021568627451, Val : 51.742777777777775\n",
            "Epoch 122 ------> Error => Train : 51.98213725490196, Val : 51.690555555555555\n",
            "Epoch 123 ------> Error => Train : 51.89649019607843, Val : 51.64288888888889\n",
            "Epoch 124 ------> Error => Train : 51.76841176470588, Val : 51.556\n",
            "Epoch 125 ------> Error => Train : 51.64919607843137, Val : 51.383222222222216\n",
            "Epoch 126 ------> Error => Train : 51.59656862745098, Val : 51.27655555555556\n",
            "Epoch 127 ------> Error => Train : 51.46131372549019, Val : 51.19577777777778\n",
            "Epoch 128 ------> Error => Train : 51.379392156862735, Val : 51.07033333333334\n",
            "Epoch 129 ------> Error => Train : 51.306529411764714, Val : 51.050777777777775\n",
            "Epoch 130 ------> Error => Train : 51.17319607843137, Val : 50.85455555555556\n",
            "Epoch 131 ------> Error => Train : 51.090823529411765, Val : 50.745999999999995\n",
            "Epoch 132 ------> Error => Train : 50.98860784313725, Val : 50.669555555555554\n",
            "Epoch 133 ------> Error => Train : 50.902117647058816, Val : 50.68211111111111\n",
            "Epoch 134 ------> Error => Train : 50.73370588235294, Val : 50.46588888888889\n",
            "Epoch 135 ------> Error => Train : 50.68439215686274, Val : 50.44566666666667\n",
            "Epoch 136 ------> Error => Train : 50.596039215686275, Val : 50.371\n",
            "Epoch 137 ------> Error => Train : 50.53509803921568, Val : 50.248222222222225\n",
            "Epoch 138 ------> Error => Train : 50.38933333333333, Val : 50.17955555555555\n",
            "Epoch 139 ------> Error => Train : 50.29915686274509, Val : 49.92922222222222\n",
            "Epoch 140 ------> Error => Train : 50.28047058823529, Val : 49.96966666666667\n",
            "Epoch 141 ------> Error => Train : 50.2008431372549, Val : 49.78033333333334\n",
            "Epoch 142 ------> Error => Train : 50.01590196078432, Val : 49.763\n",
            "Epoch 143 ------> Error => Train : 49.973882352941175, Val : 49.83255555555556\n",
            "Epoch 144 ------> Error => Train : 49.86431372549019, Val : 49.580777777777776\n",
            "Epoch 145 ------> Error => Train : 49.839215686274514, Val : 49.460222222222214\n",
            "Epoch 146 ------> Error => Train : 49.77892156862745, Val : 49.461000000000006\n",
            "Epoch 147 ------> Error => Train : 49.59801960784314, Val : 49.38166666666666\n",
            "Epoch 148 ------> Error => Train : 49.57872549019608, Val : 49.192\n",
            "Epoch 149 ------> Error => Train : 49.43839215686275, Val : 49.18088888888889\n",
            "Epoch 150 ------> Error => Train : 49.35260784313726, Val : 49.040333333333336\n",
            "Epoch 151 ------> Error => Train : 49.286137254901966, Val : 48.96677777777778\n",
            "Epoch 152 ------> Error => Train : 49.266549019607844, Val : 48.92344444444444\n",
            "Epoch 153 ------> Error => Train : 49.14715686274509, Val : 48.903444444444446\n",
            "Epoch 154 ------> Error => Train : 49.00911764705882, Val : 48.846444444444444\n",
            "Epoch 155 ------> Error => Train : 48.98227450980392, Val : 48.83588888888889\n",
            "Epoch 156 ------> Error => Train : 48.88052941176471, Val : 48.518222222222214\n",
            "Epoch 157 ------> Error => Train : 48.85201960784313, Val : 48.54622222222222\n",
            "Epoch 158 ------> Error => Train : 48.76, Val : 48.45455555555556\n",
            "Epoch 159 ------> Error => Train : 48.637764705882354, Val : 48.51222222222222\n",
            "Epoch 160 ------> Error => Train : 48.62282352941176, Val : 48.34733333333333\n",
            "Epoch 161 ------> Error => Train : 48.53374509803922, Val : 48.251666666666665\n",
            "Epoch 162 ------> Error => Train : 48.4588431372549, Val : 48.213\n",
            "Epoch 163 ------> Error => Train : 48.402803921568626, Val : 48.09488888888889\n",
            "Epoch 164 ------> Error => Train : 48.31605882352942, Val : 48.06355555555555\n",
            "Epoch 165 ------> Error => Train : 48.22286274509804, Val : 47.98811111111111\n",
            "Epoch 166 ------> Error => Train : 48.15843137254902, Val : 47.858888888888885\n",
            "Epoch 167 ------> Error => Train : 48.03066666666666, Val : 47.82022222222223\n",
            "Epoch 168 ------> Error => Train : 48.019627450980394, Val : 47.707222222222214\n",
            "Epoch 169 ------> Error => Train : 47.94717647058824, Val : 47.68166666666667\n",
            "Epoch 170 ------> Error => Train : 47.89876470588236, Val : 47.52111111111111\n",
            "Epoch 171 ------> Error => Train : 47.821882352941174, Val : 47.50566666666666\n",
            "Epoch 172 ------> Error => Train : 47.730823529411765, Val : 47.62144444444445\n",
            "Epoch 173 ------> Error => Train : 47.70205882352941, Val : 47.502111111111105\n",
            "Epoch 174 ------> Error => Train : 47.60070588235294, Val : 47.30677777777778\n",
            "Epoch 175 ------> Error => Train : 47.52274509803922, Val : 47.42944444444444\n",
            "Epoch 176 ------> Error => Train : 47.42296078431372, Val : 47.16711111111111\n",
            "Epoch 177 ------> Error => Train : 47.42927450980392, Val : 47.238666666666674\n",
            "Epoch 178 ------> Error => Train : 47.34343137254902, Val : 47.08\n",
            "Epoch 179 ------> Error => Train : 47.22805882352941, Val : 47.004000000000005\n",
            "Epoch 180 ------> Error => Train : 47.191568627450984, Val : 47.082111111111104\n",
            "Epoch 181 ------> Error => Train : 47.07447058823529, Val : 46.84777777777778\n",
            "Epoch 182 ------> Error => Train : 47.00335294117647, Val : 46.792777777777786\n",
            "Epoch 183 ------> Error => Train : 47.04890196078432, Val : 46.70788888888889\n",
            "Epoch 184 ------> Error => Train : 46.9913725490196, Val : 46.647888888888886\n",
            "Epoch 185 ------> Error => Train : 46.862686274509805, Val : 46.757444444444445\n",
            "Epoch 186 ------> Error => Train : 46.788196078431376, Val : 46.58888888888889\n",
            "Epoch 187 ------> Error => Train : 46.762921568627455, Val : 46.602111111111114\n",
            "Epoch 188 ------> Error => Train : 46.736333333333334, Val : 46.547777777777775\n",
            "Epoch 189 ------> Error => Train : 46.63039215686274, Val : 46.40877777777778\n",
            "Epoch 190 ------> Error => Train : 46.548980392156864, Val : 46.300555555555555\n",
            "Epoch 191 ------> Error => Train : 46.56617647058823, Val : 46.23633333333333\n",
            "Epoch 192 ------> Error => Train : 46.427215686274515, Val : 46.37188888888889\n",
            "Epoch 193 ------> Error => Train : 46.390392156862745, Val : 46.16088888888889\n",
            "Epoch 194 ------> Error => Train : 46.30233333333334, Val : 46.022333333333336\n",
            "Epoch 195 ------> Error => Train : 46.25143137254902, Val : 46.117555555555555\n",
            "Epoch 196 ------> Error => Train : 46.28272549019607, Val : 46.06733333333333\n",
            "Epoch 197 ------> Error => Train : 46.17494117647058, Val : 46.01133333333333\n",
            "Epoch 198 ------> Error => Train : 46.121725490196084, Val : 45.92022222222223\n",
            "Epoch 199 ------> Error => Train : 46.066607843137255, Val : 45.86311111111111\n",
            "Epoch 200 ------> Error => Train : 46.018313725490195, Val : 45.824444444444445\n",
            "Epoch 201 ------> Error => Train : 45.96354901960784, Val : 45.81488888888889\n",
            "Epoch 202 ------> Error => Train : 45.94127450980392, Val : 45.77622222222223\n",
            "Epoch 203 ------> Error => Train : 45.80345098039216, Val : 45.666444444444444\n",
            "Epoch 204 ------> Error => Train : 45.782588235294114, Val : 45.60911111111111\n",
            "Epoch 205 ------> Error => Train : 45.75474509803921, Val : 45.56677777777777\n",
            "Epoch 206 ------> Error => Train : 45.66490196078431, Val : 45.51277777777777\n",
            "Epoch 207 ------> Error => Train : 45.66623529411764, Val : 45.33733333333333\n",
            "Epoch 208 ------> Error => Train : 45.547980392156866, Val : 45.373000000000005\n",
            "Epoch 209 ------> Error => Train : 45.496274509803925, Val : 45.25377777777778\n",
            "Epoch 210 ------> Error => Train : 45.47927450980392, Val : 45.278555555555556\n",
            "Epoch 211 ------> Error => Train : 45.429078431372545, Val : 45.257666666666665\n",
            "Epoch 212 ------> Error => Train : 45.41235294117647, Val : 45.19477777777778\n",
            "Epoch 213 ------> Error => Train : 45.322156862745096, Val : 45.06922222222222\n",
            "Epoch 214 ------> Error => Train : 45.304196078431374, Val : 45.03955555555555\n",
            "Epoch 215 ------> Error => Train : 45.152235294117645, Val : 44.915333333333336\n",
            "Epoch 216 ------> Error => Train : 45.150627450980394, Val : 44.89266666666667\n",
            "Epoch 217 ------> Error => Train : 45.14439215686275, Val : 44.84122222222222\n",
            "Epoch 218 ------> Error => Train : 45.03576470588236, Val : 44.959999999999994\n",
            "Epoch 219 ------> Error => Train : 45.01713725490196, Val : 44.81033333333333\n",
            "Epoch 220 ------> Error => Train : 44.93333333333334, Val : 44.812777777777775\n",
            "Epoch 221 ------> Error => Train : 44.928411764705885, Val : 44.78322222222222\n",
            "Epoch 222 ------> Error => Train : 44.84380392156862, Val : 44.65111111111111\n",
            "Epoch 223 ------> Error => Train : 44.82713725490196, Val : 44.68311111111112\n",
            "Epoch 224 ------> Error => Train : 44.74272549019608, Val : 44.57244444444444\n",
            "Epoch 225 ------> Error => Train : 44.72129411764706, Val : 44.49722222222222\n",
            "Epoch 226 ------> Error => Train : 44.684588235294115, Val : 44.49933333333333\n",
            "Epoch 227 ------> Error => Train : 44.5931568627451, Val : 44.485\n",
            "Epoch 228 ------> Error => Train : 44.55574509803922, Val : 44.40311111111111\n",
            "Epoch 229 ------> Error => Train : 44.61329411764706, Val : 44.38166666666666\n",
            "Epoch 230 ------> Error => Train : 44.50619607843137, Val : 44.278333333333336\n",
            "Epoch 231 ------> Error => Train : 44.43749019607843, Val : 44.31422222222223\n",
            "Epoch 232 ------> Error => Train : 44.37652941176471, Val : 44.17155555555556\n",
            "Epoch 233 ------> Error => Train : 44.347921568627456, Val : 44.18644444444445\n",
            "Epoch 234 ------> Error => Train : 44.35082352941177, Val : 44.227111111111114\n",
            "Epoch 235 ------> Error => Train : 44.27441176470588, Val : 44.093111111111114\n",
            "Epoch 236 ------> Error => Train : 44.17809803921568, Val : 44.130111111111106\n",
            "Epoch 237 ------> Error => Train : 44.1511568627451, Val : 44.10388888888889\n",
            "Epoch 238 ------> Error => Train : 44.13074509803921, Val : 43.97488888888889\n",
            "Epoch 239 ------> Error => Train : 44.07309803921569, Val : 43.915333333333336\n",
            "Epoch 240 ------> Error => Train : 44.07003921568628, Val : 43.860888888888894\n",
            "Epoch 241 ------> Error => Train : 43.99107843137255, Val : 43.81933333333333\n",
            "Epoch 242 ------> Error => Train : 43.967549019607844, Val : 43.876333333333335\n",
            "Epoch 243 ------> Error => Train : 43.90107843137255, Val : 43.68922222222222\n",
            "Epoch 244 ------> Error => Train : 43.837196078431376, Val : 43.71944444444445\n",
            "Epoch 245 ------> Error => Train : 43.813078431372546, Val : 43.718444444444444\n",
            "Epoch 246 ------> Error => Train : 43.8156862745098, Val : 43.754666666666665\n",
            "Epoch 247 ------> Error => Train : 43.729725490196074, Val : 43.57522222222222\n",
            "Epoch 248 ------> Error => Train : 43.6901568627451, Val : 43.55322222222222\n",
            "Epoch 249 ------> Error => Train : 43.66701960784314, Val : 43.45866666666666\n",
            "Epoch 250 ------> Error => Train : 43.59223529411764, Val : 43.494777777777784\n",
            "Epoch 251 ------> Error => Train : 43.56370588235294, Val : 43.49122222222222\n",
            "Epoch 252 ------> Error => Train : 43.60641176470588, Val : 43.46688888888889\n",
            "Epoch 253 ------> Error => Train : 43.45719607843137, Val : 43.328\n",
            "Epoch 254 ------> Error => Train : 43.439058823529415, Val : 43.37833333333333\n",
            "Epoch 255 ------> Error => Train : 43.41229411764706, Val : 43.290333333333336\n",
            "Epoch 256 ------> Error => Train : 43.36872549019608, Val : 43.28288888888889\n",
            "Epoch 257 ------> Error => Train : 43.33409803921569, Val : 43.19988888888889\n",
            "Epoch 258 ------> Error => Train : 43.249431372549026, Val : 43.08733333333333\n",
            "Epoch 259 ------> Error => Train : 43.228, Val : 43.17677777777777\n",
            "Epoch 260 ------> Error => Train : 43.207313725490195, Val : 43.01733333333334\n",
            "Epoch 261 ------> Error => Train : 43.22364705882353, Val : 42.90866666666667\n",
            "Epoch 262 ------> Error => Train : 43.12725490196078, Val : 42.94533333333334\n",
            "Epoch 263 ------> Error => Train : 43.060039215686274, Val : 42.86255555555555\n",
            "Epoch 264 ------> Error => Train : 43.077176470588235, Val : 42.95522222222222\n",
            "Epoch 265 ------> Error => Train : 43.0181568627451, Val : 42.93344444444444\n",
            "Epoch 266 ------> Error => Train : 42.9763137254902, Val : 42.897777777777776\n",
            "Epoch 267 ------> Error => Train : 42.908, Val : 42.72822222222222\n",
            "Epoch 268 ------> Error => Train : 42.894999999999996, Val : 42.84522222222222\n",
            "Epoch 269 ------> Error => Train : 42.83433333333333, Val : 42.721444444444444\n",
            "Epoch 270 ------> Error => Train : 42.83035294117647, Val : 42.556\n",
            "Epoch 271 ------> Error => Train : 42.74509803921569, Val : 42.64033333333333\n",
            "Epoch 272 ------> Error => Train : 42.75974509803921, Val : 42.596222222222224\n",
            "Epoch 273 ------> Error => Train : 42.70092156862745, Val : 42.52955555555556\n",
            "Epoch 274 ------> Error => Train : 42.70158823529412, Val : 42.55255555555556\n",
            "Epoch 275 ------> Error => Train : 42.62858823529412, Val : 42.516555555555556\n",
            "Epoch 276 ------> Error => Train : 42.60619607843137, Val : 42.540333333333336\n",
            "Epoch 277 ------> Error => Train : 42.543176470588236, Val : 42.382666666666665\n",
            "Epoch 278 ------> Error => Train : 42.49054901960784, Val : 42.49611111111111\n",
            "Epoch 279 ------> Error => Train : 42.52298039215686, Val : 42.379666666666665\n",
            "Epoch 280 ------> Error => Train : 42.48950980392157, Val : 42.379333333333335\n",
            "Epoch 281 ------> Error => Train : 42.430882352941175, Val : 42.32233333333333\n",
            "Epoch 282 ------> Error => Train : 42.37535294117647, Val : 42.329\n",
            "Epoch 283 ------> Error => Train : 42.34631372549019, Val : 42.34277777777778\n",
            "Epoch 284 ------> Error => Train : 42.30954901960784, Val : 42.20588888888889\n",
            "Epoch 285 ------> Error => Train : 42.2833137254902, Val : 42.178444444444445\n",
            "Epoch 286 ------> Error => Train : 42.25541176470588, Val : 42.13422222222222\n",
            "Epoch 287 ------> Error => Train : 42.25033333333333, Val : 42.10933333333334\n",
            "Epoch 288 ------> Error => Train : 42.18941176470588, Val : 42.037444444444446\n",
            "Epoch 289 ------> Error => Train : 42.2118431372549, Val : 41.967333333333336\n",
            "Epoch 290 ------> Error => Train : 42.13309803921568, Val : 41.96377777777778\n",
            "Epoch 291 ------> Error => Train : 42.08345098039216, Val : 42.013222222222225\n",
            "Epoch 292 ------> Error => Train : 41.96794117647059, Val : 42.016888888888886\n",
            "Epoch 293 ------> Error => Train : 41.94447058823529, Val : 41.85933333333334\n",
            "Epoch 294 ------> Error => Train : 42.0001568627451, Val : 41.76877777777777\n",
            "Epoch 295 ------> Error => Train : 41.96074509803921, Val : 41.82744444444444\n",
            "Epoch 296 ------> Error => Train : 41.88043137254902, Val : 41.80711111111111\n",
            "Epoch 297 ------> Error => Train : 41.87429411764706, Val : 41.72844444444444\n",
            "Epoch 298 ------> Error => Train : 41.824666666666666, Val : 41.609\n",
            "Epoch 299 ------> Error => Train : 41.79733333333333, Val : 41.70633333333333\n",
            "Epoch 300 ------> Error => Train : 41.77082352941177, Val : 41.54655555555556\n",
            "Epoch 301 ------> Error => Train : 41.724529411764706, Val : 41.769444444444446\n",
            "Epoch 302 ------> Error => Train : 41.65982352941177, Val : 41.56077777777778\n",
            "Epoch 303 ------> Error => Train : 41.64364705882353, Val : 41.522777777777776\n",
            "Epoch 304 ------> Error => Train : 41.593666666666664, Val : 41.565\n",
            "Epoch 305 ------> Error => Train : 41.601392156862744, Val : 41.474111111111114\n",
            "Epoch 306 ------> Error => Train : 41.56996078431373, Val : 41.53044444444444\n",
            "Epoch 307 ------> Error => Train : 41.56301960784314, Val : 41.534\n",
            "Epoch 308 ------> Error => Train : 41.5475294117647, Val : 41.41988888888889\n",
            "Epoch 309 ------> Error => Train : 41.49337254901961, Val : 41.33011111111111\n",
            "Epoch 310 ------> Error => Train : 41.48613725490196, Val : 41.34711111111111\n",
            "Epoch 311 ------> Error => Train : 41.39760784313726, Val : 41.355888888888884\n",
            "Epoch 312 ------> Error => Train : 41.39090196078431, Val : 41.405666666666676\n",
            "Epoch 313 ------> Error => Train : 41.36549019607843, Val : 41.22555555555556\n",
            "Epoch 314 ------> Error => Train : 41.322607843137256, Val : 41.221333333333334\n",
            "Epoch 315 ------> Error => Train : 41.29058823529411, Val : 41.20666666666666\n",
            "Epoch 316 ------> Error => Train : 41.30117647058824, Val : 41.11622222222222\n",
            "Epoch 317 ------> Error => Train : 41.2316274509804, Val : 41.150333333333336\n",
            "Epoch 318 ------> Error => Train : 41.21892156862745, Val : 41.147333333333336\n",
            "Epoch 319 ------> Error => Train : 41.16660784313726, Val : 41.06144444444445\n",
            "Epoch 320 ------> Error => Train : 41.146235294117645, Val : 41.06588888888889\n",
            "Epoch 321 ------> Error => Train : 41.14070588235295, Val : 41.08411111111111\n",
            "Epoch 322 ------> Error => Train : 41.09564705882353, Val : 41.01155555555556\n",
            "Epoch 323 ------> Error => Train : 41.09937254901961, Val : 40.92411111111112\n",
            "Epoch 324 ------> Error => Train : 41.020980392156865, Val : 40.95033333333333\n",
            "Epoch 325 ------> Error => Train : 41.04060784313725, Val : 40.94611111111111\n",
            "Epoch 326 ------> Error => Train : 41.00405882352941, Val : 40.903888888888886\n",
            "Epoch 327 ------> Error => Train : 40.960686274509804, Val : 40.968444444444444\n",
            "Epoch 328 ------> Error => Train : 40.860392156862744, Val : 40.81811111111111\n",
            "Epoch 329 ------> Error => Train : 40.86633333333333, Val : 40.739888888888885\n",
            "Epoch 330 ------> Error => Train : 40.870901960784316, Val : 40.784666666666666\n",
            "Epoch 331 ------> Error => Train : 40.79972549019608, Val : 40.747555555555564\n",
            "Epoch 332 ------> Error => Train : 40.79543137254902, Val : 40.83588888888889\n",
            "Epoch 333 ------> Error => Train : 40.75821568627451, Val : 40.58122222222222\n",
            "Epoch 334 ------> Error => Train : 40.71801960784313, Val : 40.663555555555554\n",
            "Epoch 335 ------> Error => Train : 40.66417647058824, Val : 40.617000000000004\n",
            "Epoch 336 ------> Error => Train : 40.69647058823529, Val : 40.643888888888895\n",
            "Epoch 337 ------> Error => Train : 40.65262745098039, Val : 40.602333333333334\n",
            "Epoch 338 ------> Error => Train : 40.624901960784314, Val : 40.51222222222222\n",
            "Epoch 339 ------> Error => Train : 40.584901960784315, Val : 40.42833333333333\n",
            "Epoch 340 ------> Error => Train : 40.56192156862745, Val : 40.467555555555556\n",
            "Epoch 341 ------> Error => Train : 40.57707843137254, Val : 40.513111111111115\n",
            "Epoch 342 ------> Error => Train : 40.507176470588234, Val : 40.48466666666667\n",
            "Epoch 343 ------> Error => Train : 40.508607843137256, Val : 40.510333333333335\n",
            "Epoch 344 ------> Error => Train : 40.43078431372549, Val : 40.40222222222222\n",
            "Epoch 345 ------> Error => Train : 40.39033333333333, Val : 40.35766666666667\n",
            "Epoch 346 ------> Error => Train : 40.42341176470588, Val : 40.411\n",
            "Epoch 347 ------> Error => Train : 40.356274509803924, Val : 40.32622222222222\n",
            "Epoch 348 ------> Error => Train : 40.354098039215685, Val : 40.29311111111111\n",
            "Epoch 349 ------> Error => Train : 40.340607843137256, Val : 40.31411111111112\n",
            "Epoch 350 ------> Error => Train : 40.27754901960785, Val : 40.349444444444444\n",
            "Epoch 351 ------> Error => Train : 40.26939215686274, Val : 40.23466666666667\n",
            "Epoch 352 ------> Error => Train : 40.22980392156863, Val : 40.209777777777774\n",
            "Epoch 353 ------> Error => Train : 40.2048431372549, Val : 40.07888888888888\n",
            "Epoch 354 ------> Error => Train : 40.22401960784313, Val : 40.172666666666665\n",
            "Epoch 355 ------> Error => Train : 40.12845098039216, Val : 40.15155555555555\n",
            "Epoch 356 ------> Error => Train : 40.17813725490196, Val : 40.093444444444444\n",
            "Epoch 357 ------> Error => Train : 40.11396078431373, Val : 40.086444444444446\n",
            "Epoch 358 ------> Error => Train : 40.08764705882353, Val : 39.940666666666665\n",
            "Epoch 359 ------> Error => Train : 40.05190196078431, Val : 39.998222222222225\n",
            "Epoch 360 ------> Error => Train : 40.05192156862745, Val : 39.89311111111111\n",
            "Epoch 361 ------> Error => Train : 39.97764705882353, Val : 39.904444444444444\n",
            "Epoch 362 ------> Error => Train : 40.017647058823535, Val : 39.92766666666667\n",
            "Epoch 363 ------> Error => Train : 39.93321568627451, Val : 39.943111111111115\n",
            "Epoch 364 ------> Error => Train : 39.95329411764706, Val : 39.878888888888895\n",
            "Epoch 365 ------> Error => Train : 39.875725490196075, Val : 39.87133333333333\n",
            "Epoch 366 ------> Error => Train : 39.852529411764706, Val : 39.82411111111111\n",
            "Epoch 367 ------> Error => Train : 39.86143137254902, Val : 39.75222222222222\n",
            "Epoch 368 ------> Error => Train : 39.86496078431372, Val : 39.68966666666667\n",
            "Epoch 369 ------> Error => Train : 39.815137254901956, Val : 39.62788888888889\n",
            "Epoch 370 ------> Error => Train : 39.79450980392157, Val : 39.70422222222223\n",
            "Epoch 371 ------> Error => Train : 39.75003921568627, Val : 39.73188888888889\n",
            "Epoch 372 ------> Error => Train : 39.72549019607843, Val : 39.70422222222223\n",
            "Epoch 373 ------> Error => Train : 39.67423529411765, Val : 39.681888888888885\n",
            "Epoch 374 ------> Error => Train : 39.66964705882353, Val : 39.57899999999999\n",
            "Epoch 375 ------> Error => Train : 39.66680392156863, Val : 39.68244444444444\n",
            "Epoch 376 ------> Error => Train : 39.634, Val : 39.61377777777778\n",
            "Epoch 377 ------> Error => Train : 39.6135294117647, Val : 39.50644444444445\n",
            "Epoch 378 ------> Error => Train : 39.564549019607846, Val : 39.589111111111116\n",
            "Epoch 379 ------> Error => Train : 39.59480392156863, Val : 39.58\n",
            "Epoch 380 ------> Error => Train : 39.46888235294117, Val : 39.50866666666667\n",
            "Epoch 381 ------> Error => Train : 39.5446862745098, Val : 39.58266666666667\n",
            "Epoch 382 ------> Error => Train : 39.505117647058825, Val : 39.43844444444444\n",
            "Epoch 383 ------> Error => Train : 39.44454901960784, Val : 39.45455555555556\n",
            "Epoch 384 ------> Error => Train : 39.404607843137256, Val : 39.346333333333334\n",
            "Epoch 385 ------> Error => Train : 39.415803921568624, Val : 39.46633333333333\n",
            "Epoch 386 ------> Error => Train : 39.41125490196079, Val : 39.41055555555556\n",
            "Epoch 387 ------> Error => Train : 39.36550980392157, Val : 39.32011111111111\n",
            "Epoch 388 ------> Error => Train : 39.31978431372549, Val : 39.248000000000005\n",
            "Epoch 389 ------> Error => Train : 39.34635294117648, Val : 39.41744444444444\n",
            "Epoch 390 ------> Error => Train : 39.31617647058823, Val : 39.28133333333333\n",
            "Epoch 391 ------> Error => Train : 39.315411764705885, Val : 39.20322222222222\n",
            "Epoch 392 ------> Error => Train : 39.26292156862745, Val : 39.28366666666667\n",
            "Epoch 393 ------> Error => Train : 39.238, Val : 39.14722222222222\n",
            "Epoch 394 ------> Error => Train : 39.2366862745098, Val : 39.166000000000004\n",
            "Epoch 395 ------> Error => Train : 39.19750980392157, Val : 39.17366666666666\n",
            "Epoch 396 ------> Error => Train : 39.14535294117647, Val : 39.157333333333334\n",
            "Epoch 397 ------> Error => Train : 39.097941176470584, Val : 39.12244444444445\n",
            "Epoch 398 ------> Error => Train : 39.10925490196078, Val : 39.07811111111111\n",
            "Epoch 399 ------> Error => Train : 39.081, Val : 39.11211111111111\n",
            "Epoch 400 ------> Error => Train : 39.07370588235294, Val : 39.03988888888889\n",
            "Epoch 401 ------> Error => Train : 39.030607843137254, Val : 38.986222222222224\n",
            "Epoch 402 ------> Error => Train : 39.088137254901966, Val : 38.97966666666666\n",
            "Epoch 403 ------> Error => Train : 39.02170588235295, Val : 38.910333333333334\n",
            "Epoch 404 ------> Error => Train : 39.01660784313725, Val : 38.96233333333333\n",
            "Epoch 405 ------> Error => Train : 38.97225490196078, Val : 38.97211111111111\n",
            "Epoch 406 ------> Error => Train : 38.91717647058823, Val : 38.894777777777776\n",
            "Epoch 407 ------> Error => Train : 38.87833333333333, Val : 38.90822222222222\n",
            "Epoch 408 ------> Error => Train : 38.882254901960785, Val : 38.86533333333333\n",
            "Epoch 409 ------> Error => Train : 38.875509803921574, Val : 38.859\n",
            "Epoch 410 ------> Error => Train : 38.81537254901961, Val : 38.830777777777776\n",
            "Epoch 411 ------> Error => Train : 38.83750980392157, Val : 38.785555555555554\n",
            "Epoch 412 ------> Error => Train : 38.79894117647059, Val : 38.757777777777775\n",
            "Epoch 413 ------> Error => Train : 38.77703921568627, Val : 38.69466666666667\n",
            "Epoch 414 ------> Error => Train : 38.723549019607844, Val : 38.79555555555556\n",
            "Epoch 415 ------> Error => Train : 38.73601960784313, Val : 38.67455555555556\n",
            "Epoch 416 ------> Error => Train : 38.6854705882353, Val : 38.67755555555556\n",
            "Epoch 417 ------> Error => Train : 38.655686274509804, Val : 38.663\n",
            "Epoch 418 ------> Error => Train : 38.67745098039216, Val : 38.56433333333334\n",
            "Epoch 419 ------> Error => Train : 38.66070588235294, Val : 38.69233333333334\n",
            "Epoch 420 ------> Error => Train : 38.58749019607842, Val : 38.45344444444444\n",
            "Epoch 421 ------> Error => Train : 38.59507843137255, Val : 38.64988888888889\n",
            "Epoch 422 ------> Error => Train : 38.54892156862745, Val : 38.54366666666667\n",
            "Epoch 423 ------> Error => Train : 38.55394117647059, Val : 38.57733333333333\n",
            "Epoch 424 ------> Error => Train : 38.55154901960785, Val : 38.53066666666666\n",
            "Epoch 425 ------> Error => Train : 38.56552941176471, Val : 38.535444444444444\n",
            "Epoch 426 ------> Error => Train : 38.51535294117647, Val : 38.55522222222223\n",
            "Epoch 427 ------> Error => Train : 38.47735294117647, Val : 38.44433333333333\n",
            "Epoch 428 ------> Error => Train : 38.48627450980392, Val : 38.544\n",
            "Epoch 429 ------> Error => Train : 38.44505882352941, Val : 38.45133333333334\n",
            "Epoch 430 ------> Error => Train : 38.39427450980392, Val : 38.37155555555556\n",
            "Epoch 431 ------> Error => Train : 38.39190196078432, Val : 38.51255555555555\n",
            "Epoch 432 ------> Error => Train : 38.37380392156863, Val : 38.321666666666665\n",
            "Epoch 433 ------> Error => Train : 38.398078431372554, Val : 38.33888888888889\n",
            "Epoch 434 ------> Error => Train : 38.35841176470588, Val : 38.370333333333335\n",
            "Epoch 435 ------> Error => Train : 38.287549019607845, Val : 38.33833333333334\n",
            "Epoch 436 ------> Error => Train : 38.28186274509804, Val : 38.167777777777786\n",
            "Epoch 437 ------> Error => Train : 38.27992156862745, Val : 38.18222222222222\n",
            "Epoch 438 ------> Error => Train : 38.25535294117647, Val : 38.24911111111111\n",
            "Epoch 439 ------> Error => Train : 38.262058823529415, Val : 38.257555555555555\n",
            "Epoch 440 ------> Error => Train : 38.20358823529412, Val : 38.19488888888889\n",
            "Epoch 441 ------> Error => Train : 38.25860784313725, Val : 38.21344444444445\n",
            "Epoch 442 ------> Error => Train : 38.17666666666666, Val : 38.21044444444445\n",
            "Epoch 443 ------> Error => Train : 38.1214705882353, Val : 38.14977777777778\n",
            "Epoch 444 ------> Error => Train : 38.123, Val : 38.144333333333336\n",
            "Epoch 445 ------> Error => Train : 38.159333333333336, Val : 38.18788888888889\n",
            "Epoch 446 ------> Error => Train : 38.128764705882354, Val : 38.10033333333334\n",
            "Epoch 447 ------> Error => Train : 38.08094117647059, Val : 38.135444444444445\n",
            "Epoch 448 ------> Error => Train : 38.06849019607843, Val : 38.14911111111111\n",
            "Epoch 449 ------> Error => Train : 38.05174509803922, Val : 38.07666666666667\n",
            "Epoch 450 ------> Error => Train : 37.98566666666667, Val : 38.08533333333334\n",
            "Epoch 451 ------> Error => Train : 38.04666666666667, Val : 37.958111111111116\n",
            "Epoch 452 ------> Error => Train : 38.019058823529406, Val : 37.95722222222223\n",
            "Epoch 453 ------> Error => Train : 37.97998039215686, Val : 38.03044444444444\n",
            "Epoch 454 ------> Error => Train : 37.98909803921568, Val : 38.04333333333334\n",
            "Epoch 455 ------> Error => Train : 37.91507843137255, Val : 37.922444444444444\n",
            "Epoch 456 ------> Error => Train : 37.915176470588236, Val : 38.03311111111111\n",
            "Epoch 457 ------> Error => Train : 37.91705882352941, Val : 37.846000000000004\n",
            "Epoch 458 ------> Error => Train : 37.88403921568627, Val : 37.90755555555556\n",
            "Epoch 459 ------> Error => Train : 37.83227450980392, Val : 37.837555555555554\n",
            "Epoch 460 ------> Error => Train : 37.84980392156862, Val : 37.952999999999996\n",
            "Epoch 461 ------> Error => Train : 37.80778431372549, Val : 37.86311111111111\n",
            "Epoch 462 ------> Error => Train : 37.800411764705885, Val : 37.78888888888889\n",
            "Epoch 463 ------> Error => Train : 37.76898039215686, Val : 37.80966666666667\n",
            "Epoch 464 ------> Error => Train : 37.77776470588235, Val : 37.82933333333334\n",
            "Epoch 465 ------> Error => Train : 37.79870588235294, Val : 37.71388888888889\n",
            "Epoch 466 ------> Error => Train : 37.727215686274505, Val : 37.77111111111111\n",
            "Epoch 467 ------> Error => Train : 37.72333333333333, Val : 37.68088888888889\n",
            "Epoch 468 ------> Error => Train : 37.70319607843137, Val : 37.657888888888884\n",
            "Epoch 469 ------> Error => Train : 37.66876470588235, Val : 37.68733333333333\n",
            "Epoch 470 ------> Error => Train : 37.672, Val : 37.68422222222222\n",
            "Epoch 471 ------> Error => Train : 37.64254901960784, Val : 37.617000000000004\n",
            "Epoch 472 ------> Error => Train : 37.609647058823526, Val : 37.64255555555556\n",
            "Epoch 473 ------> Error => Train : 37.602156862745105, Val : 37.665333333333336\n",
            "Epoch 474 ------> Error => Train : 37.55345098039216, Val : 37.58166666666666\n",
            "Epoch 475 ------> Error => Train : 37.538588235294114, Val : 37.56233333333333\n",
            "Epoch 476 ------> Error => Train : 37.56105882352941, Val : 37.51855555555556\n",
            "Epoch 477 ------> Error => Train : 37.52160784313726, Val : 37.52766666666666\n",
            "Epoch 478 ------> Error => Train : 37.53078431372549, Val : 37.54422222222222\n",
            "Epoch 479 ------> Error => Train : 37.44549019607843, Val : 37.55733333333333\n",
            "Epoch 480 ------> Error => Train : 37.42107843137255, Val : 37.44377777777778\n",
            "Epoch 481 ------> Error => Train : 37.47619607843137, Val : 37.510666666666665\n",
            "Epoch 482 ------> Error => Train : 37.44901960784314, Val : 37.53611111111111\n",
            "Epoch 483 ------> Error => Train : 37.427549019607845, Val : 37.43366666666667\n",
            "Epoch 484 ------> Error => Train : 37.4151568627451, Val : 37.51533333333333\n",
            "Epoch 485 ------> Error => Train : 37.359529411764704, Val : 37.38322222222222\n",
            "Epoch 486 ------> Error => Train : 37.35713725490196, Val : 37.35922222222222\n",
            "Epoch 487 ------> Error => Train : 37.348705882352945, Val : 37.39522222222223\n",
            "Epoch 488 ------> Error => Train : 37.32017647058824, Val : 37.36611111111111\n",
            "Epoch 489 ------> Error => Train : 37.35817647058823, Val : 37.45133333333334\n",
            "Epoch 490 ------> Error => Train : 37.314235294117644, Val : 37.254333333333335\n",
            "Epoch 491 ------> Error => Train : 37.27186274509804, Val : 37.27711111111111\n",
            "Epoch 492 ------> Error => Train : 37.27709803921569, Val : 37.26777777777778\n",
            "Epoch 493 ------> Error => Train : 37.241098039215686, Val : 37.143777777777785\n",
            "Epoch 494 ------> Error => Train : 37.231647058823526, Val : 37.192\n",
            "Epoch 495 ------> Error => Train : 37.22521568627451, Val : 37.235888888888894\n",
            "Epoch 496 ------> Error => Train : 37.20094117647059, Val : 37.333333333333336\n",
            "Epoch 497 ------> Error => Train : 37.17045098039216, Val : 37.19622222222222\n",
            "Epoch 498 ------> Error => Train : 37.168176470588236, Val : 37.28522222222222\n",
            "Epoch 499 ------> Error => Train : 37.14725490196078, Val : 37.211444444444446\n",
            "Epoch 500 ------> Error => Train : 37.13770588235293, Val : 37.12477777777778\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "-Yefr5jKS7AT",
        "outputId": "fa14da33-3a4f-4e16-f6fd-fb051cb5a1e4"
      },
      "source": [
        "fig = plt.figure()\n",
        "plt.plot(train_loss, c='r', label=\"Train\")\n",
        "plt.plot(val_loss, c='g', label=\"Val\")\n",
        "plt.legend()\n",
        "plt.title(\"Reconstruction Error\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Error\")"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Error')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lol-hyPcBByF"
      },
      "source": [
        "# Test data image reconstruction\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        },
        "id": "mHybMXHyBAKH",
        "outputId": "3799faf4-33ba-4abe-9c8b-3363aaba6b95"
      },
      "source": [
        "print(\"\\n\\nOriginal Images ....\")\n",
        "fig1 = plt.figure()\n",
        "for i in range(9):\n",
        "  plt.subplot(3,3,i+1)\n",
        "  plt.tight_layout()\n",
        "  plt.imshow(test[i].reshape((28,28)), cmap='gray', interpolation='none')\n",
        "  plt.title(\"Digit: {}\".format(test_y[i]))\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Original Images ....\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVUAAAELCAYAAABpiBWpAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAARS0lEQVR4nO3dX8hk9X3H8fdXE9eq61/EdtW4oZuLpTaRFKUXKgYsKFUaoUiK1GBqFSF4YfEPEcULSTUFSxWClRqtCFpbEsLSWHLjhSJir0TXWKqyi8vjnyxmg6sirPvtxZmHjNN59pkz85s5vzPzfsHAzsx5zvzOc77Pdz7nd87MRmYiSSrjqK4HIEnLxKYqSQXZVCWpIJuqJBVkU5WkgmyqklTQwptqRDwcEXeVXlb9ZU1oVJ9rIkpepxoRe4AzgEPA58DrwBPAI5l5eMZ1XwI8mZlntfiZZ4GLhh46BvifzPzjWcaiyVVYE7cC3wXOAfYDP87Mf5hlHGqnwpr4FnA38E3gN5m5fZYxzCOpXpmZW2mK9j7gduDRObzOpjLz8sw8Yf0GvAj8exdjWXHV1AQQwLXAKcBlwPcj4jsdjWWV1VQTHwM/AW4tsrbMLHYD9gCXjjx2AXAYOHdw/3Hg3qHnbwPeBdaA64EEdgwvCxwPfDpYz8HBbVvLsW2neVfcXnKbvfW3JgbrexB4qOvf0yrdaq0J4FJgz6zbN/c51cx8GdjHFw/DAYiIy4BbBhuzA7hkg3V8DFwOrOXvkudaRFwYEQcmHMq1wPOZuaf9VqikWmoiImIwht1TbYiKqaUmSljUiao14NQxj18NPJaZuzPzE+CeNivNzBcy8+QJF7+W5h1NdaihJu6h+Rt4rM1raG5qqImZLaqpngl8OObxbcA7Q/ffGbPMzCLiQuD3gf+Yx/o1la5r4vs0b7R/npmfzeM11FqnNVHKl+b9AhFxPs0v64UxT78LDJ+lO/sIq5rlMoXvAj/NzIMzrEOFdF0TEfE94A7g4szcN806VFbXNVHS3JJqRJwYEVcAT9Nc4vDqmMWeAa6LiJ0RcRxwpGvN3gdOi4iTWo7j92gOHx5v83Mqr4aaiIhrgB8Cf5aZb7cYvuagkpo4KiKOBb7c3I1jI+KYFpvxBfNoqrsi4iOaiH4n8ABw3bgFM/NZmrOvzwFvAi8Nnvp/h2OZ+QbwFPB2RByIiG0RcVFEbJY+vw0cGLyGulFTTdwLnAb8d0QcHNwennbDNLWaauJimqsGfgF8ZfDvX061VRS++H9WEbETeA3YkpmHuh6PumdNaFTtNdH5Z/8j4qqI2BIRpwD3A7tq/EVpcawJjepTTXTeVIEbgQ+At2guzr+p2+GoAtaERvWmJqo6/JekvqshqUrS0rCpSlJBrS7+j4iVmCvIzOh6DH2xKjUB7M/M07seRB+sek2YVKXJ7O16AKrO2JqwqUpSQTZVSSrIpipJBdlUJamguX/1n9TWtB9Iab7IX+qWSVWSCjKpqhqzfmR6/edNrNqolhZRGyZVSSrIpKrO+aU+WiYmVUkqyKSqTkyTTtfnw0y2amuR8+wmVUkqaK5JdZY0IlkLaquGoxiTqiQVZFOVpIKqO1E1j/juYWR9hvfJ6D53f6nPTKqSVFB1SVWrZ9JkWsNJCGkzJlVJKmiuSbXN3JgpRBuZtDaci11dXX6ByiiTqiQVVM2c6rTvKCZcmVBVE5OqJBVUTVJta7OEanrpP49C1EcmVUkqqLdJVcvLs/2aVI1HMyZVSSqod0nVuVS5j7WZLmvEpCpJBfUuqWp51Tg/JrVlUpWkgnqTVJ1LXV6e7VdbNX3Wf5RJVZIK6k1S3UgN70yStM6kKkkFVZ9UPSMsj0bUJyZVSSqo2qTq2X6ta3t1QMmjG+tMbZlUJamg6pKqc6ialrWz/Pqwj02qklRQdUl1M85xSaqZSVWSCrKpSlJB1Rz+92ECWvMxj0uhjvQ66p8+XWJpUpWkgqpJqpup6Z1I8+E+1jIwqUpSQZ0nVedSJW2mT0cxJlVJKsimKkkF2VQlqaDO51Q306e5FEkyqUpSQZ0nVZOopGViUpWkgtom1f3A3nkMpCLndD2AnlmFmgDroo2Vronw4ntJKsfDf0kqyKYqSQXZVCWpIJuqJBVkU5WkgmyqklSQTVWSCrKpSlJBNlVJKsimKkkF2VQlqSCbqiQVtPCmGhEPR8RdpZdVf1kTGtXnmij6LVURsQc4AzgEfA68DjwBPJKZh2dc9yXAk5l5VoufCeA+4PrBQ/8C3JF+NdfC1FYTQz97DPAKsHWan9f0aquJiPgWcDfwTeA3mbl9ljHMI6lemZlbab5r8D7gduDRObzOJG4Avg18A/g6cCVwY0djWWU11cS6W4FfdzyGVVZTTXwM/ISmJmaXmcVuwB7g0pHHLgAOA+cO7j8O3Dv0/G3Au8AaTaJMYMfwssDxwKeD9Rwc3LZNMJ4XgRuG7v8N8FLJbfbWr5oYrOOrwK+Ay4F9Xf+OVu1WY00M1nMpsGfW7Zv7nGpmvgzsAy4afS4iLgNuGWzMDuCSDdbxMc0fwFpmnjC4rUXEhRFx4Agv/0c0h3jrXhk8pg51XBMADwE/oPkDVAUqqIliFnWiag04dczjVwOPZebuzPwEuKfNSjPzhcw8+QiLnAD8duj+b4ETwv9tsAad1EREXAUcnZk/a7NeLURXfaKoRTXVM4EPxzy+DXhn6P47Y5aZxUHgxKH7JwIHc5D11amF10REHA/8CLi51DpVVFd9oqi5N9WIOJ/ml/XCmKffBYbP0p19hFVN0wh305ykWveNwWPqUIc18TVgO/B8RLwH/BT4g4h4LyK2t1yXCuq4TxQ1t6YaESdGxBXA0zSXOLw6ZrFngOsiYmdEHAcc6Vqz94HTIuKkFsN4ArglIs6MiG3A39FMaqsDFdTEazR/kOcNbtcP1nEelaefZVVBTRARR0XEscCXm7tx7OCSu6nMo6nuioiPaIr0TuAB4LpxC2bms8CDwHPAm8BLg6c+G7PsG8BTwNsRcSAitkXERRFx8Ahj+WdgF/AqzR/Ufw4e02JVUROZeSgz31u/0RxqHh7c/3zGbVQ7VdTEwMU0Jy1/AXxl8O9fTrVVVPZfVEfETprmtyUzD3U9HnXPmtCo2mui88/+R8RVEbElIk4B7gd21fiL0uJYExrVp5rovKnSfMLpA+Atmo+s3dTtcFQBa0KjelMTVR3+S1Lf1ZBUJWlp2FQlqaAvtVk4IlZiriAz/RjrhFalJoD9mXl614Pog1WvCZOqNJm9XQ9A1RlbEzZVSSrIpipJBdlUJakgm6okFWRTlaSCWl1StQiTfsLLL++XVCOTqiQVVF1SlUaPVqY9Kim1HvXPZke886wFk6okFVRNUvXbsiTNqoY+YlKVpII6T6rTvrM4X7Z85p0yhtdvvWheTKqSVJBNVZIK6vzwv5T1QzsP66TVU9OHhkyqklRQZ0m1hksfVAdrQfO2yCNYk6okFbTwpLqoy2acW+2/Uh9PlRbJpCpJBS0kqZZIDqOpZbN1jnve9FqPI+0/95P6zKQqSQVVe53qZmll/Xnnz7Suy697Uzdq3OcmVUkqqLqkappYbl3MpVpTWiSTqiQV1HlSNUVIWiYmVUkqqPOkKq2b9tNwXgGyemo867/OpCpJBfUuqZpK+m2S64vdx+ozk6okFdS7pDoNrzCQtCgmVUkqqDdJte08m+m0buP2z7T/z9BGP2cNLJ+az/qvM6lKUkGdJ9XSZ3preKfSdErvO/8XCHXBpCpJBXWeVKV5MaGqCyZVSSrIpipJBdlUJakgm6okFbSQE1XDJwxKXULlSQhpdfThov91JlVJKmjhl1RN+hFDSeojk6okFdT5xf81zYVoOVhTy2eSLzevhUlVkgrqPKlKszKZro4+7GuTqiQVZFOVpIJsqpJUkE1VkgqyqUpSQW3P/u8H9s5jIBU5p+sB9Mwq1ARYF22sdE1EHy6mlaS+8PBfkgqyqUpSQTZVSSrIpipJBdlUJakgm6okFWRTlaSCbKqSVJBNVZIKsqlKUkE2VUkqyKYqSQXZVCWpoIU31Yh4OCLuKr2s+sua0Kg+10TRr/6LiD3AGcAh4HPgdeAJ4JHMPDzjui8BnszMs6b42WOAV4Ct0/y8pldbTUTEycA/AZcPHvpxZt4zyzjUToU1cQ9wJ/DZ0MNfz8y3pxnDPJLqlZm5leYLXO8DbgcencPrtHEr8OuOx7DKaqqJfwSOA7YDFwB/HRHXdTSWVVZTTQD8W2aeMHSbqqECkJnFbsAe4NKRxy4ADgPnDu4/Dtw79PxtwLvAGnA9kMCO4WWB44FPB+s5OLhtm3BMXwV+RZNM9pXcXm/9qwmab6U/f+j+D4Dnu/49rdKtwpq4hybdFtm+uc+pZubLwD7gotHnIuIy4BbgUmAHcMkG6/iYpimu5e/eSdYi4sKIOLDJEB6i+cP5dPqtUEkV1ESM/Pvc9luhkiqoiSsj4sOI2B0RN82yLYs6UbUGnDrm8auBxzJzd2Z+QvOOMbHMfCEzT97o+Yi4Cjg6M3/WZr1aiE5qAvgv4I6I2BoRO4Dv0UwHqHtd1cQzwE7gdOBvgbsj4q/avMawRTXVM4EPxzy+DXhn6P47Y5aZSkQcD/wIuLnUOlXUwmti4Gaao5b/BX4OPEWTkNS9TmoiM1/PzLXM/DwzX6Q5kfmX066v7f+m2lpEnE/zy3phzNPvAsNn6c4+wqraXqbwNZqTEc9HBMAxwEkR8R7wp5m5p+X6VEiHNUFmfghcMzSWHwIvt12PyuqyJjZYR2y61AbmllQj4sSIuAJ4mmYS+NUxiz0DXBcROyPiOOBI15q9D5wWESdNOITXaH755w1u1w/WcR7l048mUEFNEBF/GBGnRcTREXE5cAPNSQ51oJKa+IuIOCUaF9Aczfy8xWZ8wTya6q6I+Iimcd0JPACMvWQlM58FHgSeA94EXho89dmYZd+gOVR7OyIORMS2iLgoIg5usO5Dmfne+o3msOLw4P7nM26j2qmiJgb+BHgV+Aj4e+CazNw93WZpBjXVxHcG6/2I5nrZ+zPzX6fbrMIX/88qInbSJMwtmXmo6/Goe9aERtVeE51/9j8iroqILRFxCnA/sKvGX5QWx5rQqD7VROdNFbgR+AB4i+YjazNdI6alYE1oVG9qoqrDf0nquxqSqiQtDZuqJBXU6uL/iFiJuYLMnPrC31WzKjUB7M/M07seRB+sek2YVKXJ7O16AKrO2JqwqUpSQTZVSSrIpipJBdlUJakgm6okFTT371OVpK6U+MTo4PuYJ2ZSlaSCOkuqm72DtH13aLP+WdctqU41fJeJSVWSClp4Uu0yoapf5l0r6q+a/85NqpJU0EKS6iTvKotIHSabfqg5hUibMalKUkE2VUkqaGku/veQsf/a7sP15Z3WWT4b1ULpfT2P2jGpSlJBc02qizhBVctJMHVntAbc3/3U5khlfR+PHq3UUAsmVUkqaGnmVEeZVvrD+fDVNsv+H/07r+Hv3qQqSQX1Lqn60cXVsdE82Wa8KqAfpplD7QOTqiQV1HlSdT5NmxlNKdbM6uhTQl1nUpWkgjpPqlJpfUw3+qI+70OTqiQVNNekOu3Z21leS8tj2rrx7H//1fDJqGmZVCWpoIXMqZZ4l/GMr7S6Zv37X2TSNalKUkG9P/vfp7kWjTft3PtmP+fcqtYtshZMqpJUUPVJ1bnU1TFpYjV5alqLSKwmVUkqqPqkuhHTyvJqu2+dW+2nSfZHH49UTaqSVFBvk6qk5dfHbygzqUpSQdUm1UX9v99aHpPOrQ4vK5VmUpWkgqpNqpvp87fYaL4mud7VKwI0LyZVSSrIpipJBfXu8L8Pl1RImo9Zv3xnEUyqklRQ75KqNKlF/nc+WqxJPxTQxYlIk6okFdT7pOolMdrMkRKrl1Yth5r2n0lVkgqqNqnW9M4jSZMyqUpSQdUmVak0j360CCZVSSrIpipJBdlUJamgtnOq+4G98xhIRc7pegA9swo1AdZFGytdE+FH+CSpHA//Jakgm6okFWRTlaSCbKqSVJBNVZIKsqlKUkE2VUkqyKYqSQXZVCWpoP8DakTLZFYeTyEAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 9 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "kLQRDTvgBh_Z",
        "outputId": "ff943ea5-45dd-4f41-af45-8acf90fc9d14"
      },
      "source": [
        "print(\"\\n\\nSampled images....\")\n",
        "fig2 = plt.figure()\n",
        "for i in range(9):\n",
        "  plt.subplot(3,3,i+1)\n",
        "  plt.tight_layout()\n",
        "\n",
        "  # 1 step sampling\n",
        "  img = rbm.reconstruct_image(test[i].T.reshape((784,1)))\n",
        "\n",
        "  plt.imshow(img.reshape((28,28)), cmap='gray', interpolation='none')\n",
        "  plt.title(\"Digit: {}\".format(test_y[i]))\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Sampled images....\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:35: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 9 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}